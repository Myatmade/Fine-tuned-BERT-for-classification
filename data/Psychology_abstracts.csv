Abstract,Link
"This research paper studies about the role of social media use and increase
the risk factor of mental health during covid 19 or lockdown. Although few
studies have been conducted on the role about the effect of social media use on
mental health during lockdown and impact on human reactive nature during
lockdown. As a rapidly spreading pandemic, a biomedical disease has serious
physical and tremendous mental health implications. An occupational community
of internal migrant workers is one of the most vulnerable, but neglected, and
is likely to develop psychological ill-effects due to COVID-19's double whammy
impact. Mental health is a crucial aspect that needs to be addressed during
this lock-down as all modes of communication revolve around the virus. There
are many difficulties with the unprecedented changes that have occurred so
quickly due to the pandemic and stay-at - home confinement to achieve social
distance and mitigate the risk of infection. These include impaired health,
well-being, and sleep as a result of daily routine disruption, anxiety, worry,
isolation, greater stress on family and work, and excessive screen time. An
essential part of our overall health and well-being is mental and emotional
health. An important skill is managing emotions and maintaining emotional
balance. It helps you face challenges and stress when you manage your emotional
health. Lack of skills in emotional regulation may lead to poor mental health
and relationship difficulties. It is as important to look after our mental
health as it is to look after our physical health. For mental health
professionals, the pandemic has also brought many ethical challenges.",http://arxiv.org/abs/2102.09369v1
"Mothers of infants have specific demands in fostering emotional bonds with
their children, characterized by dynamics that are different from adult-adult
interactions, notably requiring heightened maternal emotional regulation. In
this study, we analyzed maternal emotional state by modeling maternal emotion
regulation reflected in smiles. The dataset comprises N=94 videos of
approximately 3 plus or minus 1-minutes, capturing free play interactions
between 6 and 12-month-old infants and their mothers. Corresponding demographic
details of self-reported maternal mental health provide variables for
determining mothers' relations to emotions measured during free play. In this
work, we employ diverse methodological approaches to explore the temporal
evolution of maternal smiles. Our findings reveal a correlation between the
temporal dynamics of mothers' smiles and their emotional state. Furthermore, we
identify specific smile features that correlate with maternal emotional state,
thereby enabling informed inferences with existing literature on general smile
analysis. This study offers insights into emotional labor, defined as the
management of one's own emotions for the benefit of others, and emotion
regulation entailed in mother-infant interactions.",http://arxiv.org/abs/2408.01434v1
"We describe a set of experiments for building a temporal mental health
dynamics system. We utilise a pre-existing methodology for distant-supervision
of mental health data mining from social media platforms and deploy the system
during the global COVID-19 pandemic as a case study. Despite the challenging
nature of the task, we produce encouraging results, both explicit to the global
pandemic and implicit to a global phenomenon, Christmas Depression, supported
by the literature. We propose a methodology for providing insight into temporal
mental health dynamics to be utilised for strategic decision-making.",http://arxiv.org/abs/2008.13121v3
"Mental health support in colleges is vital in educating students by offering
counseling services and organizing supportive events. However, evaluating its
effectiveness faces challenges like data collection difficulties and lack of
standardized metrics, limiting research scope. Student feedback is crucial for
evaluation but often relies on qualitative analysis without systematic
investigation using advanced machine learning methods. This paper uses public
Student Voice Survey data to analyze student sentiments on mental health
support with large language models (LLMs). We created a sentiment analysis
dataset, SMILE-College, with human-machine collaboration. The investigation of
both traditional machine learning methods and state-of-the-art LLMs showed the
best performance of GPT-3.5 and BERT on this new dataset. The analysis
highlights challenges in accurately predicting response sentiments and offers
practical insights on how LLMs can enhance mental health-related research and
improve college mental health services. This data-driven approach will
facilitate efficient and informed mental health support evaluation, management,
and decision-making.",http://arxiv.org/abs/2412.04326v1
"There is a growing interest in HCI to envision, design, and evaluate
technology-enabled interventions that support users' emotion regulation. This
interest stems in part from increased recognition that the ability to regulate
emotions is critical to mental health, and that a lack of effective emotion
regulation is a transdiagnostic factor for mental illness. However, the
potential to combine innovative HCI designs with the theoretical grounding and
state-of-art interventions from psychology has yet to be fully realised. In
this paper, we synthesise HCI work on emotion regulation interventions and
propose a three-part framework to guide technology designers in making: (i)
theory-informed decisions about intervention targets; (ii) strategic decisions
regarding the technology-enabled intervention mechanisms to be included in the
system; and (iii) practical decisions around previous implementations of the
selected intervention components. We show how this framework can both
systematise HCI work to date and suggest a research agenda for future work.",http://arxiv.org/abs/2204.00118v2
"Failure and resilience are important aspects of gameplay. This is especially
important for serious and competitive games, where players need to adapt and
cope with failure frequently. In such situations, emotion regulation -- the
active process of modulating ones' emotions to cope and adapt to challenging
situations -- becomes essential. It is one of the prominent aspects of human
intelligence and promotes mental health and well-being. While there has been
work on developing artificial emotional regulation assistants to help users
cope with emotion regulation in the field of Intelligent Tutoring systems,
little is done to incorporate such systems or ideas into (serious) video games.
In this paper, we introduce a data-driven 6-phase approach to establish
empathetic artificial intelligence (EAI), which operates on raw chat log data
to detect key affective states, identify common sequences and emotion
regulation strategies and generalizes these to make them applicable for
intervention systems.",http://arxiv.org/abs/2302.09070v1
"In this paper, we provide causal evidence on abortions and risky health
behaviors as determinants of mental health development among young women. Using
administrative in- and outpatient records from Sweden, we apply a novel grouped
fixed-effects estimator proposed by Bonhomme and Manresa (2015) to allow for
time-varying unobserved heterogeneity. We show that the positive association
obtained from standard estimators shrinks to zero once we control for grouped
time-varying unobserved heterogeneity. We estimate the group-specific profiles
of unobserved heterogeneity, which reflect differences in unobserved risk to be
diagnosed with a mental health condition. We then analyze mental health
development and risky health behaviors other than unwanted pregnancies across
groups. Our results suggest that these are determined by the same type of
unobserved heterogeneity, which we attribute to the same unobserved process of
decision-making. We develop and estimate a theoretical model of risky choices
and mental health, in which mental health disparity across groups is generated
by different degrees of self-control problems. Our findings imply that mental
health concerns cannot be used to justify restrictive abortion policies.
Moreover, potential self-control problems should be targeted as early as
possible to combat future mental health consequences.",http://arxiv.org/abs/2103.12159v4
"Emotion regulation is a crucial element in dealing with emotional events and
has positive effects on mental health. This paper aims to provide a more
comprehensive understanding of emotional events by introducing a new French
corpus of emotional narratives collected using a questionnaire for emotion
regulation. We follow the theoretical framework of the Component Process Model
which considers emotions as dynamic processes composed of four interrelated
components (behavior, feeling, thinking and territory). Each narrative is
related to a discrete emotion and is structured based on all emotion components
by the writers. We study the interaction of components and their impact on
emotion classification with machine learning methods and pre-trained language
models. Our results show that each component improves prediction performance,
and that the best results are achieved by jointly considering all components.
Our results also show the effectiveness of pre-trained language models in
predicting discrete emotion from certain components, which reveal differences
in how emotion components are expressed.",http://arxiv.org/abs/2305.10446v1
"In cognitive psychology, automatic and self-reinforcing irrational thought
patterns are known as cognitive distortions. Left unchecked, patients
exhibiting these types of thoughts can become stuck in negative feedback loops
of unhealthy thinking, leading to inaccurate perceptions of reality commonly
associated with anxiety and depression. In this paper, we present a machine
learning framework for the automatic detection and classification of 15 common
cognitive distortions in two novel mental health free text datasets collected
from both crowdsourcing and a real-world online therapy program. When
differentiating between distorted and non-distorted passages, our model
achieved a weighted F1 score of 0.88. For classifying distorted passages into
one of 15 distortion categories, our model yielded weighted F1 scores of 0.68
in the larger crowdsourced dataset and 0.45 in the smaller online counseling
dataset, both of which outperformed random baseline metrics by a large margin.
For both tasks, we also identified the most discriminative words and phrases
between classes to highlight common thematic elements for improving targeted
and therapist-guided mental health treatment. Furthermore, we performed an
exploratory analysis using unsupervised content-based clustering and topic
modeling algorithms as first efforts towards a data-driven perspective on the
thematic relationship between similar cognitive distortions traditionally
deemed unique. Finally, we highlight the difficulties in applying mental
health-based machine learning in a real-world setting and comment on the
implications and benefits of our framework for improving automated delivery of
therapeutic treatment in conjunction with traditional cognitive-behavioral
therapy.",http://arxiv.org/abs/1909.07502v2
"Cognitive psychology delves on understanding perception, attention, memory,
language, problem-solving, decision-making, and reasoning. Large language
models (LLMs) are emerging as potent tools increasingly capable of performing
human-level tasks. The recent development in the form of GPT-4 and its
demonstrated success in tasks complex to humans exam and complex problems has
led to an increased confidence in the LLMs to become perfect instruments of
intelligence. Although GPT-4 report has shown performance on some cognitive
psychology tasks, a comprehensive assessment of GPT-4, via the existing
well-established datasets is required. In this study, we focus on the
evaluation of GPT-4's performance on a set of cognitive psychology datasets
such as CommonsenseQA, SuperGLUE, MATH and HANS. In doing so, we understand how
GPT-4 processes and integrates cognitive psychology with contextual
information, providing insight into the underlying cognitive processes that
enable its ability to generate the responses. We show that GPT-4 exhibits a
high level of accuracy in cognitive psychology tasks relative to the prior
state-of-the-art models. Our results strengthen the already available
assessments and confidence on GPT-4's cognitive psychology abilities. It has
significant potential to revolutionize the field of AI, by enabling machines to
bridge the gap between human and machine reasoning.",http://arxiv.org/abs/2303.11436v2
"After the pandemic, artificial intelligence (AI) powered support for mental
health care has become increasingly important. The breadth and complexity of
significant challenges required to provide adequate care involve: (a)
Personalized patient understanding, (b) Safety-constrained and medically
validated chatbot patient interactions, and (c) Support for continued
feedback-based refinements in design using chatbot-patient interactions. We
propose Alleviate, a chatbot designed to assist patients suffering from mental
health challenges with personalized care and assist clinicians with
understanding their patients better. Alleviate draws from an array of publicly
available clinically valid mental-health texts and databases, allowing
Alleviate to make medically sound and informed decisions. In addition,
Alleviate's modular design and explainable decision-making lends itself to
robust and continued feedback-based refinements to its design. In this paper,
we explain the different modules of Alleviate and submit a short video
demonstrating Alleviate's capabilities to help patients and clinicians
understand each other better to facilitate optimal care strategies.",http://arxiv.org/abs/2304.00025v1
"Emerging psychopathology studies are showing that patterns of changes in
emotional state -- emotion dynamics -- are associated with overall well-being
and mental health. More recently, there has been some work in tracking emotion
dynamics through one's utterances, allowing for data to be collected on a
larger scale across time and people. However, several questions about how
emotion dynamics change with age, especially in children, and when determined
through children's writing, remain unanswered. In this work, we use both a
lexicon and a machine learning based approach to quantify characteristics of
emotion dynamics determined from poems written by children of various ages. We
show that both approaches point to similar trends: consistent increasing
intensities for some emotions (e.g., anger, fear, joy, sadness, arousal, and
dominance) with age and a consistent decreasing valence with age. We also find
increasing emotional variability, rise rates (i.e., emotional reactivity), and
recovery rates (i.e., emotional regulation) with age. These results act as a
useful baselines for further research in how patterns of emotions expressed by
children change with age, and their association with mental health.",http://arxiv.org/abs/2306.05387v1
"The ability to regulate and cope with strong emotions is essential for
maintaining our mental health and well-being. However, learning how to
emotionally regulate can be a bit of a mystery since it is largely an invisible
process and it can be difficult to conjure up strong emotions to practice
regulating them. This is where virtual reality (or VR) comes in. VR is a
computer-generated 3D environment where the user experiences a simulated world
through 360 visuals, stereo audio, and 3D interaction with tracking sensors. VR
is a very visceral experience that feels 'real' even though you know it isn't.
If a virtual ball came flying at your head, you would duck! My past research
shows that we can provide VR experiences that elicit strong emotional reactions
so that people can practice coping and regulating their emotional responses.
For example, I helped create a VR experience of being in nature and then going
into space to see the Earth; it created the emotional reaction of awe and
wonder that led to a deeper connection with our planet. This shows that
emotional VR experiences can impact our emotions and behaviour both in VR and
beyond. My research proposal is to investigate the feasibility of emotion
regulation skills development in VR with teenagers. The idea is to simulate
emotional experiences (like the 1st day of high school) as a means to develop
emotion regulation skills so that they will be able to better cope with their
emotions. I will lead the design, development, and evaluation of this VR
experience and work directly with youth to meet their needs. This proof of
concept prototype is the first step in developing a VR platform that provides
youth with an effective way to regulate their emotions and improve their mental
health from their own homes, which will lead to improvements in education,
socio-emotional, and economic outcomes for youth in Canada and globally.",http://arxiv.org/abs/2212.00002v1
"Recently foundational issues of applicability of the formalism of quantum
mechanics (QM) to cognitive psychology, decision making, and psychophysics
attracted a lot of interest. In particular, in \cite{DKBB} the possibility to
use of the projection postulate and representation of ""mental observables"" by
Hermitian operators was discussed in very detail. The main conclusion of the
recent discussions on the foundations of ""quantum(-like) cognitive psychology""
is that one has to be careful in determination of conditions of applicability
of the projection postulate as a mathematical tool for description of
measurements of observables represented by Hermitian operators. To represent
some statistical experimental data (both physical and mental) in the
quantum(-like) way, one has to use generalized quantum observables given by
positive operator-valued measures (POVMs). This paper contains a brief review
on POVMs which can be useful for newcomers to the field of quantum(-like)
studies. Especially interesting for cognitive psychology is a variant of the
formula of total probability (FTP) with the interference term derived for
incompatible observables given by POVMs. We present an interpretation of the
interference term from the psychological viewpoint. As was shown before, the
appearance of such a term (perturbing classical FTP) plays the important role
in cognitive psychology, e.g., recognition of ambiguous figures and the
disjunction effect. The interference term for observables given by POVMs has
much more complicated structure than the corresponding term for observables
given by Hermitian operators. We elaborate cognitive interpretations of
different components of the POVMs-interference term and apply our analysis to a
quantum(-like) model of decision making.",http://arxiv.org/abs/1405.1269v1
"Automatic depression detection on Twitter can help individuals privately and
conveniently understand their mental health status in the early stages before
seeing mental health professionals. Most existing black-box-like deep learning
methods for depression detection largely focused on improving classification
performance. However, explaining model decisions is imperative in health
research because decision-making can often be high-stakes and life-and-death.
Reliable automatic diagnosis of mental health problems including depression
should be supported by credible explanations justifying models' predictions. In
this work, we propose a novel explainable model for depression detection on
Twitter. It comprises a novel encoder combining hierarchical attention
mechanisms and feed-forward neural networks. To support psycholinguistic
studies, our model leverages metaphorical concept mappings as input. Thus, it
not only detects depressed individuals, but also identifies features of such
users' tweets and associated metaphor concept mappings.",http://arxiv.org/abs/2209.07494v1
"We are united in how emotions are central to shaping our experiences; and
yet, individuals differ greatly in how we each identify, categorize, and
express emotions. In psychology, variation in the ability of individuals to
differentiate between emotion concepts is called emotion granularity
(determined through self-reports of one's emotions). High emotion granularity
has been linked with better mental and physical health; whereas low emotion
granularity has been linked with maladaptive emotion regulation strategies and
poor health outcomes. In this work, we propose computational measures of
emotion granularity derived from temporally-ordered speaker utterances in
social media (in lieu of self-reports that suffer from various biases). We then
investigate the effectiveness of such text-derived measures of emotion
granularity in functioning as markers of various mental health conditions
(MHCs). We establish baseline measures of emotion granularity derived from
textual utterances, and show that, at an aggregate level, emotion granularities
are significantly lower for people self-reporting as having an MHC than for the
control population. This paves the way towards a better understanding of the
MHCs, and specifically the role emotions play in our well-being.",http://arxiv.org/abs/2403.02281v2
"We study GPT-3, a recent large language model, using tools from cognitive
psychology. More specifically, we assess GPT-3's decision-making, information
search, deliberation, and causal reasoning abilities on a battery of canonical
experiments from the literature. We find that much of GPT-3's behavior is
impressive: it solves vignette-based tasks similarly or better than human
subjects, is able to make decent decisions from descriptions, outperforms
humans in a multi-armed bandit task, and shows signatures of model-based
reinforcement learning. Yet we also find that small perturbations to
vignette-based tasks can lead GPT-3 vastly astray, that it shows no signatures
of directed exploration, and that it fails miserably in a causal reasoning
task. These results enrich our understanding of current large language models
and pave the way for future investigations using tools from cognitive
psychology to study increasingly capable and opaque artificial agents.",http://arxiv.org/abs/2206.14576v1
"As the prevalence of mental health challenges, social media has emerged as a
key platform for individuals to express their emotions.Deep learning tends to
be a promising solution for analyzing mental health on social media. However,
black box models are often inflexible when switching between tasks, and their
results typically lack explanations. With the rise of large language models
(LLMs), their flexibility has introduced new approaches to the field. Also due
to the generative nature, they can be prompted to explain decision-making
processes. However, their performance on complex psychological analysis still
lags behind deep learning. In this paper, we introduce the first multi-task
Chinese Social Media Interpretable Mental Health Instructions (C-IMHI) dataset,
consisting of 9K samples, which has been quality-controlled and manually
validated. We also propose MentalGLM series models, the first open-source LLMs
designed for explainable mental health analysis targeting Chinese social media,
trained on a corpus of 50K instructions. The proposed models were evaluated on
three downstream tasks and achieved better or comparable performance compared
to deep learning models, generalized LLMs, and task fine-tuned LLMs. We
validated a portion of the generated decision explanations with experts,
showing promising results. We also evaluated the proposed models on a clinical
dataset, where they outperformed other LLMs, indicating their potential
applicability in the clinical field. Our models show strong performance,
validated across tasks and perspectives. The decision explanations enhance
usability and facilitate better understanding and practical application of the
models. Both the constructed dataset and the models are publicly available via:
https://github.com/zwzzzQAQ/MentalGLM.",http://arxiv.org/abs/2410.10323v1
"Sleep is known to be a key factor in emotional regulation and overall mental
health. In this study, we explore the integration of sleep measures from the
previous night into wearable-based mood recognition. To this end, we propose
NapTune, a novel prompt-tuning framework that utilizes sleep-related measures
as additional inputs to a frozen pre-trained wearable time-series encoder by
adding and training lightweight prompt parameters to each Transformer layer.
Through rigorous empirical evaluation, we demonstrate that the inclusion of
sleep data using NapTune not only improves mood recognition performance across
different wearable time-series namely ECG, PPG, and EDA, but also makes it more
sample-efficient. Our method demonstrates significant improvements over the
best baselines and unimodal variants. Furthermore, we analyze the impact of
adding sleep-related measures on recognizing different moods as well as the
influence of individual sleep-related measures.",http://arxiv.org/abs/2409.04723v1
"The premise of this working paper is based around agent-based simulation
models and how to go about creating them from given incomplete information.
Agent-based simulations are stochastic simulations that revolve around groups
of agents that each have their own characteristics and can make decisions. Such
simulations can be used to emulate real life situations and to create
hypothetical situations without the need for real-world testing prior. Here we
describe the development of an agent-based simulation model for studying future
digital mental health scenarios. An incomplete conceptual model has been used
as the basis for this development. To define differences in responses to
stimuli we employed fuzzy decision making logic. The model has been implemented
but not been used for structured experimentation yet. This is planned as our
next step.",http://arxiv.org/abs/1902.01642v1
"PhD students report a higher prevalence of mental illness symptoms than
highly educated individuals in the general population. This situation presents
a serious problem for universities. Thus, the knowledge about this phenomenon
is of great importance in decision-making. In this paper we use the Nature PhD
survey 2019 and estimate several binomial logistic regression models to analyze
the risk of interrupting doctoral studies. This risk is measured through the
desire of change in either the supervisor or the area of expertise, or the wish
of not pursue a PhD. Among the explanatory factors, we focus on the influence
of anxiety/depression, discrimination, and bullying. As control variables we
use demographic characteristics and others related with the doctoral program.
Insufficient contact time with supervisors, and exceeding time spent studying
-crossing the 50-h week barrier-, are risk factors of PhD studies interruption,
but the most decisive risk factor is poor mental health. Universities should
therefore foster an environment of well-being, which allows the development of
autonomy and resilience of their PhD students or, when necessary, which fosters
the development of conflict resolution skills.",http://arxiv.org/abs/2010.07039v1
"Depression is a common mental health issue that requires prompt diagnosis and
treatment. Despite the promise of social media data for depression detection,
the opacity of employed deep learning models hinders interpretability and
raises bias concerns. We address this challenge by introducing ProtoDep, a
novel, explainable framework for Twitter-based depression detection. ProtoDep
leverages prototype learning and the generative power of Large Language Models
to provide transparent explanations at three levels: (i) symptom-level
explanations for each tweet and user, (ii) case-based explanations comparing
the user to similar individuals, and (iii) transparent decision-making through
classification weights. Evaluated on five benchmark datasets, ProtoDep achieves
near state-of-the-art performance while learning meaningful prototypes. This
multi-faceted approach offers significant potential to enhance the reliability
and transparency of depression detection on social media, ultimately aiding
mental health professionals in delivering more informed care.",http://arxiv.org/abs/2407.21041v1
"Exploration of the physical environment is an indispensable precursor to data
acquisition and enables knowledge generation via analytical or direct trialing.
Artificial Intelligence lacks the exploratory capabilities of even the most
underdeveloped organisms, hindering its autonomy and adaptability. Supported by
cognitive psychology, this works links human behavior and artificial agents to
endorse self-development. In accordance with reported data, paradigms of
epistemic and achievement emotion are embedded to machine-learning methodology
contingent on their impact when decision making. A study is subsequently
designed to mirror previous human trials, which artificial agents are made to
undergo repeatedly towards convergence. Results demonstrate causality, learned
by the vast majority of agents, between their internal states and exploration
to match those reported for human counterparts. The ramifications of these
findings are pondered for both research into human cognition and betterment of
artificial intelligence.",http://arxiv.org/abs/2302.06615v1
"This review aims to contribute to the quest for artificial general
intelligence by examining neuroscience and cognitive psychology methods for
potential inspiration. Despite the impressive advancements achieved by deep
learning models in various domains, they still have shortcomings in abstract
reasoning and causal understanding. Such capabilities should be ultimately
integrated into artificial intelligence systems in order to surpass data-driven
limitations and support decision making in a way more similar to human
intelligence. This work is a vertical review that attempts a wide-ranging
exploration of brain function, spanning from lower-level biological neurons,
spiking neural networks, and neuronal ensembles to higher-level concepts such
as brain anatomy, vector symbolic architectures, cognitive and categorization
models, and cognitive architectures. The hope is that these concepts may offer
insights for solutions in artificial general intelligence.",http://arxiv.org/abs/2401.10904v1
"Global rates of mental health concerns are rising, and there is increasing
realization that existing models of mental health care will not adequately
expand to meet the demand. With the emergence of large language models (LLMs)
has come great optimism regarding their promise to create novel, large-scale
solutions to support mental health. Despite their nascence, LLMs have already
been applied to mental health related tasks. In this paper, we summarize the
extant literature on efforts to use LLMs to provide mental health education,
assessment, and intervention and highlight key opportunities for positive
impact in each area. We then highlight risks associated with LLMs' application
to mental health and encourage the adoption of strategies to mitigate these
risks. The urgent need for mental health support must be balanced with
responsible development, testing, and deployment of mental health LLMs. It is
especially critical to ensure that mental health LLMs are fine-tuned for mental
health, enhance mental health equity, and adhere to ethical standards and that
people, including those with lived experience with mental health concerns, are
involved in all stages from development through deployment. Prioritizing these
efforts will minimize potential harms to mental health and maximize the
likelihood that LLMs will positively impact mental health globally.",http://arxiv.org/abs/2403.14814v3
"Recently people started to understand that applications of the mathematical
formalism of quantum theory are not reduced to physics. Nowadays, this
formalism is widely used outside of quantum physics, in particular, in
cognition, psychology, decision making, information processing, especially
information retrieval. The latter is very promising. The aim of this brief
introductory review is to stimulate research in this exciting area of
information science. This paper is not aimed to present a complete review on
the state of art in quantum information retrieval.",http://arxiv.org/abs/2008.13541v1
"Cognitive psychology investigates perception, attention, memory, language,
problem-solving, decision-making, and reasoning. Kahneman's dual-system theory
elucidates the human decision-making process, distinguishing between the rapid,
intuitive System 1 and the deliberative, rational System 2. Recent advancements
have positioned large language Models (LLMs) as formidable tools nearing
human-level proficiency in various cognitive tasks. Nonetheless, the presence
of a dual-system framework analogous to human cognition in LLMs remains
unexplored. This study introduces the \textbf{CogniDual Framework for LLMs}
(CFLLMs), designed to assess whether LLMs can, through self-training, evolve
from deliberate deduction to intuitive responses, thereby emulating the human
process of acquiring and mastering new information. Our findings reveal the
cognitive mechanisms behind LLMs' response generation, enhancing our
understanding of their capabilities in cognitive psychology. Practically,
self-trained models can provide faster responses to certain queries, reducing
computational demands during inference.",http://arxiv.org/abs/2409.03381v2
"In recent years, quantum mechanics has been actively used in areas outside of
physics, such as psychology, sociology, theory of decision-making, game theory,
and others. In particular, quantum mechanics is used to explain the paradoxes
arising in cognitive psychology and decision making. Wang and Busemeyer
invented a quantum model and approach as well as non-parametric equality
(so-called QQ-equality), explaining the questions order effect. The primary
objective of this note is to test the possibility to expand the Wang-Busemeyer
model by considering questions which are mathematically represented by positive
operator valued measures. We found that, for such observables, the QQ-equality
can be violated. But, we also showed that, in principle, it is possible to
reduce expanded model to the original Wang-Busemeyer model by expanding the
context of the questions. This version of preprint is aimed to point out to
annoying miscalculation in version 1. This miscalculation might mislead a
reader who is not experienced in operating with POVMs. Otherwise the main line
of construction and reasoning presented in version 1 is right and it can be
easily completed by the reader on the basis of version 1 and the correction
remark in version 2.",http://arxiv.org/abs/1811.00045v2
"This research draws upon cognitive psychology and information systems studies
to anticipate user engagement and decision-making on digital platforms. By
employing natural language processing (NLP) techniques and insights from
cognitive bias research, we delve into user interactions with synonyms within
digital content. Our methodology synthesizes four cognitive
biasesRepresentativeness, Ease-of-use, Affect, and Distributioninto the READ
model. Through a comprehensive user survey, we assess the model's ability to
predict user engagement, discovering that synonyms that accurately represent
core ideas, are easy to understand, elicit emotional responses, and are
commonly encountered, promote greater user engagement. Crucially, our work
offers a fresh lens on human-computer interaction, digital behaviors, and
decision-making processes. Our results highlight the promise of cognitive
biases as potent indicators of user engagement, underscoring their significance
in designing effective digital content across fields like education and
marketing.",http://arxiv.org/abs/2307.14511v1
"Depression has been the leading cause of mental-health illness worldwide.
Major depressive disorder (MDD), is a common mental health disorder that
affects both psychologically as well as physically which could lead to loss of
lives. Due to the lack of diagnostic tests and subjectivity involved in
detecting depression, there is a growing interest in using behavioural cues to
automate depression diagnosis and stage prediction. The absence of labelled
behavioural datasets for such problems and the huge amount of variations
possible in behaviour makes the problem more challenging. This paper presents a
novel multi-level attention based network for multi-modal depression prediction
that fuses features from audio, video and text modalities while learning the
intra and inter modality relevance. The multi-level attention reinforces
overall learning by selecting the most influential features within each
modality for the decision making. We perform exhaustive experimentation to
create different regression models for audio, video and text modalities.
Several fusions models with different configurations are constructed to
understand the impact of each feature and modality. We outperform the current
baseline by 17.52% in terms of root mean squared error.",http://arxiv.org/abs/1909.01417v1
"Diverse cases regarding the impact, with its related factors, of the COVID-19
pandemic on mental health have been reported in previous studies. College
student groups have been frequently selected as the target population in
previous studies because they are easily affected by pandemics. In this study,
multivariable datasets were collected from 751 college students based on the
complex relationships between various mental health factors. We utilized
quantum annealing (QA)-based feature selection algorithms that were executed by
commercial D-Wave quantum computers to determine the changes in the relative
importance of the associated factors before and after the pandemic.
Multivariable linear regression (MLR) and XGBoost models were also applied to
validate the QA-based algorithms. Based on the experimental results, we confirm
that QA-based algorithms have comparable capabilities in factor analysis
research to the MLR models that have been widely used in previous studies.
Furthermore, the performance of the QA-based algorithms was validated through
the important factor results from the algorithms. Pandemic-related factors
(e.g., confidence in the social system) and psychological factors (e.g.,
decision-making in uncertain situations) were more important in post-pandemic
conditions. We believe that our study will serve as a reference for researchers
studying similar topics.",http://arxiv.org/abs/2310.00018v1
"Passively collected behavioral health data from ubiquitous sensors holds
significant promise to provide mental health professionals insights from
patient's daily lives; however, developing analysis tools to use this data in
clinical practice requires addressing challenges of generalization across
devices and weak or ambiguous correlations between the measured signals and an
individual's mental health. To address these challenges, we take a novel
approach that leverages large language models (LLMs) to synthesize clinically
useful insights from multi-sensor data. We develop chain of thought prompting
methods that use LLMs to generate reasoning about how trends in data such as
step count and sleep relate to conditions like depression and anxiety. We first
demonstrate binary depression classification with LLMs achieving accuracies of
61.1% which exceed the state of the art. While it is not robust for clinical
use, this leads us to our key finding: even more impactful and valued than
classification is a new human-AI collaboration approach in which clinician
experts interactively query these tools and combine their domain expertise and
context about the patient with AI generated reasoning to support clinical
decision-making. We find models like GPT-4 correctly reference numerical data
75% of the time, and clinician participants express strong interest in using
this approach to interpret self-tracking data.",http://arxiv.org/abs/2311.13063v3
"Bayesian nonparametric estimates of Australian mental health distributions
are obtained to assess how the mental health status of the population has
changed over time and to compare the mental health status of female/male and
indigenous/non-indigenous population subgroups. First- and second-order
stochastic dominance are used to compare distributions, with results presented
in terms of the posterior probability of dominance and the posterior
probability of no dominance. Our results suggest mental health has deteriorated
in recent years, that males mental health status is better than that of
females, and non-indigenous health status is better than that of the indigenous
population.",http://arxiv.org/abs/2106.08047v1
"Childhood Sexual Abuse (CSA) is a menace to society and has long-lasting
effects on the mental health of the survivors. From time to time CSA survivors
are haunted by various mental health issues in their lifetime. Proper care and
attention towards CSA survivors facing mental health issues can drastically
improve the mental health conditions of CSA survivors. Previous works
leveraging online social media (OSM) data for understanding mental health
issues haven't focused on mental health issues in individuals with CSA
background. Our work fills this gap by studying Reddit posts related to CSA to
understand their mental health issues. Mental health issues such as depression,
anxiety, and Post-Traumatic Stress Disorder (PTSD) are most commonly observed
in posts with CSA background. Observable differences exist between posts
related to mental health issues with and without CSA background. Keeping this
difference in mind, for identifying mental health issues in posts with CSA
exposure we develop a two-stage framework. The first stage involves classifying
posts with and without CSA background and the second stage involves recognizing
mental health issues in posts that are classified as belonging to CSA
background. The top model in the first stage is able to achieve accuracy and
f1-score (macro) of 96.26% and 96.24%. and in the second stage, the top model
reports hamming score of 67.09%. Content Warning: Reader discretion is
recommended as our study tackles topics such as child sexual abuse,
molestation, etc.",http://arxiv.org/abs/2306.10338v1
"Mental health stigma prevents many individuals from receiving the appropriate
care, and social psychology studies have shown that mental health tends to be
overlooked in men. In this work, we investigate gendered mental health stigma
in masked language models. In doing so, we operationalize mental health stigma
by developing a framework grounded in psychology research: we use clinical
psychology literature to curate prompts, then evaluate the models' propensity
to generate gendered words. We find that masked language models capture
societal stigma about gender in mental health: models are consistently more
likely to predict female subjects than male in sentences about having a mental
health condition (32% vs. 19%), and this disparity is exacerbated for sentences
that indicate treatment-seeking behavior. Furthermore, we find that different
models capture dimensions of stigma differently for men and women, associating
stereotypes like anger, blame, and pity more with women with mental health
conditions than with men. In showing the complex nuances of models' gendered
mental health stigma, we demonstrate that context and overlapping dimensions of
identity are important considerations when assessing computational models'
social biases.",http://arxiv.org/abs/2210.15144v2
"Probabilistic graphical models such as Bayesian Networks are one of the most
powerful structures known by the Computer Science community for deriving
probabilistic inferences. However, modern cognitive psychology has revealed
that human decisions could not follow the rules of classical probability
theory, because humans cannot process large amounts of data in order to make
judgements. Consequently, the inferences performed are based on limited data
coupled with several heuristics, leading to violations of the law of total
probability. This means that probabilistic graphical models based on classical
probability theory are too limited to fully simulate and explain various
aspects of human decision making.
  Quantum probability theory was developed in order to accommodate the
paradoxical findings that the classical theory could not explain. Recent
findings in cognitive psychology revealed that quantum probability can fully
describe human decisions in an elegant framework. Their findings suggest that,
before taking a decision, human thoughts are seen as superposed waves that can
interfere with each other, influencing the final decision.
  In this work, we propose a new Bayesian Network based on the psychological
findings of cognitive scientists. We made experiments with two very well known
Bayesian Networks from the literature. The results obtained revealed that the
quantum like Bayesian Network can affect drastically the probabilistic
inferences, specially when the levels of uncertainty of the network are very
high (no pieces of evidence observed). When the levels of uncertainty are very
low, then the proposed quantum like network collapses to its classical
counterpart.",http://arxiv.org/abs/1409.8470v1
"Software testing is a complex, intellectual activity based (at least) on
analysis, reasoning, decision making, abstraction and collaboration performed
in a highly demanding environment. Naturally, it uses and allocates multiple
cognitive resources in software testers. However, while a cognitive psychology
perspective is increasingly used in the general software engineering
literature, it has yet to find its place in software testing. To the best of
our knowledge, no theory of software testers' cognitive processes exists. Here,
we take the first step towards such a theory by presenting a cognitive model of
software testing based on how problem solving is conceptualized in cognitive
psychology. Our approach is to instantiate a general problem solving process
for the specific problem of creating test cases. We then propose an experiment
for testing our cognitive test design model. The experiment makes use of verbal
protocol analysis to understand the mechanisms by which human testers choose,
design, implement and evaluate test cases. An initial evaluation was then
performed with five software engineering master students as subjects. The
results support a problem solving-based model of test design for capturing
testers' cognitive processes.",http://arxiv.org/abs/2007.08927v3
"Several examples of Cyber-physical human systems (CPHS) include real-time
decisions from humans as a necessary building block for the successful
performance of the overall system. Many of these decision-making problems
necessitate an appropriate model of human behavior. Tools from Utility Theory
have been used successfully in several problems in transportation for resource
allocation and balance of supply and demand \citep{ben1985discrete}. More
recently, Prospect Theory has been demonstrated as a useful tool in behavioral
economics and cognitive psychology for deriving human behavioral models that
characterize their subjective decision-making in the presence of stochastic
uncertainties and risks, as an alternative to conventional Utility Theory
\citep{kahneman_prospect_2012}. These models will be described in this article.
Theoretical implications of Prospect Theory are also discussed. Examples will
be drawn from transportation use cases such as shared mobility to illustrate
these models as well as the distinctions between Utility Theory and Prospect
Theory.",http://arxiv.org/abs/2210.07322v1
"Large Language Models (LLMs) have gradually become the gateway for people to
acquire new knowledge. However, attackers can break the model's security
protection (""jail"") to access restricted information, which is called
""jailbreaking."" Previous studies have shown the weakness of current LLMs when
confronted with such jailbreaking attacks. Nevertheless, comprehension of the
intrinsic decision-making mechanism within the LLMs upon receipt of jailbreak
prompts is noticeably lacking. Our research provides a psychological
explanation of the jailbreak prompts. Drawing on cognitive consistency theory,
we argue that the key to jailbreak is guiding the LLM to achieve cognitive
coordination in an erroneous direction. Further, we propose an automatic
black-box jailbreaking method based on the Foot-in-the-Door (FITD) technique.
This method progressively induces the model to answer harmful questions via
multi-step incremental prompts. We instantiated a prototype system to evaluate
the jailbreaking effectiveness on 8 advanced LLMs, yielding an average success
rate of 83.9%. This study builds a psychological perspective on the explanatory
insights into the intrinsic decision-making logic of LLMs.",http://arxiv.org/abs/2402.15690v1
"More than 1 million students play high school American football annually, but
many health professionals have recently questioned its safety or called for its
ban. These concerns have been partially driven by reports of chronic traumatic
encephalopathy (CTE), increased risks of neurodegenerative disease, and
associations between concussion history and later-life cognitive impairment and
depression among retired professional football players.
  A recent observational study of a cohort of men who graduated from a
Wisconsin high school in 1957 found no statistically significant harmful
effects of playing high school football on a range of cognitive, psychological,
and socio-economic outcomes measured at ages 35, 54, 65, and 72. Unfortunately,
these findings may not generalize to younger populations, thanks to changes and
improvements in football helmet technology and training techniques. In
particular, these changes may have led to increased perceptions of safety but
ultimately more dangerous styles of play, characterized by the frequent
sub-concussive impacts thought to be associated with later-life neurological
decline.
  In this work, we replicate the methodology of that earlier matched
observational study using data from the National Longitudinal Study of
Adolescent to Adult Health (Add Health). These include adolescent and family
co-morbidities, academic experience, self-reported levels of general health and
physical activity, and the score on the Add Health Picture Vocabulary Test. Our
primary outcome is the CES-D score measured in 2008 when subjects were aged 24
-- 34 and settling into early adulthood. We also examine several secondary
outcomes related to physical and psychological health, including suicidality.
Our results can provide insight into the natural history of potential
football-related decline and dysfunction.",http://arxiv.org/abs/1808.03934v2
"Mental health challenges are thought to afflict around 10% of the global
population each year, with many going untreated due to stigma and limited
access to services. Here, we explore trends in words and phrases related to
mental health through a collection of 1- , 2-, and 3-grams parsed from a data
stream of roughly 10% of all English tweets since 2012. We examine temporal
dynamics of mental health language, finding that the popularity of the phrase
'mental health' increased by nearly two orders of magnitude between 2012 and
2018. We observe that mentions of 'mental health' spike annually and reliably
due to mental health awareness campaigns, as well as unpredictably in response
to mass shootings, celebrities dying by suicide, and popular fictional stories
portraying suicide. We find that the level of positivity of messages containing
'mental health', while stable through the growth period, has declined recently.
Finally, we use the ratio of original tweets to retweets to quantify the
fraction of appearances of mental health language due to social amplification.
Since 2015, mentions of mental health have become increasingly due to retweets,
suggesting that stigma associated with discussion of mental health on Twitter
has diminished with time.",http://arxiv.org/abs/2106.01481v1
"Mental health remains a significant challenge of public health worldwide.
With increasing popularity of online platforms, many use the platforms to share
their mental health conditions, express their feelings, and seek help from the
community and counselors. Some of these platforms, such as Reachout, are
dedicated forums where the users register to seek help. Others such as Reddit
provide subreddits where the users publicly but anonymously post their mental
health distress. Although posts are of varying length, it is beneficial to
provide a short, but informative summary for fast processing by the counselors.
To facilitate research in summarization of mental health online posts, we
introduce Mental Health Summarization dataset, MentSum, containing over 24k
carefully selected user posts from Reddit, along with their short user-written
summary (called TLDR) in English from 43 mental health subreddits. This
domain-specific dataset could be of interest not only for generating short
summaries on Reddit, but also for generating summaries of posts on the
dedicated mental health forums such as Reachout. We further evaluate both
extractive and abstractive state-of-the-art summarization baselines in terms of
Rouge scores, and finally conduct an in-depth human evaluation study of both
user-written and system-generated summaries, highlighting challenges in this
research.",http://arxiv.org/abs/2206.00856v1
"Despite the ever-strong demand for mental health care globally, access to
traditional mental health services remains severely limited expensive, and
stifled by stigma and systemic barriers. Thus, over the last few years, young
people are increasingly turning to content on video-sharing platforms (VSPs)
like TikTok and YouTube to help them navigate their mental health journey.
However, navigating towards trustworthy information relating to mental health
on these platforms is challenging, given the uncontrollable and unregulated
growth of dedicated mental health content and content creators catering to a
wide array of mental health conditions on these platforms. In this paper, we
attempt to define what constitutes as ""mental health misinformation"" through
examples. In addition, we also suggest some open questions to answer and
challenges to tackle regarding this important and timely research topic",http://arxiv.org/abs/2304.07417v1
"This chapter discusses the existing and future use of robotics and
intelligent sensing technology in mental health care. While the use of this
technology is nascent in mental health care, it represents a potentially useful
tool in the practitioner's toolbox. The goal of this chapter is to provide a
brief overview of the field, discuss the recent use of robotics technology in
mental health care practice, explore some of the design issues and ethical
issues of using robots in this space, and finally to explore the potential of
emerging technology.",http://arxiv.org/abs/1511.02281v1
"This research paper presents a meta-analysis of the multifaceted role of
technology in mental health. The pervasive influence of technology on daily
lives necessitates a deep understanding of its impact on mental health
services. This study synthesizes literature covering Behavioral Intervention
Technologies (BITs), digital mental health interventions during COVID-19, young
men's attitudes toward mental health technologies, technology-based
interventions for university students, and the applicability of mobile health
technologies for individuals with serious mental illnesses. BITs are recognized
for their potential to provide evidence-based interventions for mental health
conditions, especially anxiety disorders. The COVID-19 pandemic acted as a
catalyst for the adoption of digital mental health services, underscoring their
crucial role in providing accessible and quality care; however, their efficacy
needs to be reinforced by workforce training, high-quality evidence, and
digital equity. A nuanced understanding of young men's attitudes toward mental
health is imperative for devising effective online services. Technology-based
interventions for university students are promising, although variable in
effectiveness; their deployment must be evidence-based and tailored to
individual needs. Mobile health technologies, particularly activity tracking,
hold promise for individuals with serious mental illnesses. Collectively,
technology has immense potential to revolutionize mental health care. However,
the implementation must be evidence-based, ethical, and equitable, with
continued research focusing on experiences across diverse populations, ensuring
accessibility and efficacy for all.",http://arxiv.org/abs/2307.10513v2
"Effective surveillance on the long-term public health impact due to war and
terrorist attacks remain limited. Such health issues are commonly
under-reported, specifically for a large group of individuals. For this
purpose, efficient estimation of the size of the population under the risk of
physical and mental health hazards is of utmost necessity. In this context,
multiple system estimation is a potential strategy that has recently been
applied to quantify under-reported events allowing heterogeneity among the
individuals and dependence between the sources of information. To model such
complex phenomena, a novel trivariate Bernoulli model is developed, and an
estimation methodology using Monte Carlo based EM algorithm is proposed.
Simulation results show superiority of the performance of the proposed method
over existing competitors and robustness under model mis-specifications. The
method is applied to analyze real case studies on the Gulf War and 9/11
Terrorist Attack at World Trade Center, US. The results provide interesting
insights that can assist in effective decision making and policy formulation
for monitoring the health status of post-war survivors.",http://arxiv.org/abs/2208.11992v4
"Mental manipulation severely undermines mental wellness by covertly and
negatively distorting decision-making. While there is an increasing interest in
mental health care within the natural language processing community, progress
in tackling manipulation remains limited due to the complexity of detecting
subtle, covert tactics in conversations. In this paper, we propose Intent-Aware
Prompting (IAP), a novel approach for detecting mental manipulations using
large language models (LLMs), providing a deeper understanding of manipulative
tactics by capturing the underlying intents of participants. Experimental
results on the MentalManip dataset demonstrate superior effectiveness of IAP
against other advanced prompting strategies. Notably, our approach
substantially reduces false negatives, helping detect more instances of mental
manipulation with minimal misjudgment of positive cases. The code of this paper
is available at https://github.com/Anton-Jiayuan-MA/Manip-IAP.",http://arxiv.org/abs/2412.08414v1
"Predictive machine learning (ML) models are computational innovations that
can enhance medical decision-making, including aiding in determining optimal
timing for discharging patients. However, societal biases can be encoded into
such models, raising concerns about inadvertently affecting health outcomes for
disadvantaged groups. This issue is particularly pressing in the context of
substance use disorder (SUD) treatment, where biases in predictive models could
significantly impact the recovery of highly vulnerable patients. In this study,
we focus on the development and assessment of ML models designed to predict the
length of stay (LOS) for both inpatients (i.e., residential) and outpatients
undergoing SUD treatment. We utilize the Treatment Episode Data Set for
Discharges (TEDS-D) from the Substance Abuse and Mental Health Services
Administration (SAMHSA). Through the lenses of distributive justice and
socio-relational fairness, we assess our models for bias across variables
related to demographics (e.g., race) as well as medical (e.g., diagnosis) and
financial conditions (e.g., insurance). We find that race, US geographic
region, type of substance used, diagnosis, and payment source for treatment are
primary indicators of unfairness. From a policy perspective, we provide bias
mitigation strategies to achieve fair outcomes. We discuss the implications of
these findings for medical decision-making and health equity. We ultimately
seek to contribute to the innovation and policy-making literature by seeking to
advance the broader objectives of social justice when applying computational
innovations in health care.",http://arxiv.org/abs/2412.05832v1
"Mental health is a significant and growing public health concern. As language
usage can be leveraged to obtain crucial insights into mental health
conditions, there is a need for large-scale, labeled, mental health-related
datasets of users who have been diagnosed with one or more of such conditions.
In this paper, we investigate the creation of high-precision patterns to
identify self-reported diagnoses of nine different mental health conditions,
and obtain high-quality labeled data without the need for manual labelling. We
introduce the SMHD (Self-reported Mental Health Diagnoses) dataset and make it
available. SMHD is a novel large dataset of social media posts from users with
one or multiple mental health conditions along with matched control users. We
examine distinctions in users' language, as measured by linguistic and
psychological variables. We further explore text classification methods to
identify individuals with mental conditions through their language.",http://arxiv.org/abs/1806.05258v2
"Background: Mental health problems are prevalent in college students. The
COVID-19 pandemic exacerbated the problems, and created a surge in the
popularity of telehealth and mobile health solutions. Despite that mobile
health is a promising approach to help students with mental health needs, few
studies exist in investigating key features students need in a mental health
self-management tool. Objective: The objective of our study was to identified
key requirements and features for the design of a student-centered mental
health self-management tool. Methods: An interview study was first conducted to
understand college students' needs and preferences on a mental health
self-management tool. Functional information requirement analysis was then
conducted to translate the needs into design implications. Results: A total of
153 university students were recruited for the semi-structured interview. The
participants mentioned several features including coping techniques, artificial
intelligence, time management, tracking, and communication with others.
Participant's preferences on usability and privacy settings were also
collected. The desired functions were analyzed and turned into design-agnostic
information requirements. Conclusions: This study documents findings from
interviews with university students to understand their needs and preferences
for a tool to help with self-management of mental health.",http://arxiv.org/abs/2206.02960v1
"Self-disclosed mental health diagnoses, which serve as ground truth
annotations of mental health status in the absence of clinical measures,
underpin the conclusions behind most computational studies of mental health
language from the last decade. However, psychiatric conditions are dynamic; a
prior depression diagnosis may no longer be indicative of an individual's
mental health, either due to treatment or other mitigating factors. We ask: to
what extent are self-disclosures of mental health diagnoses actually relevant
over time? We analyze recent activity from individuals who disclosed a
depression diagnosis on social media over five years ago and, in turn, acquire
a new understanding of how presentations of mental health status on social
media manifest longitudinally. We also provide expanded evidence for the
presence of personality-related biases in datasets curated using self-disclosed
diagnoses. Our findings motivate three practical recommendations for improving
mental health datasets curated using self-disclosed diagnoses: 1) Annotate
diagnosis dates and psychiatric comorbidities; 2) Sample control groups using
propensity score matching; 3) Identify and remove spurious correlations
introduced by selection bias.",http://arxiv.org/abs/2206.11155v1
"Mental health disorders are particularly prevalent among those in the
criminal justice system and may be a contributing factor in recidivism. Using
North Carolina court cases from 1994 to 2009, this paper evaluates how mandated
mental health treatment as a term of probation impacts the likelihood that
individuals return to the criminal justice system. I use random variation in
judge assignment to compare those who were required to seek weekly mental
health counseling to those who were not. The main findings are that being
assigned to seek mental health treatment decreases the likelihood of three-year
recidivism by about 12 percentage points, or 36 percent. This effect persists
over time, and is similar among various types of individuals on probation. In
addition, I show that mental health treatment operates distinctly from drug
addiction interventions in a multiple-treatment framework. I provide evidence
that mental health treatment's longer-term effectiveness is strongest among
more financially-advantaged probationers, consistent with this setting, in
which the cost of mandated treatment is shouldered by offenders. Finally,
conservative calculations result in a 5:1 benefit-to-cost ratio which suggests
that the treatment-induced decrease in future crime would be more than
sufficient to offset the costs of treatment.",http://arxiv.org/abs/2212.06736v2
"Long counseling Text Generation for Mental health support (LTGM), an
innovative and challenging task, aims to provide help-seekers with mental
health support through a comprehensive and more acceptable response. The
combination of chain-of-thought (CoT) prompting and Large Language Models
(LLMs) is employed and get the SOTA performance on various NLP tasks,
especially on text generation tasks. Zero-shot CoT prompting is one of the most
common methods in CoT prompting. However, in the LTGM task, Zero-shot CoT
prompting can not simulate a counselor or provide personalized strategies
without effective mental health counseling strategy prompts. To tackle this
challenge, we propose a zero-shot Dynamic Strategy Chain (DSC) prompting
method. Firstly, we utilize GPT2 to learn the responses written by mental
health counselors and dynamically generate mental health counseling strategies
tailored to the help-seekers' needs. Secondly, the Zero-shot DSC prompting is
constructed according to mental health counseling strategies and the
help-seekers' post. Finally, the Zero-shot DSC prompting is employed to guide
LLMs in generating more human-like responses for the help-seekers. Both
automatic and manual evaluations demonstrate that Zero-shot DSC prompting can
deliver more human-like responses than CoT prompting methods on LTGM tasks.",http://arxiv.org/abs/2308.10444v1
"Housing instability is a widespread phenomenon in the United States. In
combination with other social determinants of health, housing instability
affects children's overall health and development. Drawing on data from the
2022 National Survey of Children's Health, we employed multiple logistic
regression models to understand how sociodemographic factors, especially
housing instability, affect mental health outcomes and treatment access for
youth aged 6-17 years. Our results show that youth facing housing instability
have a higher likelihood of experiencing anxiety (OR: 1.42, p<0.001) and
depression (OR: 1.57, p<0.001). Furthermore, youth experiencing both mental
health conditions and housing instability are significantly less likely to
receive mental health services in the past year, indicating the substantial
barriers they face in accessing mental health care. Based on our findings, we
highlight opportunities for digital mental health interventions to provide
children experiencing housing instability with more accessible and consistent
mental health services.",http://arxiv.org/abs/2409.06011v2
"Large Language Models (LLMs) are increasingly integrated into various medical
fields, including mental health support systems. However, there is a gap in
research regarding the effectiveness of LLMs in non-English mental health
support applications. To address this problem, we present a novel multilingual
adaptation of widely-used mental health datasets, translated from English into
six languages (Greek, Turkish, French, Portuguese, German, and Finnish). This
dataset enables a comprehensive evaluation of LLM performance in detecting
mental health conditions and assessing their severity across multiple
languages. By experimenting with GPT and Llama, we observe considerable
variability in performance across languages, despite being evaluated on the
same translated dataset. This inconsistency underscores the complexities
inherent in multilingual mental health support, where language-specific nuances
and mental health data coverage can affect the accuracy of the models. Through
comprehensive error analysis, we emphasize the risks of relying exclusively on
large language models (LLMs) in medical settings (e.g., their potential to
contribute to misdiagnoses). Moreover, our proposed approach offers significant
cost savings for multilingual tasks, presenting a major advantage for
broad-scale implementation.",http://arxiv.org/abs/2409.17397v1
"Large language models (LLMs) are increasingly used in medical fields. In
mental health support, the early identification of linguistic markers
associated with mental health conditions can provide valuable support to mental
health professionals, and reduce long waiting times for patients. Despite the
benefits of LLMs for mental health support, there is limited research on their
application in mental health systems for languages other than English. Our
study addresses this gap by focusing on the detection of depression severity in
Greek through user-generated posts which are automatically translated from
English. Our results show that GPT3.5-turbo is not very successful in
identifying the severity of depression in English, and it has a varying
performance in Greek as well. Our study underscores the necessity for further
research, especially in languages with less resources. Also, careful
implementation is necessary to ensure that LLMs are used effectively in mental
health platforms, and human supervision remains crucial to avoid misdiagnosis.",http://arxiv.org/abs/2410.12985v1
"Behavioral research can provide important insights for SE practices. But in
performing it, many studies of SE are committing a normative fallacy - they
misappropriate normative and prescriptive theories for descriptive purposes.
The evidence from reviews of empirical studies of decision making in SE
suggests that the normative fallacy may is common. This article draws on
cognitive psychology and behavioral economics to explains this fallacy. Because
data collection is framed by narrow and empirically invalid theories, flawed
assumptions baked into those theories lead to misleading interpretations of
observed behaviors and ultimately, to invalid conclusions and flawed
recommendations. Researchers should be careful not to rely solely on
engineering methods to explain what people do when they do engineering.
Instead, insist that descriptive research be based on validated descriptive
theories, listen carefully to skilled practitioners, and only rely on validated
findings to prescribe what they should do.",http://arxiv.org/abs/2005.03084v1
"With advancement in computer science research on artificial intelligence and
in cognitive psychology research on human learning and performance, the next
generation of computer-based tutoring systems moved beyond the simple
presentation of pages of text or graphics. These new intelligent tutoring
systems (ITSs) called cognitive tutors; incorporated model-tracing technology
which is a cognitive model of student problem solving that captures students
multiple strategies and common misconceptions. Such Intelligent tutoring
systems or Knowledge Based Tutoring Systems can guide learners to progress in
the learning process at their best. This paper deals with the review of various
Intelligent tutoring systems using Bayesian Networks and how Bayesian Networks
can be used for efficient decision making.",http://arxiv.org/abs/1302.7081v1
"Large language models are powerful systems that excel at many tasks, ranging
from translation to mathematical reasoning. Yet, at the same time, these models
often show unhuman-like characteristics. In the present paper, we address this
gap and ask whether large language models can be turned into cognitive models.
We find that -- after finetuning them on data from psychological experiments --
these models offer accurate representations of human behavior, even
outperforming traditional cognitive models in two decision-making domains. In
addition, we show that their representations contain the information necessary
to model behavior on the level of individual subjects. Finally, we demonstrate
that finetuning on multiple tasks enables large language models to predict
human behavior in a previously unseen task. Taken together, these results
suggest that large, pre-trained models can be adapted to become generalist
cognitive models, thereby opening up new research directions that could
transform cognitive psychology and the behavioral sciences as a whole.",http://arxiv.org/abs/2306.03917v1
"Concept learning is a fundamental aspect of human cognition and plays a
critical role in mental processes such as categorization, reasoning, memory,
and decision-making. Researchers across various disciplines have shown
consistent interest in the process of concept acquisition in individuals. To
elucidate the mechanisms involved in human concept learning, this study
examines the findings from computational neuroscience and cognitive psychology.
These findings indicate that the brain's representation of concepts relies on
two essential components: multisensory representation and text-derived
representation. These two types of representations are coordinated by a
semantic control system, ultimately leading to the acquisition of concepts.
Drawing inspiration from this mechanism, the study develops a human-like
computational model for concept learning based on spiking neural networks. By
effectively addressing the challenges posed by diverse sources and imbalanced
dimensionality of the two forms of concept representations, the study
successfully attains human-like concept representations. Tests involving
similar concepts demonstrate that our model, which mimics the way humans learn
concepts, yields representations that closely align with human cognition.",http://arxiv.org/abs/2401.06471v1
"Mental health disorders affect a large number of people, leading to many
lives being lost every year. These disorders affect struggling individuals and
businesses whose productivity decreases due to days of lost work or lower
employee performance. Recent studies provide alarming numbers of individuals
who suffer from mental health disorders, e.g., depression and anxiety, in
particular contexts, such as academia. In the context of the software industry,
there are limited studies that aim to understand the presence of mental health
disorders and the characteristics of jobs in this context that can be triggers
for the deterioration of the mental health of software professionals. In this
paper, we present the results of a survey with 500 software professionals. We
investigate different aspects of their mental health and the characteristics of
their work to identify possible triggers of mental health deterioration. Our
results provide the first evidence that mental health is a critical issue to be
addressed in the software industry, as well as raise the direction of changes
that can be done in this context to improve the mental health of software
professionals.",http://arxiv.org/abs/2309.17140v1
"Cumulative Prospect Theory (CPT) is a modeling tool widely used in behavioral
economics and cognitive psychology that captures subjective decision making of
individuals under risk or uncertainty. In this paper, we propose a dynamic
pricing strategy for Shared Mobility on Demand Services (SMoDSs) using a
passenger behavioral model based on CPT. This dynamic pricing strategy together
with dynamic routing via a constrained optimization algorithm that we have
developed earlier, provide a complete solution customized for SMoDS of
multi-passenger transportation. The basic principles of CPT and the derivation
of the passenger behavioral model in the SMoDS context are described in detail.
The implications of CPT on dynamic pricing of the SMoDS are delineated using
computational experiments involving passenger preferences. These implications
include interpretation of the classic fourfold pattern of risk attitudes,
strong risk aversion over mixed prospects, and behavioral preferences of self
reference. Overall, it is argued that the use of the CPT framework corresponds
to a crucial building block in designing socio-technical systems by allowing
quantification of subjective decision making under risk or uncertainty that is
perceived to be otherwise qualitative.",http://arxiv.org/abs/1904.04824v2
"Machine learning (ML) algorithms are gaining increased importance in many
academic and industrial applications, and such algorithms are, accordingly,
becoming common components in computer science curricula. Learning ML is
challenging not only due to its complex mathematical and algorithmic aspects,
but also due to a) the complexity of using correctly these algorithms in the
context of real-life situations and b) the understanding of related social and
ethical issues. Cognitive biases are phenomena of the human brain that may
cause erroneous perceptions and irrational decision-making processes. As such,
they have been researched thoroughly in the context of cognitive psychology and
decision making; they do, however, have important implications for computer
science education as well. One well-known cognitive bias, first described by
Kahneman and Tversky, is the base rate neglect bias, according to which humans
fail to consider the base rate of the underlying phenomena when evaluating
conditional probabilities. In this paper, we explore the expression of the base
rate neglect bias in ML education. Specifically, we show that about one third
of students in an Introduction to ML course, from varied backgrounds (computer
science students and teachers, data science, engineering, social science and
digital humanities), fail to correctly evaluate ML algorithm performance due to
the base rate neglect bias. This failure rate should alert educators and
promote the development of new pedagogical methods for teaching ML algorithm
performance.",http://arxiv.org/abs/2209.08312v2
"Anonymity in social media platforms keeps users hidden behind a keyboard.
This absolves users of responsibility, allowing them to engage in online rage,
hate speech, and other text-based toxicity that harms online well-being. Recent
research in the field of Digital Emotion Regulation (DER) has revealed that
indulgence in online toxicity can be a result of ineffective emotional
regulation (ER). This, we believe, can be reduced by educating users about the
consequences of their actions. Prior DER research has primarily focused on
exploring digital emotion regulation practises, identifying emotion regulation
using multimodal sensors, and encouraging users to act responsibly in online
conversations. While these studies provide valuable insights into how users
consciously utilise digital media for emotion regulation, they do not capture
the contextual dynamics of emotion regulation online. Through interaction
design, this work provides an intervention for the delivery of ER support. It
introduces a novel technique for identifying the need for emotional regulation
in online conversations and delivering information to users in a way that
integrates didactic learning into their daily life. By fostering
self-reflection in periods of intensified emotional expression, we present a
graph-based framework for on-the-spot emotion regulation support in online
conversations. Our findings suggest that using this model in a conversation can
help identify its influential threads/nodes to locate where toxicity is
concentrated and help reduce it by up to 12\%. This is the first study in the
field of DER that focuses on learning transfer by inducing self-reflection and
implicit emotion regulation.",http://arxiv.org/abs/2303.00884v1
"This paper investigates the mental health penalty for women after childbirth
in Switzerland. Leveraging insurance data, we employ a staggered
difference-in-difference research design. The findings reveal a substantial
mental health penalty for women following the birth of their first child.
Approximately four years after childbirth, there is a one percentage point
(p.p.) increase in antidepressant prescriptions, representing a 50% increase
compared to pre-birth levels. This increase rises to 1.7 p.p. (a 70% increase)
six years postpartum. The mental health penalty is likely not only a direct
consequence of giving birth but also a consequence of the changed life
circumstances and time constraints that accompany it, as the penalty is rising
over time and is higher for women who are employed before childbirth.",http://arxiv.org/abs/2410.20861v1
"Many people struggling with mental health issues are unable to access
adequate care due to high costs and a shortage of mental health professionals,
leading to a global mental health crisis. Online mental health communities can
help mitigate this crisis by offering a scalable, easily accessible alternative
to in-person sessions with therapists or support groups. However, people
seeking emotional or psychological support online may be especially vulnerable
to the kinds of antisocial behavior that sometimes occur in online discussions.
Moderation can improve online discourse quality, but we lack an understanding
of its effects on online mental health conversations. In this work, we
leveraged a natural experiment, occurring across 200,000 messages from 7,000
online mental health conversations, to evaluate the effects of moderation on
online mental health discussions. We found that participation in group mental
health discussions led to improvements in psychological perspective, and that
these improvements were larger in moderated conversations. The presence of a
moderator increased user engagement, encouraged users to discuss negative
emotions more candidly, and dramatically reduced bad behavior among chat
participants. Moderation also encouraged stronger linguistic coordination,
which is indicative of trust building. In addition, moderators who remained
active in conversations were especially successful in keeping conversations on
topic. Our findings suggest that moderation can serve as a valuable tool to
improve the efficacy and safety of online mental health conversations. Based on
these findings, we discuss implications and trade-offs involved in designing
effective online spaces for mental health support.",http://arxiv.org/abs/2005.09225v7
"Mental illnesses adversely affect a significant proportion of the population
worldwide. However, the methods traditionally used for estimating and
characterizing the prevalence of mental health conditions are time-consuming
and expensive. Consequently, best-available estimates concerning the prevalence
of mental health conditions are often years out of date. Automated approaches
to supplement these survey methods with broad, aggregated information derived
from social media content provides a potential means for near real-time
estimates at scale. These may, in turn, provide grist for supporting,
evaluating and iteratively improving upon public health programs and
interventions.
  We propose a novel model for automated mental health status quantification
that incorporates user embeddings. This builds upon recent work exploring
representation learning methods that induce embeddings by leveraging social
media post histories. Such embeddings capture latent characteristics of
individuals (e.g., political leanings) and encode a soft notion of homophily.
In this paper, we investigate whether user embeddings learned from twitter post
histories encode information that correlates with mental health statuses. To
this end, we estimated user embeddings for a set of users known to be affected
by depression and post-traumatic stress disorder (PTSD), and for a set of
demographically matched `control' users. We then evaluated these embeddings
with respect to: (i) their ability to capture homophilic relations with respect
to mental health status; and (ii) the performance of downstream mental health
prediction models based on these features. Our experimental results demonstrate
that the user embeddings capture similarities between users with respect to
mental conditions, and are predictive of mental health.",http://arxiv.org/abs/1705.00335v1
"The rapid evolution of Large Language Models (LLMs) offers promising
potential to alleviate the global scarcity of mental health professionals.
However, LLMs' alignment with essential mental health counseling competencies
remains understudied. We introduce CounselingBench, a novel NCMHCE-based
benchmark evaluating LLMs across five key mental health counseling
competencies. Testing 22 general-purpose and medical-finetuned LLMs, we find
frontier models exceed minimum thresholds but fall short of expert-level
performance, with significant variations: they excel in Intake, Assessment &
Diagnosis yet struggle with Core Counseling Attributes and Professional
Practice & Ethics. Medical LLMs surprisingly underperform generalist models
accuracy-wise, while at the same time producing slightly higher-quality
justifications but making more context-related errors. Our findings highlight
the complexities of developing AI systems for mental health counseling,
particularly for competencies requiring empathy and contextual understanding.
We found that frontier LLMs perform at a level exceeding the minimal required
level of aptitude for all key mental health counseling competencies, but fall
short of expert-level performance, and that current medical LLMs do not
significantly improve upon generalist models in mental health counseling
competencies. This underscores the critical need for specialized, mental health
counseling-specific fine-tuned LLMs that rigorously aligns with core
competencies combined with appropriate human supervision before any responsible
real-world deployment can be considered.",http://arxiv.org/abs/2410.22446v1
"Self-reported diagnosis statements have been widely employed in studying
language related to mental health in social media. However, existing research
has largely ignored the temporality of mental health diagnoses. In this work,
we introduce RSDD-Time: a new dataset of 598 manually annotated self-reported
depression diagnosis posts from Reddit that include temporal information about
the diagnosis. Annotations include whether a mental health condition is present
and how recently the diagnosis happened. Furthermore, we include exact temporal
spans that relate to the date of diagnosis. This information is valuable for
various computational methods to examine mental health through social media
because one's mental health state is not static. We also test several baseline
classification and extraction approaches, which suggest that extracting
temporal information from self-reported diagnosis statements is challenging.",http://arxiv.org/abs/1806.07916v1
"The spread of the novel coronavirus disease caused schools in Japan to close
to cope with the pandemic. In response to this, parents of students were
obliged to care for their children during the daytime when they were usually at
school. Does the increase in burden of childcare influence parents mental
health? Based on short panel data from mid-March to mid-April 2020, we explored
how school closures influenced the mental health of parents with school-aged
children. Using the fixed effects model, we found that school closures lead to
students mothers suffering from worse mental health than other females, while
the fathers mental health did not differ from other males. This tendency was
only observed for less educated mothers who had children attending primary
school, but not those attending junior high school. The contribution of this
paper is to show that school closures increased the inequality of mental health
between genders and the educational background of parents.",http://arxiv.org/abs/2101.08476v1
"Previous researches on dialogue system assessment usually focus on the
quality evaluation (e.g. fluency, relevance, etc) of responses generated by the
chatbots, which are local and technical metrics. For a chatbot which responds
to millions of online users including minors, we argue that it should have a
healthy mental tendency in order to avoid the negative psychological impact on
them. In this paper, we establish several mental health assessment dimensions
for chatbots (depression, anxiety, alcohol addiction, empathy) and introduce
the questionnaire-based mental health assessment methods. We conduct
assessments on some well-known open-domain chatbots and find that there are
severe mental health issues for all these chatbots. We consider that it is due
to the neglect of the mental health risks during the dataset building and the
model training procedures. We expect to attract researchers' attention to the
serious mental health problems of chatbots and improve the chatbots' ability in
positive emotional interaction.",http://arxiv.org/abs/2201.05382v1
"Mobile mental health applications are seen as a promising way to fulfill the
growing need for mental health care. Although there are more than ten thousand
mental health apps available on app marketplaces, such as Google Play and Apple
App Store, many of them are not evidence-based, or have been minimally
evaluated or regulated. The real-life experience and concerns of the app users
are largely unknown. To address this knowledge gap, we analyzed 2159 user
reviews from 117 Android apps and 2764 user reviews from 76 iOS apps. Our
findings include the critiques around inconsistent moderation standards and
lack of transparency. App-embedded social features and chatbots were criticized
for providing little support during crises. We provide research and design
implications for future mental health app developers, discuss the necessity of
developing a comprehensive and centralized app development guideline, and the
opportunities of incorporating existing AI technology in mental health
chatbots.",http://arxiv.org/abs/2209.07796v1
"Pretrained language models have been used in various natural language
processing applications. In the mental health domain, domain-specific language
models are pretrained and released, which facilitates the early detection of
mental health conditions. Social posts, e.g., on Reddit, are usually long
documents. However, there are no domain-specific pretrained models for
long-sequence modeling in the mental health domain. This paper conducts
domain-specific continued pretraining to capture the long context for mental
health. Specifically, we train and release MentalXLNet and MentalLongformer
based on XLNet and Longformer. We evaluate the mental health classification
performance and the long-range ability of these two domain-specific pretrained
models. Our models are released in HuggingFace.",http://arxiv.org/abs/2304.10447v1
"Evaluating Large Language Models (LLMs) in the mental health domain poses
distinct challenged from other domains, given the subtle and highly subjective
nature of symptoms that exhibit significant variability among individuals. This
paper presents PsyEval, the first comprehensive suite of mental health-related
tasks for evaluating LLMs. PsyEval encompasses five sub-tasks that evaluate
three critical dimensions of mental health. This comprehensive framework is
designed to thoroughly assess the unique challenges and intricacies of mental
health-related tasks, making PsyEval a highly specialized and valuable tool for
evaluating LLM performance in this domain. We evaluate twelve advanced LLMs
using PsyEval. Experiment results not only demonstrate significant room for
improvement in current LLMs concerning mental health but also unveil potential
directions for future model optimization.",http://arxiv.org/abs/2311.09189v2
"In order to uncover users' attitudes towards ChatGPT in mental health, this
study examines public opinions about ChatGPT in mental health discussions on
Reddit. Researchers used the bert-base-multilingual-uncased-sentiment
techniques for sentiment analysis and the BERTopic model for topic modeling. It
was found that overall, negative sentiments prevail, followed by positive ones,
with neutral sentiments being the least common. The prevalence of negative
emotions has increased over time. Negative emotions encompass discussions on
ChatGPT providing bad mental health advice, debates on machine vs. human value,
the fear of AI, and concerns about Universal Basic Income (UBI). In contrast,
positive emotions highlight ChatGPT's effectiveness in counseling, with
mentions of keywords like ""time"" and ""wallet."" Neutral discussions center
around private data concerns. These findings shed light on public attitudes
toward ChatGPT in mental health, potentially contributing to the development of
trustworthy AI in mental health from the public perspective.",http://arxiv.org/abs/2311.15800v1
"People experiencing severe distress increasingly use Large Language Model
(LLM) chatbots as mental health support tools. Discussions on social media have
described how engagements were lifesaving for some, but evidence suggests that
general-purpose LLM chatbots also have notable risks that could endanger the
welfare of users if not designed responsibly. In this study, we investigate the
lived experiences of people who have used LLM chatbots for mental health
support. We build on interviews with 21 individuals from globally diverse
backgrounds to analyze how users create unique support roles for their
chatbots, fill in gaps in everyday care, and navigate associated cultural
limitations when seeking support from chatbots. We ground our analysis in
psychotherapy literature around effective support, and introduce the concept of
therapeutic alignment, or aligning AI with therapeutic values for mental health
contexts. Our study offers recommendations for how designers can approach the
ethical and effective use of LLM chatbots and other AI mental health support
tools in mental health care.",http://arxiv.org/abs/2401.14362v2
"We introduce a multi-layer perceptron (MLP) called the COVID-19 Depression
and Anxiety Predictor (CoDAP) to predict mental health trends, particularly
anxiety and depression, during the COVID-19 pandemic. Our method utilizes a
comprehensive dataset, which tracked mental health symptoms weekly over ten
weeks during the initial COVID-19 wave (April to June 2020) in a diverse cohort
of U.S. adults. This period, characterized by a surge in mental health symptoms
and conditions, offers a critical context for our analysis. Our focus was to
extract and analyze patterns of anxiety and depression through a unique lens of
qualitative individual attributes using CoDAP. This model not only predicts
patterns of anxiety and depression during the pandemic but also unveils key
insights into the interplay of demographic factors, behavioral changes, and
social determinants of mental health. These findings contribute to a more
nuanced understanding of the complexity of mental health issues in times of
global health crises, potentially guiding future early interventions.",http://arxiv.org/abs/2403.06033v1
"LGBTQ+ community face disproportionate mental health challenges, including
higher rates of depression, anxiety, and suicidal ideation. Research has shown
that LGBTQ+ people have been using large language model-based chatbots, such as
ChatGPT, for their mental health needs. Despite the potential for immediate
support and anonymity these chatbots offer, concerns regarding their capacity
to provide empathetic, accurate, and affirming responses remain. In response to
these challenges, we propose a framework for evaluating the affirmativeness of
LLMs based on principles of affirmative therapy, emphasizing the need for
attitudes, knowledge, and actions that support and validate LGBTQ+ experiences.
We propose a combination of qualitative and quantitative analyses, hoping to
establish benchmarks for ""Affirmative AI,"" ensuring that LLM-based chatbots can
provide safe, supportive, and effective mental health support to LGBTQ+
individuals. We benchmark LLM affirmativeness not as a mental health solution
for LGBTQ+ individuals or to claim it resolves their mental health issues, as
we highlight the need to consider complex discrimination in the LGBTQ+
community when designing technological aids. Our goal is to evaluate LLMs for
LGBTQ+ mental health support since many in the community already use them,
aiming to identify potential harms of using general-purpose LLMs in this
context.",http://arxiv.org/abs/2405.04652v1
"The application of machine learning (ML) in detecting, diagnosing, and
treating mental health disorders is garnering increasing attention.
Traditionally, research has focused on single modalities, such as text from
clinical notes, audio from speech samples, or video of interaction patterns.
Recently, multimodal ML, which combines information from multiple modalities,
has demonstrated significant promise in offering novel insights into human
behavior patterns and recognizing mental health symptoms and risk factors.
Despite its potential, multimodal ML in mental health remains an emerging
field, facing several complex challenges before practical applications can be
effectively developed. This survey provides a comprehensive overview of the
data availability and current state-of-the-art multimodal ML applications for
mental health. It discusses key challenges that must be addressed to advance
the field. The insights from this survey aim to deepen the understanding of the
potential and limitations of multimodal ML in mental health, guiding future
research and development in this evolving domain.",http://arxiv.org/abs/2407.16804v1
"Non-invasive methods for diagnosing mental health conditions, such as speech
analysis, offer promising potential in modern medicine. Recent advancements in
machine learning, particularly speech foundation models, have shown significant
promise in detecting mental health states by capturing diverse features. This
study investigates which pretext tasks in these models best transfer to mental
health detection and examines how different model layers encode features
relevant to mental health conditions. We also probed the optimal length of
audio segments and the best pooling strategies to improve detection accuracy.
Using the Callyope-GP and Androids datasets, we evaluated the models'
effectiveness across different languages and speech tasks, aiming to enhance
the generalizability of speech-based mental health diagnostics. Our approach
achieved SOTA scores in depression detection on the Androids dataset.",http://arxiv.org/abs/2409.19042v1
"Access to mental health support remains limited, particularly in marginalized
communities where structural and cultural barriers hinder timely care. This
paper explores the potential of AI-enabled chatbots as a scalable solution,
focusing on advanced large language models (LLMs)-GPT v4, Mistral Large, and
LLama V3.1-and assessing their ability to deliver empathetic, meaningful
responses in mental health contexts. While these models show promise in
generating structured responses, they fall short in replicating the emotional
depth and adaptability of human therapists. Additionally, trustworthiness,
bias, and privacy challenges persist due to unreliable datasets and limited
collaboration with mental health professionals. To address these limitations,
we propose a federated learning framework that ensures data privacy, reduces
bias, and integrates continuous validation from clinicians to enhance response
quality. This approach aims to develop a secure, evidence-based AI chatbot
capable of offering trustworthy, empathetic, and bias-reduced mental health
support, advancing AI's role in digital mental health care.",http://arxiv.org/abs/2410.02783v1
"Mental health issues significantly impact individuals' daily lives, yet many
do not receive the help they need even with available online resources. This
study aims to provide accessible, stigma-free, personalized, and real-time
mental health support through cutting-edge AI technologies. It makes the
following contributions: (1) Conducting an extensive survey of recent mental
health support methods to identify prevalent functionalities and unmet needs.
(2) Introducing SouLLMate, an adaptive LLM-driven system that integrates LLM
technologies, Chain, Retrieval-Augmented Generation (RAG), prompt engineering,
and domain knowledge. This system offers advanced features such as Suicide Risk
Detection and Proactive Guidance Dialogue, and utilizes RAG for personalized
profile uploads and Conversational Information Extraction. (3) Developing novel
evaluation approaches to assess preliminary assessments and suicide risk
detection, utilizing annotated real-life interview data and professionally
labeled datasets indicating suicide tendencies. (4) Proposing Key Indicator
Summarization (KIS) and Proactive Questioning Strategy (PQS) methods to enhance
model performance and usability through context-sensitive response adjustments
and semantic coherence evaluations. This study contributes to advancing mental
health support technologies, potentially improving the accessibility and
effectiveness of mental health care globally.",http://arxiv.org/abs/2410.11859v1
"Student mental health is a sensitive issue that necessitates special
attention. A primary concern is the student-to-counselor ratio, which surpasses
the recommended standard of 250:1 in most universities. This imbalance results
in extended waiting periods for in-person consultations, which cause suboptimal
treatment. Significant efforts have been directed toward developing mental
health dialogue systems utilizing the existing open-source mental
health-related datasets. However, currently available datasets either discuss
general topics or various strategies that may not be viable for direct
application due to numerous ethical constraints inherent in this research
domain. To address this issue, this paper introduces a specialized mental
health dataset that emphasizes the active listening strategy employed in
conversation for counseling, also named as ConvCounsel. This dataset comprises
both speech and text data, which can facilitate the development of a reliable
pipeline for mental health dialogue systems. To demonstrate the utility of the
proposed dataset, this paper also presents the NYCUKA, a spoken mental health
dialogue system that is designed by using the ConvCounsel dataset. The results
show the merit of using this dataset.",http://arxiv.org/abs/2411.00604v1
"Ensuring accurate call prioritisation is essential for optimising the
efficiency and responsiveness of mental health helplines. Currently, call
operators rely entirely on the caller's statements to determine the priority of
the calls. It has been shown that entirely subjective assessment can lead to
errors. Furthermore, it is a missed opportunity not to utilise the voice
properties readily available during the call to aid in the evaluation.
Incorrect prioritisation can result in delayed assistance for high-risk
individuals, resource misallocation, increased mental health deterioration,
loss of trust, and potential legal consequences. It is vital to address these
risks to guarantee the reliability and effectiveness of mental health services.
This study delves into the potential of using machine learning, a branch of
Artificial Intelligence, to estimate call priority from the callers' voices for
users of mental health phone helplines. After analysing 459 call records from a
mental health helpline, we achieved a balanced accuracy of 92\%, showing
promise in aiding the call operators' efficiency in call handling processes and
improving customer satisfaction.",http://arxiv.org/abs/2412.00057v1
"Given the current social distance restrictions across the world, most
individuals now use social media as their major medium of communication.
Millions of people suffering from mental diseases have been isolated due to
this, and they are unable to get help in person. They have become more reliant
on online venues to express themselves and seek advice on dealing with their
mental disorders. According to the World health organization (WHO),
approximately 450 million people are affected. Mental illnesses, such as
depression, anxiety, etc., are immensely common and have affected an
individuals' physical health. Recently Artificial Intelligence (AI) methods
have been presented to help mental health providers, including psychiatrists
and psychologists, in decision making based on patients' authentic information
(e.g., medical records, behavioral data, social media utilization, etc.). AI
innovations have demonstrated predominant execution in numerous real-world
applications broadening from computer vision to healthcare. This study analyzes
unstructured user data on the Reddit platform and classifies five common mental
illnesses: depression, anxiety, bipolar disorder, ADHD, and PTSD. We trained
traditional machine learning, deep learning, and transfer learning multi-class
models to detect mental disorders of individuals. This effort will benefit the
public health system by automating the detection process and informing
appropriate authorities about people who require emergency assistance.",http://arxiv.org/abs/2207.01012v1
"The empirical risk minimization approach to data-driven decision making
requires access to training data drawn under the same conditions as those that
will be faced when the decision rule is deployed. However, in a number of
settings, we may be concerned that our training sample is biased in the sense
that some groups (characterized by either observable or unobservable
attributes) may be under- or over-represented relative to the general
population; and in this setting empirical risk minimization over the training
set may fail to yield rules that perform well at deployment. We propose a model
of sampling bias called conditional $\Gamma$-biased sampling, where observed
covariates can affect the probability of sample selection arbitrarily much but
the amount of unexplained variation in the probability of sample selection is
bounded by a constant factor. Applying the distributionally robust optimization
framework, we propose a method for learning a decision rule that minimizes the
worst-case risk incurred under a family of test distributions that can generate
the training distribution under $\Gamma$-biased sampling. We apply a result of
Rockafellar and Uryasev to show that this problem is equivalent to an augmented
convex risk minimization problem. We give statistical guarantees for learning a
model that is robust to sampling bias via the method of sieves, and propose a
deep learning algorithm whose loss function captures our robust learning
target. We empirically validate our proposed method in a case study on
prediction of mental health scores from health survey data and a case study on
ICU length of stay prediction.",http://arxiv.org/abs/2209.01754v3
"Digital Biomarkers and remote patient monitoring can provide valuable and
timely insights into how a patient is coping with their condition (disease
progression, treatment response, etc.), complementing treatment in traditional
healthcare settings.Smartphones with embedded and connected sensors have
immense potential for improving healthcare through various apps and mHealth
(mobile health) platforms. This capability could enable the development of
reliable digital biomarkers from long-term longitudinal data collected remotely
from patients. We built an open-source platform, RADAR-base, to support
large-scale data collection in remote monitoring studies. RADAR-base is a
modern remote data collection platform built around Confluent's Apache Kafka,
to support scalability, extensibility, security, privacy and quality of data.
It provides support for study design and set-up, active (eg PROMs) and passive
(eg. phone sensors, wearable devices and IoT) remote data collection
capabilities with feature generation (eg. behavioural, environmental and
physiological markers). The backend enables secure data transmission, and
scalable solutions for data storage, management and data access. The platform
has successfully collected longitudinal data for various cohorts in a number of
disease areas including Multiple Sclerosis, Depression, Epilepsy, ADHD,
Alzheimer, Autism and Lung diseases. Digital biomarkers developed through
collected data are providing useful insights into different diseases.
RADAR-base provides a modern open-source, community-driven solution for remote
monitoring, data collection, and digital phenotyping of physical and mental
health diseases. Clinicians can use digital biomarkers to augment their
decision making for the prevention, personalisation and early intervention of
disease.",http://arxiv.org/abs/2308.02043v1
"This paper explores the intricate relationship between capitalism, racial
injustice, and artificial intelligence (AI), arguing that AI acts as a
contemporary vehicle for age-old forms of exploitation. By linking historical
patterns of racial and economic oppression with current AI practices, this
study illustrates how modern technology perpetuates and deepens societal
inequalities. It specifically examines how AI is implicated in the exploitation
of marginalized communities through underpaid labor in the gig economy, the
perpetuation of biases in algorithmic decision-making, and the reinforcement of
systemic barriers that prevent these groups from benefiting equitably from
technological advances. Furthermore, the paper discusses the role of AI in
extending and intensifying the social, economic, and psychological burdens
faced by these communities, highlighting the problematic use of AI in
surveillance, law enforcement, and mental health contexts. The analysis
concludes with a call for transformative changes in how AI is developed and
deployed. Advocating for a reevaluation of the values driving AI innovation,
the paper promotes an approach that integrates social justice and equity into
the core of technological design and policy. This shift is crucial for ensuring
that AI serves as a tool for societal improvement, fostering empowerment and
healing rather than deepening existing divides.",http://arxiv.org/abs/2403.06332v2
"This manuscript presents a methodical examination of the utilization of
Artificial Intelligence in the assessment of emotions in texts related to
healthcare, with a particular focus on the incorporation of Natural Language
Processing and deep learning technologies. We scrutinize numerous research
studies that employ AI to augment sentiment analysis, categorize emotions, and
forecast patient outcomes based on textual information derived from clinical
narratives, patient feedback on medications, and online health discussions. The
review demonstrates noteworthy progress in the precision of algorithms used for
sentiment classification, the prognostic capabilities of AI models for
neurodegenerative diseases, and the creation of AI-powered systems that offer
support in clinical decision-making. Remarkably, the utilization of AI
applications has exhibited an enhancement in personalized therapy plans by
integrating patient sentiment and contributing to the early identification of
mental health disorders. There persist challenges, which encompass ensuring the
ethical application of AI, safeguarding patient confidentiality, and addressing
potential biases in algorithmic procedures. Nevertheless, the potential of AI
to revolutionize healthcare practices is unmistakable, offering a future where
healthcare is not only more knowledgeable and efficient but also more
empathetic and centered around the needs of patients. This investigation
underscores the transformative influence of AI on healthcare, delivering a
comprehensive comprehension of its role in examining emotional content in
healthcare texts and highlighting the trajectory towards a more compassionate
approach to patient care. The findings advocate for a harmonious synergy
between AI's analytical capabilities and the human aspects of healthcare.",http://arxiv.org/abs/2403.09762v1
"Correctly assessing the malignancy of breast lesions identified during
ultrasound examinations is crucial for effective clinical decision-making.
However, the current ""golden standard"" relies on manual BI-RADS scoring by
clinicians, often leading to unnecessary biopsies and a significant mental
health burden on patients and their families. In this paper, we introduce
PersonalizedUS, an interpretable machine learning system that leverages recent
advances in conformal prediction to provide precise and personalized risk
estimates with local coverage guarantees and sensitivity, specificity, and
predictive values above 0.9 across various threshold levels. In particular, we
identify meaningful lesion subgroups where distribution-free, model-agnostic
conditional coverage holds, with approximately 90% of our prediction sets
containing only the ground truth in most lesion subgroups, thus explicitly
characterizing for which patients the model is most suitably applied. Moreover,
we make available a curated tabular dataset of 1936 biopsied breast lesions
from a recent observational multicenter study and benchmark the performance of
several state-of-the-art learning algorithms. We also report a successful case
study of the deployed system in the same multicenter context. Concrete clinical
benefits include up to a 65% reduction in requested biopsies among BI-RADS 4a
and 4b lesions, with minimal to no missed cancer cases.",http://arxiv.org/abs/2408.15458v1
"Widely distributed misinformation shared across social media channels is a
pressing issue that poses a significant threat to many aspects of society's
well-being. Inaccurate shared information causes confusion, can adversely
affect mental health, and can lead to mis-informed decision-making. Therefore,
it is important to implement proactive measures to intervene and curb the
spread of misinformation where possible. This has prompted scholars to
investigate a variety of intervention strategies for misinformation sharing on
social media. This study explores the typology of intervention strategies for
addressing misinformation sharing on social media, identifying 4 important
clusters - cognition-based, automated-based, information-based, and
hybrid-based. The literature selection process utilized the PRISMA method to
ensure a systematic and comprehensive analysis of relevant literature while
maintaining transparency and reproducibility. A total of 139 articles published
from 2013-2023 were then analyzed. Meanwhile, bibliometric analyses were
conducted using performance analysis and science mapping techniques for the
typology development. A comparative analysis of the typology was conducted to
reveal patterns and evolution in the field. This provides valuable insights for
both theory and practical applications. Overall, the study concludes that
scholarly contributions to scientific research and publication help to address
research gaps and expand knowledge in this field. Understanding the evolution
of intervention strategies for misinformation sharing on social media can
support future research that contributes to the development of more effective
and sustainable solutions to this persistent problem.",http://arxiv.org/abs/2409.17637v1
"Emotion regulation is the process of consciously altering one's affective
state, that is the underlying emotional state such as happiness, confidence,
guilt, anger etc. The ability to effectively regulate emotions is necessary for
functioning efficiently in everyday life. Today, the pervasiveness of digital
technology is being purposefully employed to modify our affective states, a
process known as digital emotion regulation. Understanding digital emotion
regulation can help support the rise of ethical technology design, development,
and deployment. This article presents an overview of digital emotion regulation
in social media applications, as well as a synthesis of recent research on
emotion regulation interventions for social media. We share our findings from
analysing state-of-the-art literature on how different social media
applications are utilised at different stages in the process of emotion
regulation.",http://arxiv.org/abs/2307.13187v1
"While the applications and demands of Machine learning (ML) systems in mental
health are growing, there is little discussion nor consensus regarding a
uniquely challenging aspect: building security methods and requirements into
these ML systems, and keep the ML system usable for end-users. This question of
usable security is very important, because the lack of consideration in either
security or usability would hinder large-scale user adoption and active usage
of ML systems in mental health applications.
  In this short paper, we introduce a framework of four pillars, and a set of
desired properties which can be used to systematically guide and evaluate
security-related designs, implementations, and deployments of ML systems for
mental health. We aim to weave together threads from different domains,
incorporate existing views, and propose new principles and requirements, in an
effort to lay out a clear framework where criteria and expectations are
established, and are used to make security mechanisms usable for end-users of
those ML systems in mental health. Together with this framework, we present
several concrete scenarios where different usable security cases and profiles
in ML-systems in mental health applications are examined and evaluated.",http://arxiv.org/abs/2008.07738v1
"Mental health is an extremely important subject, especially in these
unprecedented times of the COVID-19 pandemic. Ubiquitous mobile phones can
equip users to supplement psychiatric treatment and manage their mental health.
Mobile Mental Health (MMH) apps emerge as an effective alternative to assist
with a broad range of psychological disorders filling the much-needed
patient-provider accessibility gap. However, it also raises significant
concerns with sensitive information leakage.The absence of a transparent
privacy policy and lack of user awareness may pose a significant threat to
undermining the applicability of such tools. We conducted a multifold study of
- 1) Privacy Policies (Manually and with Polisis, an automated framework to
evaluate privacy policies); 2) App permissions; 3) Static Analysis for inherent
security issues; 4) Dynamic Analysis for threat surface and vulnerabilities
detection, and 5) Traffic Analysis.
  Our results indicate that apps' exploitable flaws, dangerous permissions, and
insecure data handling pose a potential threat to the users' privacy and
security. The Dynamic analysis identified 145 vulnerabilities in 20 top-rated
MMH apps where attackers and malicious apps can access sensitive information.
45% of MMH apps use a unique identifier, Hardware Id, which can link a unique
id to a particular user and probe users' mental health. Traffic analysis shows
that sensitive mental health data can be leaked through insecure data
transmission. MMH apps need better scrutiny and regulation for more widespread
usage to meet the increasing need for mental health care without being
intrusive to the already vulnerable population.",http://arxiv.org/abs/2206.10728v2
"In this study, we leveraged machine learning techniques to identify risk
factors associated with post-COVID-19 mental health disorders. Our analysis,
based on data collected from 669 patients across various provinces in Iraq,
yielded valuable insights. We found that age, gender, and geographical region
of residence were significant demographic factors influencing the likelihood of
developing mental health disorders in post-COVID-19 patients. Additionally,
comorbidities and the severity of COVID-19 illness were important clinical
predictors. Psychosocial factors, such as social support, coping strategies,
and perceived stress levels, also played a substantial role. Our findings
emphasize the complex interplay of multiple factors in the development of
mental health disorders following COVID-19 recovery. Healthcare providers and
policymakers should consider these risk factors when designing targeted
interventions and support systems for individuals at risk. Machine
learning-based approaches can provide a valuable tool for predicting and
preventing adverse mental health outcomes in post-COVID-19 patients. Further
research and prospective studies are needed to validate these findings and
enhance our understanding of the long-term psychological impact of the COVID-19
pandemic. This study contributes to the growing body of knowledge regarding the
mental health consequences of the COVID-19 pandemic and underscores the
importance of a multidisciplinary approach to address the diverse needs of
individuals on the path to recovery.",http://arxiv.org/abs/2309.16055v1
"Culture moderates the way individuals perceive and express mental distress.
Current understandings of mental health expressions on social media, however,
are predominantly derived from WEIRD (Western, Educated, Industrialized, Rich,
and Democratic) contexts. To address this gap, we examine mental health posts
on Reddit made by individuals geolocated in India, to identify variations in
social media language specific to the Indian context compared to users from the
Rest of the World (RoW). Our experiments reveal significant psychosocial
variations in emotions (sadness in India vs anxiety in RoW), temporal
orientation (present-focused in India vs past-focused in the West), and
sociocultural aspects (substance use vs work/achievement). Clinical
psychologists practicing in India validated the findings and underlined
significant overlap in mental health-related concerns observed in social media
posts and in-person sessions. This study demonstrates the potential of social
media platforms for identifying cross-cultural differences in mental health
struggles (e.g. seeking help in India vs seeking peer support in RoW). Future
research should investigate how mental health assessment can be culturally
adapted to personalize interventions, ensuring equitable mental health care for
individuals from all cultural backgrounds.",http://arxiv.org/abs/2402.11477v3
"The growing prevalence and complexity of mental health disorders present
significant challenges for accurate diagnosis and treatment, particularly in
understanding the interplay between co-occurring conditions. Mental health
disorders, such as depression and Anxiety, often co-occur, yet current datasets
derived from social media posts typically focus on single-disorder labels,
limiting their utility in comprehensive diagnostic analyses. This paper
addresses this critical gap by proposing a novel methodology for cleaning,
sampling, labeling, and combining data to create versatile multi-label
datasets. Our approach introduces a synthetic labeling technique to transform
single-label datasets into multi-label annotations, capturing the complexity of
overlapping mental health conditions. To achieve this, two single-label
datasets are first merged into a foundational multi-label dataset, enabling
realistic analyses of co-occurring diagnoses. We then design and evaluate
various prompting strategies for large language models (LLMs), ranging from
single-label predictions to unrestricted prompts capable of detecting any
present disorders. After rigorously assessing multiple LLMs and prompt
configurations, the optimal combinations are identified and applied to label
six additional single-disorder datasets from RMHD. The result is SPAADE-DR, a
robust, multi-label dataset encompassing diverse mental health conditions. This
research demonstrates the transformative potential of LLM-driven synthetic
labeling in advancing mental health diagnostics from social media data, paving
the way for more nuanced, data-driven insights into mental health care.",http://arxiv.org/abs/2412.03796v1
"Recent advancements in NLP have spurred significant interest in analyzing
social media text data for identifying linguistic features indicative of mental
health issues. However, the domain of Expressive Narrative Stories (ENS)-deeply
personal and emotionally charged narratives that offer rich psychological
insights-remains underexplored. This study bridges this gap by utilizing a
dataset sourced from Reddit, focusing on ENS from individuals with and without
self-declared depression. Our research evaluates the utility of advanced
language models, BERT and MentalBERT, against traditional models. We find that
traditional models are sensitive to the absence of explicit topic-related
words, which could risk their potential to extend applications to ENS that lack
clear mental health terminology. Despite MentalBERT is design to better handle
psychiatric contexts, it demonstrated a dependency on specific topic words for
classification accuracy, raising concerns about its application when explicit
mental health terms are sparse (P-value<0.05). In contrast, BERT exhibited
minimal sensitivity to the absence of topic words in ENS, suggesting its
superior capability to understand deeper linguistic features, making it more
effective for real-world applications. Both BERT and MentalBERT excel at
recognizing linguistic nuances and maintaining classification accuracy even
when narrative order is disrupted. This resilience is statistically
significant, with sentence shuffling showing substantial impacts on model
performance (P-value<0.05), especially evident in ENS comparisons between
individuals with and without mental health declarations. These findings
underscore the importance of exploring ENS for deeper insights into mental
health-related narratives, advocating for a nuanced approach to mental health
text analysis that moves beyond mere keyword detection.",http://arxiv.org/abs/2412.16302v1
"Our aim is to compare the fundamental notions of quantum physics -
contextuality vs. incompatibility. One has to distinguish two different notions
of contextuality, {\it Bohr-contextuality} and {\it Bell-contextuality}. The
latter is defined operationally via violation of noncontextuality (Bell type)
inequalities. This sort of contextuality will be compared with incompatibility.
It is easy to show that, for quantum observables, there is {\it no
contextuality without incompatibility.} The natural question arises: What is
contextuality without incompatibility? (What is ""dry-residue""?) Generally this
is the very complex question. We concentrated on contextuality for four quantum
observables. We shown that in the CHSH-scenarios (for ""natural quantum
observables"") {\it contextuality is reduced to incompatibility.} However,
generally contextuality without incompatibility may have some physical content.
We found a mathematical constraint extracting the contextuality component from
incompatibility. However, the physical meaning of this constraint is not clear.
In appendix 1, we briefly discuss another sort of contextuality based on the
Bohr's complementarity principle which is treated as the {\it
contextuality-incompatibility principle}. Bohr-contextuality plays the crucial
role in quantum foundations. Incompatibility is, in fact, a consequence of
Bohr-contextuality. Finally, we remark that outside of physics, e.g., in
cognitive psychology and decision making Bell-contextuality cleaned of
incompatibility can play the important role.",http://arxiv.org/abs/2005.05124v3
"Untile recently crowdsourcing has been primarily conceived as an online
activity to harness resources for problem solving. However the emergence of
opportunistic networking (ON) has opened up crowdsourcing to the spatial
domain. In this paper we bring the ON model for potential crowdsourcing in the
smart city environment. We introduce cognitive features to the ON that allow
users' mobile devices to become aware of the surrounding physical environment.
Specifically, we exploit cognitive psychology studies on dynamic memory
structures and cognitive heuristics, i.e. mental models that describe how the
human brain handle decision-making amongst complex and real-time stimuli.
Combined with ON, these cognitive features allow devices to act as proxies in
the cyber-world of their users and exchange knowledge to deliver awareness of
places in an urban environment. This is done through tags associated with
locations. They represent features that are perceived by humans about a place.
We consider the extent to which this knowledge becomes available to
participants, using interactions with locations and other nodes. This is
assessed taking into account a wide range of cognitive parameters. Outcomes are
important because this functionality could support a new type of recommendation
system that is independent of the traditional forms of networking.",http://arxiv.org/abs/2109.14946v1
"There is a clear need to involve patients in medical decisions. However,
cognitive psychological research has highlighted the cognitive limitations of
humans with respect to 1. Probabilistic assessment of the patient state and of
potential outcomes of various decisions, 2. Elicitation of the patient utility
function, and 3. Integration of the probabilistic knowledge and of patient
preferences to determine the optimal strategy. Therefore, without adequate
computational support, current shared decision models have severe ethical
deficiencies. An informed consent model unfairly transfers the responsibility
to a patient who does not have the necessary knowledge, nor the integration
capability. A paternalistic model endows with exaggerated power a physician who
might not be aware of the patient preferences, is prone to multiple cognitive
biases, and whose computational integration capability is bounded. Recent
progress in Artificial Intelligence suggests adding a third agent: a computer,
in all deliberative medical decisions: Non emergency medical decisions in which
more than one alternative exists, the patient preferences can be elicited, the
therapeutic alternatives might be influenced by these preferences, medical
knowledge exists regarding the likelihood of the decision outcomes, and there
is sufficient decision time. Ethical physicians should exploit computational
decision support technologies, neither making the decisions solely on their
own, nor shirking their duty and shifting the responsibility to patients in the
name of informed consent. The resulting three way (patient, care provider,
computer) human machine model that we suggest emphasizes the patient
preferences, the physician knowledge, and the computational integration of both
aspects, does not diminish the physician role, but rather brings out the best
in human and machine.",http://arxiv.org/abs/2102.01811v1
"Working memory (WM), a fundamental cognitive process facilitating the
temporary storage, integration, manipulation, and retrieval of information,
plays a vital role in reasoning and decision-making tasks. Robust benchmark
datasets that capture the multifaceted nature of WM are crucial for the
effective development and evaluation of AI WM models. Here, we introduce a
comprehensive Working Memory (WorM) benchmark dataset for this purpose. WorM
comprises 10 tasks and a total of 1 million trials, assessing 4
functionalities, 3 domains, and 11 behavioral and neural characteristics of WM.
We jointly trained and tested state-of-the-art recurrent neural networks and
transformers on all these tasks. We also include human behavioral benchmarks as
an upper bound for comparison. Our results suggest that AI models replicate
some characteristics of WM in the brain, most notably primacy and recency
effects, and neural clusters and correlates specialized for different domains
and functionalities of WM. In the experiments, we also reveal some limitations
in existing models to approximate human behavior. This dataset serves as a
valuable resource for communities in cognitive psychology, neuroscience, and
AI, offering a standardized framework to compare and enhance WM models,
investigate WM's neural underpinnings, and develop WM models with human-like
capabilities. Our source code and data are available at
https://github.com/ZhangLab-DeepNeuroCogLab/WorM.",http://arxiv.org/abs/2307.10768v2
"The past few years have seen a surge in the application of quantum theory
methodologies and quantum-like modeling in fields such as cognition,
psychology, and decision-making. Despite the success of this approach in
explaining various psychological phenomena such as order, conjunction,
disjunction, and response replicability effects there remains a potential
dissatisfaction due to its lack of clear connection to neurophysiological
processes in the brain. Currently, it remains a phenomenological approach. In
this paper, we develop a quantum-like representation of networks of
communicating neurons. This representation is not based on standard quantum
theory but on generalized probability theory (GPT), with a focus on the
operational measurement framework. Specifically, we use a version of GPT that
relies on ordered linear state spaces rather than the traditional complex
Hilbert spaces. A network of communicating neurons is modeled as a weighted
directed graph, which is encoded by its weight matrix. The state space of these
weight matrices is embedded within the GPT framework, incorporating effect
observables and state updates within the theory of measurement instruments a
critical aspect of this model. This GPT based approach successfully reproduces
key quantum-like effects, such as order, non-repeatability, and disjunction
effects (commonly associated with decision interference). Moreover, this
framework supports quantum-like modeling in medical diagnostics for
neurological conditions such as depression and epilepsy. While this paper
focuses primarily on cognition and neuronal networks, the proposed formalism
and methodology can be directly applied to a wide range of biological and
social networks.",http://arxiv.org/abs/2411.00036v2
"Compared to physical health, population mental health measurement in the U.S.
is very coarse-grained. Currently, in the largest population surveys, such as
those carried out by the Centers for Disease Control or Gallup, mental health
is only broadly captured through ""mentally unhealthy days"" or ""sadness"", and
limited to relatively infrequent state or metropolitan estimates. Through the
large scale analysis of social media data, robust estimation of population
mental health is feasible at much higher resolutions, up to weekly estimates
for counties. In the present work, we validate a pipeline that uses a sample of
1.2 billion Tweets from 2 million geo-located users to estimate mental health
changes for the two leading mental health conditions, depression and anxiety.
We find moderate to large associations between the language-based mental health
assessments and survey scores from Gallup for multiple levels of granularity,
down to the county-week (fixed effects $\beta = .25$ to $1.58$; $p<.001$).
Language-based assessment allows for the cost-effective and scalable monitoring
of population mental health at weekly time scales. Such spatially fine-grained
time series are well suited to monitor effects of societal events and policies
as well as enable quasi-experimental study designs in population health and
other disciplines. Beyond mental health in the U.S., this method generalizes to
a broad set of psychological outcomes and allows for community measurement in
under-resourced settings where no traditional survey measures - but social
media data - are available.",http://arxiv.org/abs/2302.12952v1
"Amidst the growing interest in developing task-autonomous AI for automated
mental health care, this paper addresses the ethical and practical challenges
associated with the issue and proposes a structured framework that delineates
levels of autonomy, outlines ethical requirements, and defines beneficial
default behaviors for AI agents in the context of mental health support. We
also evaluate fourteen state-of-the-art language models (ten off-the-shelf,
four fine-tuned) using 16 mental health-related questionnaires designed to
reflect various mental health conditions, such as psychosis, mania, depression,
suicidal thoughts, and homicidal tendencies. The questionnaire design and
response evaluations were conducted by mental health clinicians (M.D.s). We
find that existing language models are insufficient to match the standard
provided by human professionals who can navigate nuances and appreciate
context. This is due to a range of issues, including overly cautious or
sycophantic responses and the absence of necessary safeguards. Alarmingly, we
find that most of the tested models could cause harm if accessed in mental
health emergencies, failing to protect users and potentially exacerbating
existing symptoms. We explore solutions to enhance the safety of current
models. Before the release of increasingly task-autonomous AI systems in mental
health, it is crucial to ensure that these models can reliably detect and
manage symptoms of common psychiatric disorders to prevent harm to users. This
involves aligning with the ethical framework and default behaviors outlined in
our study. We contend that model developers are responsible for refining their
systems per these guidelines to safeguard against the risks posed by current AI
technologies to user mental health and safety.
  Trigger warning: Contains and discusses examples of sensitive mental health
topics, including suicide and self-harm.",http://arxiv.org/abs/2406.11852v2
"Predicting mental health from smartphone and social media data on a
longitudinal basis has recently attracted great interest, with very promising
results being reported across many studies. Such approaches have the potential
to revolutionise mental health assessment, if their development and evaluation
follows a real world deployment setting. In this work we take a closer look at
state-of-the-art approaches, using different mental health datasets and
indicators, different feature sources and multiple simulations, in order to
assess their ability to generalise. We demonstrate that under a pragmatic
evaluation framework, none of the approaches deliver or even approach the
reported performances. In fact, we show that current state-of-the-art
approaches can barely outperform the most na\""ive baselines in the real-world
setting, posing serious questions not only about their deployment ability, but
also about the contribution of the derived features for the mental health
assessment task and how to make better use of such data in the future.",http://arxiv.org/abs/1807.07351v1
"As the popularity of social media platforms continues to rise, an
ever-increasing amount of human communication and self- expression takes place
online. Most recent research has focused on mining social media for public user
opinion about external entities such as product reviews or sentiment towards
political news. However, less attention has been paid to analyzing users'
internalized thoughts and emotions from a mental health perspective. In this
paper, we quantify the semantic difference between public Tweets and private
mental health journals used in online cognitive behavioral therapy. We will use
deep transfer learning techniques for analyzing the semantic gap between the
two domains. We show that for the task of emotional valence prediction, social
media can be successfully harnessed to create more accurate, robust, and
personalized mental health models. Our results suggest that the semantic gap
between public and private self-expression is small, and that utilizing the
abundance of available social media is one way to overcome the small sample
sizes of mental health data, which are commonly limited by availability and
privacy concerns.",http://arxiv.org/abs/1708.01372v1
"The COVID-19 pandemic, like many of the disease outbreaks that have preceded
it, is likely to have a profound effect on mental health. Understanding its
impact can inform strategies for mitigating negative consequences. In this
work, we seek to better understand the effects of COVID-19 on mental health by
examining discussions within mental health support communities on Reddit.
First, we quantify the rate at which COVID-19 is discussed in each community,
or subreddit, in order to understand levels of preoccupation with the pandemic.
Next, we examine the volume of activity in order to determine whether the
quantity of people seeking online mental health support has risen. Finally, we
analyze how COVID-19 has influenced language use and topics of discussion
within each subreddit.",http://arxiv.org/abs/2009.04008v1
"Empathy is critical to successful mental health support. Empathy measurement
has predominantly occurred in synchronous, face-to-face settings, and may not
translate to asynchronous, text-based contexts. Because millions of people use
text-based platforms for mental health support, understanding empathy in these
contexts is crucial. In this work, we present a computational approach to
understanding how empathy is expressed in online mental health platforms. We
develop a novel unifying theoretically-grounded framework for characterizing
the communication of empathy in text-based conversations. We collect and share
a corpus of 10k (post, response) pairs annotated using this empathy framework
with supporting evidence for annotations (rationales). We develop a multi-task
RoBERTa-based bi-encoder model for identifying empathy in conversations and
extracting rationales underlying its predictions. Experiments demonstrate that
our approach can effectively identify empathic conversations. We further apply
this model to analyze 235k mental health interactions and show that users do
not self-learn empathy over time, revealing opportunities for empathy training
and feedback.",http://arxiv.org/abs/2009.08441v1
"Mental health is a global epidemic, affecting close to half a billion people
worldwide. Chronic shortage of resources hamper detection and recovery of
affected people. Effective sensing technologies can help fight the epidemic
through early detection, prediction, and resulting proper treatment. Existing
and novel technologies for sensing mental health state could address the
aforementioned concerns by activating granular tracking of physiological,
behavioral, and social signals pertaining to problems in mental health. Our
paper focuses on the available methods of sensing mental health problems
through direct and indirect measures. We see how active and passive sensing by
technologies as well as reporting from relevant sources can contribute toward
these detection methods. We also see available methods of therapeutic treatment
available through digital means. We highlight a few key intervention
technologies that are being developed by researchers to fight against mental
illness issues.",http://arxiv.org/abs/2009.12488v1
"While there is an emergence of research investigating the educational impacts
of the COVID-19 pandemic, empirical studies assessing teacher mental health
throughout the pandemic have been scarce. Using a large national dataset, the
current study first compared mental health outcomes during the pandemic between
pK-12 teachers and professionals in other occupations. Further, we compared the
prevalence of mental health outcomes between in-person and remote teachers (n =
131,154). Findings indicated teachers reported greater mental health concerns
than those in other professions, and that remote teachers reported
significantly higher levels of distress than those teaching in-person. Policy
implications are discussed, with a focus on providing support to meet the
evolving needs of teachers.",http://arxiv.org/abs/2109.01547v1
"Interpersonal relationships are necessary for successful daily functioning
and wellbeing. Numerous studies have demonstrated the importance of social
connectivity for mental health, both through direct peer-to-peer influence and
by the location of individuals within their social network. Passive monitoring
using smartphones provides an advanced tool to map social networks based on the
proximity between individuals. This study investigates the feasibility of using
a smartphone app to measure and assess the relationship between social network
metrics and mental health. The app collected Bluetooth and mental health data
in 63 participants. Social networks of proximity were estimated from Bluetooth
data and 95% of the edges were scanned at least every 30 minutes. The majority
of participants found this method of data collection acceptable and reported
that they would be likely to participate in future studies using this app.
These findings demonstrate the feasibility of using a smartphone app that
participants can install on their own phone to investigate the relationship
between social connectivity and mental health.",http://arxiv.org/abs/1702.02644v2
"We introduce initial groundwork for estimating suicide risk and mental health
in a deep learning framework. By modeling multiple conditions, the system
learns to make predictions about suicide risk and mental health at a low false
positive rate. Conditions are modeled as tasks in a multi-task learning (MTL)
framework, with gender prediction as an additional auxiliary task. We
demonstrate the effectiveness of multi-task learning by comparison to a
well-tuned single-task baseline with the same number of parameters. Our best
MTL model predicts potential suicide attempt, as well as the presence of
atypical mental health, with AUC > 0.8. We also find additional large
improvements using multi-task learning on mental health tasks with limited
training data.",http://arxiv.org/abs/1712.03538v1
"Data-driven methods for mental health treatment and surveillance have become
a major focus in computational science research in the last decade. However,
progress in the domain, in terms of both medical understanding and system
performance, remains bounded by the availability of adequate data. Prior
systematic reviews have not necessarily made it possible to measure the degree
to which data-related challenges have affected research progress. In this
paper, we offer an analysis specifically on the state of social media data that
exists for conducting mental health research. We do so by introducing an
open-source directory of mental health datasets, annotated using a standardized
schema to facilitate meta-analysis.",http://arxiv.org/abs/2011.05233v2
"Housing expenditure tends to be sticky and costly to adjust, and makes up a
large proportion of household expenditure. Additionally, the loss of housing
can have catastrophic consequences. These specific features of housing
expenditure imply that housing stress could cause negative mental health
impacts. This research investigates the effects of housing stress on mental
health, contributing to the literature by nesting housing stress within a
measure of financial hardship, thus improving robustness to omitted variables
and creating a natural comparison group for matching. Fixed effects (FE)
regressions and a difference-in-differences (DID) methodology are estimated
utilising data from the Household Income and Labour Dynamics in Australia
(HILDA) Survey. The results show that renters who are in housing stress have a
significant decline in self-reported mental health, with those in prior
financial hardship being more severely affected. In contrast, there is little
to no evidence of housing stress impacting on owners with a mortgage. The
results also suggest that the mental health impact of housing stress is more
important than some, but not all, aspects of financial hardship.",http://arxiv.org/abs/2205.01255v1
"Understanding human behavior and monitoring mental health are essential to
maintaining the community and society's safety. As there has been an increase
in mental health problems during the COVID-19 pandemic due to uncontrolled
mental health, early detection of mental issues is crucial. Nowadays, the usage
of Intelligent Virtual Personal Assistants (IVA) has increased worldwide.
Individuals use their voices to control these devices to fulfill requests and
acquire different services. This paper proposes a novel deep learning model
based on the gated recurrent neural network and convolution neural network to
understand human emotion from speech to improve their IVA services and monitor
their mental health.",http://arxiv.org/abs/2208.12812v3
"Pain is a common reason for accessing healthcare resources and is a growing
area of research, especially in its overlap with mental health. Mental health
electronic health records are a good data source to study this overlap.
However, much information on pain is held in the free text of these records,
where mentions of pain present a unique natural language processing problem due
to its ambiguous nature. This project uses data from an anonymised mental
health electronic health records database. The data are used to train a machine
learning based classification algorithm to classify sentences as discussing
patient pain or not. This will facilitate the extraction of relevant pain
information from large databases, and the use of such outputs for further
studies on pain and mental health. 1,985 documents were manually
triple-annotated for creation of gold standard training data, which was used to
train three commonly used classification algorithms. The best performing model
achieved an F1-score of 0.98 (95% CI 0.98-0.99).",http://arxiv.org/abs/2304.01240v2
"Social media platforms have enabled individuals suffering from mental
illnesses to share their lived experiences and find the online support
necessary to cope. However, many users fail to receive genuine clinical
support, thus exacerbating their symptoms. Screening users based on what they
post online can aid providers in administering targeted healthcare and minimize
false positives. Pre-trained Language Models (LMs) can assess users' social
media data and classify them in terms of their mental health risk. We propose a
Question-Answering (QA) approach to assess mental health risk using the
Unified-QA model on two large mental health datasets. To protect user data, we
extend Unified-QA by anonymizing the model training process using differential
privacy. Our results demonstrate the effectiveness of modeling risk assessment
as a QA task, specifically for mental health use cases. Furthermore, the
model's performance decreases by less than 1% with the inclusion of
differential privacy. The proposed system's performance is indicative of a
promising research direction that will lead to the development of privacy-aware
diagnostic systems.",http://arxiv.org/abs/2306.05652v1
"Mental health disorders remain a significant challenge in modern healthcare,
with diagnosis and treatment often relying on subjective patient descriptions
and past medical history. To address this issue, we propose a personalized
mental health tracking and mood prediction system that utilizes patient
physiological data collected through personal health devices. Our system
leverages a decentralized learning mechanism that combines transfer and
federated machine learning concepts using smart contracts, allowing data to
remain on users' devices and enabling effective tracking of mental health
conditions for psychiatric treatment and management in a privacy-aware and
accountable manner. We evaluate our model using a popular mental health dataset
that demonstrates promising results. By utilizing connected health systems and
machine learning models, our approach offers a novel solution to the challenge
of providing psychiatrists with further insight into their patients' mental
health outside of traditional office visits.",http://arxiv.org/abs/2307.04777v1
"Regarding the rising number of people suffering from mental health illnesses
in today's society, the importance of mental health cannot be overstated.
Wearable sensors, which are increasingly widely available, provide a potential
way to track and comprehend mental health issues. These gadgets not only
monitor everyday activities but also continuously record vital signs like heart
rate, perhaps providing information on a person's mental state. Recent research
has used these sensors in conjunction with machine learning methods to identify
patterns relating to different mental health conditions, highlighting the
immense potential of this data beyond simple activity monitoring. In this
research, we present a novel algorithm called the Hybrid Random forest - Neural
network that has been tailored to evaluate sensor data from depressed patients.
Our method has a noteworthy accuracy of 80\% when evaluated on a special
dataset that included both unipolar and bipolar depressive patients as well as
healthy controls. The findings highlight the algorithm's potential for reliably
determining a person's depression condition using sensor data, making a
substantial contribution to the area of mental health diagnostics.",http://arxiv.org/abs/2310.09277v1
"Self-guided mental health interventions, such as ""do-it-yourself"" tools to
learn and practice coping strategies, show great promise to improve access to
mental health care. However, these interventions are often cognitively
demanding and emotionally triggering, creating accessibility barriers that
limit their wide-scale implementation and adoption. In this paper, we study how
human-language model interaction can support self-guided mental health
interventions. We take cognitive restructuring, an evidence-based therapeutic
technique to overcome negative thinking, as a case study. In an IRB-approved
randomized field study on a large mental health website with 15,531
participants, we design and evaluate a system that uses language models to
support people through various steps of cognitive restructuring. Our findings
reveal that our system positively impacts emotional intensity for 67% of
participants and helps 65% overcome negative thoughts. Although adolescents
report relatively worse outcomes, we find that tailored interventions that
simplify language model generations improve overall effectiveness and equity.",http://arxiv.org/abs/2310.15461v2
"Mental health conversational agents (a.k.a. chatbots) are widely studied for
their potential to offer accessible support to those experiencing mental health
challenges. Previous surveys on the topic primarily consider papers published
in either computer science or medicine, leading to a divide in understanding
and hindering the sharing of beneficial knowledge between both domains. To
bridge this gap, we conduct a comprehensive literature review using the PRISMA
framework, reviewing 534 papers published in both computer science and
medicine. Our systematic review reveals 136 key papers on building mental
health-related conversational agents with diverse characteristics of modeling
and experimental design techniques. We find that computer science papers focus
on LLM techniques and evaluating response quality using automated metrics with
little attention to the application while medical papers use rule-based
conversational agents and outcome metrics to measure the health outcomes of
participants. Based on our findings on transparency, ethics, and cultural
heterogeneity in this review, we provide a few recommendations to help bridge
the disciplinary divide and enable the cross-disciplinary development of mental
health conversational agents.",http://arxiv.org/abs/2310.17017v1
"The global mental health crisis is looming with a rapid increase in mental
disorders, limited resources, and the social stigma of seeking treatment. As
the field of artificial intelligence (AI) has witnessed significant
advancements in recent years, large language models (LLMs) capable of
understanding and generating human-like text may be used in supporting or
providing psychological counseling. However, the application of LLMs in the
mental health domain raises concerns regarding the accuracy, effectiveness, and
reliability of the information provided. This paper investigates the major
challenges associated with the development of LLMs for psychological
counseling, including model hallucination, interpretability, bias, privacy, and
clinical effectiveness. We explore potential solutions to these challenges that
are practical and applicable to the current paradigm of AI. From our experience
in developing and deploying LLMs for mental health, AI holds a great promise
for improving mental health care, if we can carefully navigate and overcome
pitfalls of LLMs.",http://arxiv.org/abs/2311.13857v1
"Mental health conditions, prevalent across various demographics, necessitate
efficient monitoring to mitigate their adverse impacts on life quality. The
surge in data-driven methodologies for mental health monitoring has underscored
the importance of privacy-preserving techniques in handling sensitive health
data. Despite strides in federated learning for mental health monitoring,
existing approaches struggle with vulnerabilities to certain cyber-attacks and
data insufficiency in real-world applications. In this paper, we introduce a
differential private federated transfer learning framework for mental health
monitoring to enhance data privacy and enrich data sufficiency. To accomplish
this, we integrate federated learning with two pivotal elements: (1)
differential privacy, achieved by introducing noise into the updates, and (2)
transfer learning, employing a pre-trained universal model to adeptly address
issues of data imbalance and insufficiency. We evaluate the framework by a case
study on stress detection, employing a dataset of physiological and contextual
data from a longitudinal study. Our finding show that the proposed approach can
attain a 10% boost in accuracy and a 21% enhancement in recall, while ensuring
privacy protection.",http://arxiv.org/abs/2402.10862v2
"Mental health challenges are on the rise in our modern society, and the
imperative to address mental disorders, especially regarding anxiety,
depression, and suicidal thoughts, underscores the need for effective
interventions. This paper delves into the application of recent advancements in
pretrained contextualized language models to introduce MindGuide, an innovative
chatbot serving as a mental health assistant for individuals seeking guidance
and support in these critical areas. MindGuide leverages the capabilities of
LangChain and its ChatModels, specifically ChatOpenAI, as the bedrock of its
reasoning engine. The system incorporates key features such as LangChain's
ChatPrompt Template, HumanMessage Prompt Template, ConversationBufferMemory,
and LLMChain, creating an advanced solution for early detection and
comprehensive support within the field of mental health. Additionally, the
paper discusses the implementation of Streamlit to enhance the user experience
and interaction with the chatbot. This novel approach holds great promise for
proactive mental health intervention and assistance.",http://arxiv.org/abs/2403.05568v1
"The field of digital mental health is advancing at a rapid pace. Passively
collected data from user engagements with digital tools and services continue
to contribute new insights into mental health and illness. As the field of
digital mental health grows, a concerning norm has been established -- digital
service users are given little say over how their data is collected, shared, or
used to generate revenue for private companies. Given a long history of service
user exclusion from data collection practices, we propose an alternative
approach that is attentive to this history: the consent-forward paradigm. This
paradigm embeds principles of affirmative consent in the design of digital
mental health tools and services, strengthening trust through designing around
individual choices and needs, and proactively protecting users from unexpected
harm. In this perspective, we outline practical steps to implement this
paradigm, toward ensuring that people searching for care have the safest
experiences possible.",http://arxiv.org/abs/2404.14548v1
"Providing timely support and intervention is crucial in mental health
settings. As the need to engage youth comfortable with texting increases,
mental health providers are exploring and adopting text-based media such as
chatbots, community-based forums, online therapies with licensed professionals,
and helplines operated by trained responders. To support these text-based media
for mental health--particularly for crisis care--we are developing a system to
perform passive emotion-sensing using a combination of keystroke dynamics and
sentiment analysis. Our early studies of this system posit that the analysis of
short text messages and keyboard typing patterns can provide emotion
information that may be used to support both clients and responders. We use our
preliminary findings to discuss the way forward for applying AI to support
mental health providers in providing better care.",http://arxiv.org/abs/2406.11135v1
"NLP in mental health has been primarily social media focused. Real world
practitioners also have high case loads and often domain specific variables, of
which modern LLMs lack context. We take a dataset made by recruiting 644
participants, including individuals diagnosed with Bipolar Disorder (BD),
Schizophrenia (SZ), and Healthy Controls (HC). Participants undertook tasks
derived from a standardized mental health instrument, and the resulting data
were transcribed and annotated by experts across five clinical variables. This
paper demonstrates the application of contemporary language models in
sequence-to-sequence tasks to enhance mental health research. Specifically, we
illustrate how these models can facilitate the deployment of mental health
instruments, data collection, and data annotation with high accuracy and
scalability. We show that small models are capable of annotation for
domain-specific clinical variables, data collection for mental-health
instruments, and perform better then commercial large models.",http://arxiv.org/abs/2406.12687v1
"As mental health issues globally escalate, there is a tremendous need for
advanced digital support systems. We introduce MentalAgora, a novel framework
employing large language models enhanced by interaction between multiple agents
for tailored mental health support. This framework operates through three
stages: strategic debating, tailored counselor creation, and response
generation, enabling the dynamic customization of responses based on individual
user preferences and therapeutic needs. We conduct experiments utilizing a
high-quality evaluation dataset TherapyTalk crafted with mental health
professionals, shwoing that MentalAgora generates expert-aligned and user
preference-enhanced responses. Our evaluations, including experiments and user
studies, demonstrate that MentalAgora aligns with professional standards and
effectively meets user preferences, setting a new benchmark for digital mental
health interventions.",http://arxiv.org/abs/2407.02736v1
"Mental health has become a growing concern among university students. While
medication is a common treatment, understanding how university students manage
their medication for mental health symptoms in real-world practice has not been
fully explored. In this study, we conducted semi-structured interviews with
university students to understand the unique challenges in the mental health
medication management process and their coping strategies, particularly
examining the role of various technologies in this process. We discovered that
due to struggles with self-acceptance and the interdependent relationship
between medication, symptoms, schedules, and life changes, the medication
management process for students was a highly dynamic journey involving frequent
dosage changes. Thus, students adopted flexible strategies of using minimal
technology to manage their medication in different situations while maintaining
a high degree of autonomy. Based on our findings, we propose design
implications for future technologies to seamlessly integrate into their daily
lives and assist students in managing their mental health medications.",http://arxiv.org/abs/2408.07784v1
"This paper introduces mhGPT, a lightweight generative pre-trained transformer
trained on mental health-related social media and PubMed articles. Fine-tuned
for specific mental health tasks, mhGPT was evaluated under limited hardware
constraints and compared with state-of-the-art models like MentaLLaMA and
Gemma. Despite having only 1.98 billion parameters and using just 5% of the
dataset, mhGPT outperformed larger models and matched the performance of models
trained on significantly more data. The key contributions include integrating
diverse mental health data, creating a custom tokenizer, and optimizing a
smaller architecture for low-resource settings. This research could advance
AI-driven mental health care, especially in areas with limited computing power.",http://arxiv.org/abs/2408.08261v1
"We present TheraGen, an advanced AI-powered mental health chatbot utilizing
the LLaMA 2 7B model. This approach builds upon recent advancements in language
models and transformer architectures. TheraGen provides all-day personalized,
compassionate mental health care by leveraging a large dataset of 1 million
conversational entries, combining anonymized therapy transcripts, online mental
health discussions, and psychological literature, including APA resources. Our
implementation employs transfer learning, fine-tuning, and advanced training
techniques to optimize performance. TheraGen offers a user-friendly interface
for seamless interaction, providing empathetic responses and evidence-based
coping strategies. Evaluation results demonstrate high user satisfaction rates,
with 94% of users reporting improved mental well-being. The system achieved a
BLEU score of 0.67 and a ROUGE score of 0.62, indicating strong response
accuracy. With an average response time of 1395 milliseconds, TheraGen ensures
real-time, efficient support. While not a replacement for professional therapy,
TheraGen serves as a valuable complementary tool, significantly improving user
well-being and addressing the accessibility gap in mental health treatments.
This paper details TheraGen's architecture, training methodology, ethical
considerations, and future directions, contributing to the growing field of
AI-assisted mental healthcare and offering a scalable solution to the pressing
need for mental health support.",http://arxiv.org/abs/2409.13748v1
"This research work delves into the manifestation of hallucination within
Large Language Models (LLMs) and its consequential impacts on applications
within the domain of mental health. The primary objective is to discern
effective strategies for curtailing hallucinatory occurrences, thereby
bolstering the dependability and security of LLMs in facilitating mental health
interventions such as therapy, counseling, and the dissemination of pertinent
information. Through rigorous investigation and analysis, this study seeks to
elucidate the underlying mechanisms precipitating hallucinations in LLMs and
subsequently propose targeted interventions to alleviate their occurrence. By
addressing this critical issue, the research endeavors to foster a more robust
framework for the utilization of LLMs within mental health contexts, ensuring
their efficacy and reliability in aiding therapeutic processes and delivering
accurate information to individuals seeking mental health support.",http://arxiv.org/abs/2410.10853v1
"Left-behind children (LBCs), numbering over 66 million in China, face severe
mental health challenges due to parental migration for work. Early screening
and identification of at-risk LBCs is crucial, yet challenging due to the
severe shortage of mental health professionals, especially in rural areas.
While the House-Tree-Person (HTP) test shows higher child participation rates,
its requirement for expert interpretation limits its application in
resource-scarce regions. To address this challenge, we propose PsyDraw, a
multi-agent system based on Multimodal Large Language Models that assists
mental health professionals in analyzing HTP drawings. The system employs
specialized agents for feature extraction and psychological interpretation,
operating in two stages: comprehensive feature analysis and professional report
generation. Evaluation of HTP drawings from 290 primary school students reveals
that 71.03% of the analyzes achieved High Consistency with professional
evaluations, 26.21% Moderate Consistency and only 2.41% Low Consistency. The
system identified 31.03% of cases requiring professional attention,
demonstrating its effectiveness as a preliminary screening tool. Currently
deployed in pilot schools, \method shows promise in supporting mental health
professionals, particularly in resource-limited areas, while maintaining high
professional standards in psychological assessment.",http://arxiv.org/abs/2412.14769v1
"In the emotion regulation literature, the amount of neuroimaging studies on
cognitive reappraisal led the impression that the same top-down,
control-related neural mechanisms characterize all emotion regulation
strategies. However, top-down processes may coexist with more bottom-up and
emotion-focused processes that partially bypass the recruitment of executive
functions. A case in point is acceptance-based strategies. To better understand
neural commonalities and differences behind different emotion regulation
strategies, in the present study we applied a meta-analytic method to fMRI
studies of task-related activity of reappraisal and acceptance. Results showed
increased activity in left-inferior frontal gyrus and insula for both
strategies, and decreased activity in the basal ganglia for reappraisal, and
decreased activity in limbic regions for acceptance. These findings are
discussed in the context of a model of common and specific neural mechanisms of
emotion regulation that support and expand the previous dual-routes models. We
suggest that emotion regulation may rely on a core inhibitory circuit, and on
strategy-specific top-down and bottom-up processes distinct for different
strategies.",http://arxiv.org/abs/2305.16241v1
"Mental health problems among the global population are worsened during the
coronavirus disease (COVID-19). How individuals engage with online platforms
such as Google Search and YouTube undergoes drastic shifts due to pandemic and
subsequent lockdowns. Such ubiquitous daily behaviors on online platforms have
the potential to capture and correlate with clinically alarming deteriorations
in mental health profiles in a non-invasive manner. The goal of this study is
to examine, among college students, the relationship between deteriorating
mental health conditions and changes in user behaviors when engaging with
Google Search and YouTube during COVID-19. This study recruited a cohort of 49
students from a U.S. college campus during January 2020 (prior to the pandemic)
and measured the anxiety and depression levels of each participant. This study
followed up with the same cohort during May 2020 (during the pandemic), and the
anxiety and depression levels were assessed again. The longitudinal Google
Search and YouTube history data were anonymized and collected. From
individual-level Google Search and YouTube histories, we developed 5 signals
that can quantify shifts in online behaviors during the pandemic. We then
assessed the differences between groups with and without deteriorating mental
health profiles in terms of these features. Significant features included
late-night online activities, continuous usages, and time away from the
internet, porn consumptions, and keywords associated with negative emotions,
social activities, and personal affairs. Though further studies are required,
our results demonstrated the feasibility of utilizing pervasive online data to
establish non-invasive surveillance systems for mental health conditions that
bypasses many disadvantages of existing screening methods.",http://arxiv.org/abs/2009.09076v1
"Vaccination has been promoted to mitigate the spread of the coronavirus
disease 2019 (COVID-19). Vaccination is expected to reduce the probability of
and alleviate the seriousness of COVID-19 infection. Accordingly, this might
significantly change an individuals subjective well-being and mental health.
However, it is unknown how vaccinated people perceive the effectiveness of
COVID-19 and how their subjective well-being and mental health change after
vaccination. We thus observed the same individuals on a monthly basis from
March 2020 to September 2021 in all parts of Japan. Then, large sample panel
data (N=54,007) were independently constructed. Using the data, we compared the
individuals perceptions of COVID-19, subjective well-being, and mental health
before and after vaccination. Furthermore, we compared the effect of
vaccination on the perceptions of COVID-19 and mental health for females and
males. We used the fixed-effects model to control for individual time-invariant
characteristics. The major findings were as follows: First, the vaccinated
people perceived the probability of getting infected and the seriousness of
COVID-19 to be lower than before vaccination. This was observed not only when
we used the whole sample, but also when we used sub-samples. Second, using the
whole sample, subjective well-being and mental health improved. The same
results were also observed using the sub-sample of females, whereas the
improvements were not observed using a sub-sample of males.",http://arxiv.org/abs/2203.07663v1
"The psychotherapy intervention technique is a multifaceted conversation
between a therapist and a patient. Unlike general clinical discussions,
psychotherapy's core components (viz. symptoms) are hard to distinguish, thus
becoming a complex problem to summarize later. A structured counseling
conversation may contain discussions about symptoms, history of mental health
issues, or the discovery of the patient's behavior. It may also contain
discussion filler words irrelevant to a clinical summary. We refer to these
elements of structured psychotherapy as counseling components. In this paper,
the aim is mental health counseling summarization to build upon domain
knowledge and to help clinicians quickly glean meaning. We create a new dataset
after annotating 12.9K utterances of counseling components and reference
summaries for each dialogue. Further, we propose ConSum, a novel
counseling-component guided summarization model. ConSum undergoes three
independent modules. First, to assess the presence of depressive symptoms, it
filters utterances utilizing the Patient Health Questionnaire (PHQ-9), while
the second and third modules aim to classify counseling components. At last, we
propose a problem-specific Mental Health Information Capture (MHIC) evaluation
metric for counseling summaries. Our comparative study shows that we improve on
performance and generate cohesive, semantic, and coherent summaries. We
comprehensively analyze the generated summaries to investigate the capturing of
psychotherapy elements. Human and clinical evaluations on the summary show that
ConSum generates quality summary. Further, mental health experts validate the
clinical acceptability of the ConSum. Lastly, we discuss the uniqueness in
mental health counseling summarization in the real world and show evidences of
its deployment on an online application with the support of mpathic.ai",http://arxiv.org/abs/2206.03886v1
"There has been an increase in research in developing machine learning models
for mental health detection or prediction in recent years due to increased
mental health issues in society. Effective use of mental health prediction or
detection models can help mental health practitioners re-define mental
illnesses more objectively than currently done, and identify illnesses at an
earlier stage when interventions may be more effective. However, there is still
a lack of standard in evaluating bias in such machine learning models in the
field, which leads to challenges in providing reliable predictions and in
addressing disparities. This lack of standards persists due to factors such as
technical difficulties, complexities of high dimensional clinical health data,
etc., which are especially true for physiological signals. This along with
prior evidence of relations between some physiological signals with certain
demographic identities restates the importance of exploring bias in mental
health prediction models that utilize physiological signals. In this work, we
aim to perform a fairness analysis and implement a multi-task learning based
bias mitigation method on anxiety prediction models using ECG data. Our method
is based on the idea of epistemic uncertainty and its relationship with model
weights and feature space representation. Our analysis showed that our anxiety
prediction base model introduced some bias with regards to age, income,
ethnicity, and whether a participant is born in the U.S. or not, and our bias
mitigation method performed better at reducing the bias in the model, when
compared to the reweighting mitigation technique. Our analysis on feature
importance also helped identify relationships between heart rate variability
and multiple demographic groupings.",http://arxiv.org/abs/2208.03621v1
"The latest large language models (LLMs) such as ChatGPT, exhibit strong
capabilities in automated mental health analysis. However, existing relevant
studies bear several limitations, including inadequate evaluations, lack of
prompting strategies, and ignorance of exploring LLMs for explainability. To
bridge these gaps, we comprehensively evaluate the mental health analysis and
emotional reasoning ability of LLMs on 11 datasets across 5 tasks. We explore
the effects of different prompting strategies with unsupervised and distantly
supervised emotional information. Based on these prompts, we explore LLMs for
interpretable mental health analysis by instructing them to generate
explanations for each of their decisions. We convey strict human evaluations to
assess the quality of the generated explanations, leading to a novel dataset
with 163 human-assessed explanations. We benchmark existing automatic
evaluation metrics on this dataset to guide future related works. According to
the results, ChatGPT shows strong in-context learning ability but still has a
significant gap with advanced task-specific methods. Careful prompt engineering
with emotional cues and expert-written few-shot examples can also effectively
improve performance on mental health analysis. In addition, ChatGPT generates
explanations that approach human performance, showing its great potential in
explainable mental health analysis.",http://arxiv.org/abs/2304.03347v4
"Mental health significantly influences various aspects of our daily lives,
and its importance has been increasingly recognized by the research community
and the general public, particularly in the wake of the COVID-19 pandemic. This
heightened interest is evident in the growing number of publications dedicated
to mental health in the past decade. In this study, our goal is to identify
general trends in the field and pinpoint high-impact research topics by
analyzing a large dataset of mental health research papers. To accomplish this,
we collected abstracts from various databases and trained a customized
Sentence-BERT based embedding model leveraging the BERTopic framework. Our
dataset comprises 96,676 research papers pertaining to mental health, enabling
us to examine the relationships between different topics using their abstracts.
To evaluate the effectiveness of the model, we compared it against two other
state-of-the-art methods: Top2Vec model and LDA-BERT model. The model
demonstrated superior performance in metrics that measure topic diversity and
coherence. To enhance our analysis, we also generated word clouds to provide a
comprehensive overview of the machine learning models applied in mental health
research, shedding light on commonly utilized techniques and emerging trends.
Furthermore, we provide a GitHub link* to the dataset used in this paper,
ensuring its accessibility for further research endeavors.",http://arxiv.org/abs/2308.13569v1
"The past decade has been transformative for mental health research and
practice. The ability to harness large repositories of data, whether from
electronic health records (EHR), mobile devices, or social media, has revealed
a potential for valuable insights into patient experiences, promising early,
proactive interventions, as well as personalized treatment plans. Recent
developments in generative artificial intelligence, particularly large language
models (LLMs), show promise in leading digital mental health to uncharted
territory. Patients are arriving at doctors' appointments with information
sourced from chatbots, state-of-the-art LLMs are being incorporated in medical
software and EHR systems, and chatbots from an ever-increasing number of
startups promise to serve as AI companions, friends, and partners. This article
presents contemporary perspectives on the opportunities and risks posed by LLMs
in the design, development, and implementation of digital mental health tools.
We adopt an ecological framework and draw on the affordances offered by LLMs to
discuss four application areas -- care-seeking behaviors from individuals in
need of care, community care provision, institutional and medical care
provision, and larger care ecologies at the societal level. We engage in a
thoughtful consideration of whether and how LLM-based technologies could or
should be employed for enhancing mental health. The benefits and harms our
article surfaces could serve to help shape future research, advocacy, and
regulatory efforts focused on creating more responsible, user-friendly,
equitable, and secure LLM-based tools for mental health treatment and
intervention.",http://arxiv.org/abs/2311.14693v1
"Online mental health support communities have grown in recent years for
providing accessible mental and emotional health support through volunteer
counselors. Despite millions of people participating in chat support on these
platforms, the clinical effectiveness of these communities on mental health
symptoms remains unknown. Furthermore, although volunteers receive some
training based on established therapeutic skills studied in face-to-face
environments such as active listening and motivational interviewing, it remains
understudied how the usage of these skills in this online context affects
people's mental health status. In our work, we collaborate with one of the
largest online peer support platforms and use both natural language processing
and machine learning techniques to measure how one-on-one support chats affect
depression and anxiety symptoms. We measure how the techniques and
characteristics of support providers, such as using affirmation, empathy, and
past experience on the platform, affect support-seekers' mental health changes.
We find that online peer support chats improve both depression and anxiety
symptoms with a statistically significant but relatively small effect size.
Additionally, support providers' techniques such as emphasizing the autonomy of
the client lead to better mental health outcomes. However, we also found that
some behaviors (e.g. persuading) are actually harmful to depression and anxiety
outcomes. Our work provides key understanding for mental health care in the
online setting and designing training systems for online support providers.",http://arxiv.org/abs/2312.10775v1
"Background: Rapid advancements in natural language processing have led to the
development of large language models with the potential to revolutionize mental
health care. These models have shown promise in assisting clinicians and
providing support to individuals experiencing various psychological challenges.
  Objective: This study aims to compare the performance of two large language
models, GPT-4 and Chat-GPT, in responding to a set of 18 psychological prompts,
to assess their potential applicability in mental health care settings.
  Methods: A blind methodology was employed, with a clinical psychologist
evaluating the models' responses without knowledge of their origins. The
prompts encompassed a diverse range of mental health topics, including
depression, anxiety, and trauma, to ensure a comprehensive assessment.
  Results: The results demonstrated a significant difference in performance
between the two models (p > 0.05). GPT-4 achieved an average rating of 8.29 out
of 10, while Chat-GPT received an average rating of 6.52. The clinical
psychologist's evaluation suggested that GPT-4 was more effective at generating
clinically relevant and empathetic responses, thereby providing better support
and guidance to potential users.
  Conclusions: This study contributes to the growing body of literature on the
applicability of large language models in mental health care settings. The
findings underscore the importance of continued research and development in the
field to optimize these models for clinical use. Further investigation is
necessary to understand the specific factors underlying the performance
differences between the two models and to explore their generalizability across
various populations and mental health conditions.",http://arxiv.org/abs/2405.09300v1
"Pre-trained Language Models (PLMs) have the potential to transform mental
health support by providing accessible and culturally sensitive resources.
However, despite this potential, their effectiveness in mental health care and
specifically for the Arabic language has not been extensively explored. To
bridge this gap, this study evaluates the effectiveness of foundational models
for classification of Questions and Answers (Q&A) in the domain of mental
health care. We leverage the MentalQA dataset, an Arabic collection featuring
Q&A interactions related to mental health. In this study, we conducted
experiments using four different types of learning approaches: traditional
feature extraction, PLMs as feature extractors, Fine-tuning PLMs and prompting
large language models (GPT-3.5 and GPT-4) in zero-shot and few-shot learning
settings. While traditional feature extractors combined with Support Vector
Machines (SVM) showed promising performance, PLMs exhibited even better results
due to their ability to capture semantic meaning. For example, MARBERT achieved
the highest performance with a Jaccard Score of 0.80 for question
classification and a Jaccard Score of 0.86 for answer classification. We
further conducted an in-depth analysis including examining the effects of
fine-tuning versus non-fine-tuning, the impact of varying data size, and
conducting error analysis. Our analysis demonstrates that fine-tuning proved to
be beneficial for enhancing the performance of PLMs, and the size of the
training data played a crucial role in achieving high performance. We also
explored prompting, where few-shot learning with GPT-3.5 yielded promising
results. There was an improvement of 12% for question and classification and
45% for answer classification. Based on our findings, it can be concluded that
PLMs and prompt-based approaches hold promise for mental health support in
Arabic.",http://arxiv.org/abs/2406.15966v1
"Mental health disorders are one of the most serious diseases in the world.
Most people with such a disease lack access to adequate care, which highlights
the importance of training models for the diagnosis and treatment of mental
health disorders. However, in the mental health domain, privacy concerns limit
the accessibility of personalized treatment data, making it challenging to
build powerful models. In this paper, we introduce MentalArena, a self-play
framework to train language models by generating domain-specific personalized
data, where we obtain a better model capable of making a personalized diagnosis
and treatment (as a therapist) and providing information (as a patient). To
accurately model human-like mental health patients, we devise Symptom Encoder,
which simulates a real patient from both cognition and behavior perspectives.
To address intent bias during patient-therapist interactions, we propose
Symptom Decoder to compare diagnosed symptoms with encoded symptoms, and
dynamically manage the dialogue between patient and therapist according to the
identified deviations. We evaluated MentalArena against 6 benchmarks, including
biomedicalQA and mental health tasks, compared to 6 advanced models. Our
models, fine-tuned on both GPT-3.5 and Llama-3-8b, significantly outperform
their counterparts, including GPT-4o. We hope that our work can inspire future
research on personalized care. Code is available in
https://github.com/Scarelette/MentalArena/tree/main",http://arxiv.org/abs/2410.06845v1
"Mental health issues significantly impact individuals' daily lives, yet many
do not receive the help they need even with available online resources. This
study aims to provide diverse, accessible, stigma-free, personalized, and
real-time mental health support through cutting-edge AI technologies. It makes
the following contributions: (1) Conducting an extensive survey of recent
mental health support methods to identify prevalent functionalities and unmet
needs. (2) Introducing SouLLMate, an adaptive LLM-driven system that integrates
LLM technologies, Chain, Retrieval-Augmented Generation (RAG), prompt
engineering, and domain knowledge. This system offers advanced features such as
Risk Detection and Proactive Guidance Dialogue, and utilizes RAG for
personalized profile uploads and Conversational Information Extraction. (3)
Developing novel evaluation approaches for preliminary assessments and risk
detection via professionally annotated interview data and real-life suicide
tendency data. (4) Proposing the Key Indicator Summarization (KIS), Proactive
Questioning Strategy (PQS), and Stacked Multi-Model Reasoning (SMMR) methods to
enhance model performance and usability through context-sensitive response
adjustments, semantic coherence evaluations, and enhanced accuracy of
long-context reasoning in language models. This study contributes to advancing
mental health support technologies, potentially improving the accessibility and
effectiveness of mental health care globally.",http://arxiv.org/abs/2410.16322v1
"The crisis of mental health issues is escalating. Effective counseling serves
as a critical lifeline for individuals suffering from conditions like PTSD,
stress, etc. Therapists forge a crucial therapeutic bond with clients, steering
them towards positivity. Unfortunately, the massive shortage of professionals,
high costs, and mental health stigma pose significant barriers to consulting
therapists. As a substitute, Virtual Mental Health Assistants (VMHAs) have
emerged in the digital healthcare space. However, most existing VMHAs lack the
commonsense to understand the nuanced sentiments of clients to generate
effective responses. To this end, we propose EmpRes, a novel sentiment-guided
mechanism incorporating commonsense awareness for generating responses. By
leveraging foundation models and harnessing commonsense knowledge, EmpRes aims
to generate responses that effectively shape the client's sentiment towards
positivity. We evaluate the performance of EmpRes on HOPE, a benchmark
counseling dataset, and observe a remarkable performance improvement compared
to the existing baselines across a suite of qualitative and quantitative
metrics. Moreover, our extensive empirical analysis and human evaluation show
that the generation ability of EmpRes is well-suited and, in some cases,
surpasses the gold standard. Further, we deploy EmpRes as a chat interface for
users seeking mental health support. We address the deployed system's
effectiveness through an exhaustive user study with a significant positive
response. Our findings show that 91% of users find the system effective, 80%
express satisfaction, and over 85.45% convey a willingness to continue using
the interface and recommend it to others, demonstrating the practical
applicability of EmpRes in addressing the pressing challenges of mental health
support, emphasizing user feedback, and ethical considerations in a real-world
context.",http://arxiv.org/abs/2501.03088v1
"Large language models (LLMs) have attracted significant attention for
potential applications in digital health, while their application in mental
health is subject to ongoing debate. This systematic review aims to evaluate
the usage of LLMs in mental health, focusing on their strengths and limitations
in early screening, digital interventions, and clinical applications. Adhering
to PRISMA guidelines, we searched PubMed, IEEE Xplore, Scopus, JMIR, and ACM
using keywords: 'mental health OR mental illness OR mental disorder OR
psychiatry' AND 'large language models'. We included articles published between
January 1, 2017, and April 30, 2024, excluding non-English articles. 30
articles were evaluated, which included research on mental health conditions
and suicidal ideation detection through text (n=15), usage of LLMs for mental
health conversational agents (CAs) (n=7), and other applications and
evaluations of LLMs in mental health (n=18). LLMs exhibit substantial
effectiveness in detecting mental health issues and providing accessible,
de-stigmatized eHealth services. However, the current risks associated with the
clinical use might surpass their benefits. The study identifies several
significant issues: the lack of multilingual datasets annotated by experts,
concerns about the accuracy and reliability of the content generated,
challenges in interpretability due to the 'black box' nature of LLMs, and
persistent ethical dilemmas. These include the lack of a clear ethical
framework, concerns about data privacy, and the potential for over-reliance on
LLMs by both therapists and patients, which could compromise traditional
medical practice. Despite these issues, the rapid development of LLMs
underscores their potential as new clinical aids, emphasizing the need for
continued research and development in this area.",http://arxiv.org/abs/2403.15401v3
"Depression has been a leading cause of mental-health illnesses across the
world. While the loss of lives due to unmanaged depression is a subject of
attention, so is the lack of diagnostic tests and subjectivity involved. Using
behavioural cues to automate depression diagnosis and stage prediction in
recent years has relatively increased. However, the absence of labelled
behavioural datasets and a vast amount of possible variations prove to be a
major challenge in accomplishing the task. This paper proposes a novel Custom
CM Ensemble approach and focuses on a paradigm of a cross-platform smartphone
application that takes multimodal inputs from a user through a series of
pre-defined questions, sends it to the Cloud ML architecture and conveys back a
depression quotient, representative of its severity. Our app estimates the
severity of depression based on a multi-class classification model by utilizing
the language, audio, and visual modalities. The given approach attempts to
detect, emphasize, and classify the features of a depressed person based on the
low-level descriptors for verbal and visual features, and context of the
language features when prompted with a question. The model achieved a precision
value of 0.88 and an accuracy of 91.56%. Further optimization reveals the
intramodality and intermodality relevance through the selection of the most
influential features within each modality for decision making.",http://arxiv.org/abs/2009.05651v2
"With the increasing demands of emotion comprehension and regulation in our
daily life, a customized music-based emotion regulation system is introduced by
employing current EEG information and song features, which predicts users'
emotion variation in the valence-arousal model before recommending music. The
work shows that: (1) a novel music-based emotion regulation system with a
commercial EEG device is designed without employing deterministic emotion
recognition models for daily usage; (2) the system considers users' variant
emotions towards the same song, and by which calculate user's emotion
instability and it is in accordance with Big Five Personality Test; (3) the
system supports different emotion regulation styles with users' designation of
desired emotion variation, and achieves an accuracy of over $0.85$ with
2-seconds EEG data; (4) people feel easier to report their emotion variation
comparing with absolute emotional states, and would accept a more delicate
music recommendation system for emotion regulation according to the
questionnaire.",http://arxiv.org/abs/2211.14609v1
"Effective communication and strong therapeutic relationships are critical to
successful mental health interventions. For example, in 1957 Carl Rogers, a
pioneer of person-centred therapy, proposed that an empowering relationship
could, in and of itself, create the necessary and sufficient conditions for
positive therapeutic outcomes [1]. Whilst modern psychological theories no
longer favour an exclusive focus on relationships, positive relationships and
the dynamics of client-therapist communication remain cornerstones of mental
health intervention theories. A more recent meta-review concluded that across
all interventions models, irrespective of the theoretical approach, the quality
of the relationship between therapists and clients is the second leading
determinant of successful clinical outcomes [2]. Over the past ten years we
(David Coyle and Gavin Doherty) have designed and evaluated a wide range to
systems that provide support for psychological (or talk- based) mental health
interventions [3]. Here we briefly consider two recent examples. In each case
our aim was to enhance communication and reshape clinical practice in a manner
that empowers patients. gNats Island is a computer game that supports
face-to-face interventions for adolescents [4]. MindBalance is an online
treatment programme for adults experiencing difficulties with depression [5].",http://arxiv.org/abs/1307.3164v1
"Using the metrics of the World Health Organisation, the Global Burden of
Disease Study has found that mental health difficulties are currently the
leading cause of disability in developed countries [1]. Projections also
indicate that the global burden of mental health difficulties will continue to
rise in the coming decades. The human and economic costs of this trend will be
substantial. In this paper we discuss how effectively designed interactive
systems, developed through collaborative, interdisciplinary efforts, can play a
significant role in helping to address this challenge. Our discussion is
grounded in a description of four exploratory systems, each of which has
undergone initial clinical evaluations. Directions for future research on
mental health technologies are also identified.",http://arxiv.org/abs/1307.3174v1
"Heart rate (HR) and its variability (HRV) has been proposed as a marker for
depressive symptoms and other aspects of mental health. However, the real
correlation between them is presently uncertain, as previous studies have
generally been conducted on the basis of small samples. In a sample of 113
adult male prisoners, we analyzed correlations between five measures of HR/HRV
and five psychological measures of mental health aspects (depression, state and
trait anxiety, and social relationships). We used Nadaraya-Watson
non-parametric regression in both directions and age-stratified Spearman
correlation to detect possible relations. Despite strong correlations among
HR/HRV measures and among psychological measures, correlations between HR/HRV
and psychological measures were low and non-significant for the overall sample.
However, we found an age dependency, suggesting some correlations in younger
people (HR with STAI-State, r = 0.39; with HADS-Anxiety, r = 0.52; both p <
.005). Overall, the general utility of HR/HRV as a marker for mental health
across populations remains unclear. Future research should address age and
other potential confounders more consistently.",http://arxiv.org/abs/1501.05842v1
"The intersection of data visualization and human-robot interaction (HRI) is a
burgeoning field. Understanding, communicating, and processing different kinds
of data for creating versatile visualizations can benefit HRI. Conversely,
expressing different kinds of data generated from HRI through effective
visualizations can provide interesting insights. Our work adds to the
literature of this growing domain. In this paper, we present our exploratory
work on visualizing mental health data on a social robot. Particularly, we
discuss development of mental health data visualizations using a participatory
design (PD) approach. As a first step with mental health data visualization on
a social robot, this work paves the way for relevant further work and using
social robots as data visualization tools.",http://arxiv.org/abs/2210.06469v1
"Mental health resources available via websites and mobile apps provide
support such as advice, journaling, and elements from cognitive behavioral
therapy. The proliferation of spoken conversational agents, such as Alexa,
Siri, and Google Home, has led to an increasing interest in developing mental
health apps for these devices. We present the pilot study outcomes of an Alexa
Skill that allows users to conduct depression and anxiety self-tests. Ten
participants were given access to the Alexa Skill for two-weeks, followed by an
online evaluation of the Skill's usability and trust. Our preliminary
evaluation suggests that participants trusted the Skill and scored the
usability and user experience as average. Usage of the Skill was low, with most
participants using the Skill only once. In view of work-in-progress, we also
present a discussion of implementation and study design challenges to guide the
current literature on designing spoken conversational agents for mental health
applications.",http://arxiv.org/abs/2008.03892v1
"Application of Machine Learning algorithms to the medical domain is an
emerging trend that helps to advance medical knowledge. At the same time, there
is a significant a lack of explainable studies that promote informed,
transparent, and interpretable use of Machine Learning algorithms. In this
paper, we present explainable multi-class classification of the Covid-19 mental
health data. In Machine Learning study, we aim to find the potential factors to
influence a personal mental health during the Covid-19 pandemic. We found that
Random Forest (RF) and Gradient Boosting (GB) have scored the highest accuracy
of 68.08% and 68.19% respectively, with LIME prediction accuracy 65.5% for RF
and 61.8% for GB. We then compare a Post-hoc system (Local Interpretable
Model-Agnostic Explanations, or LIME) and an Ante-hoc system (Gini Importance)
in their ability to explain the obtained Machine Learning results. To the best
of these authors knowledge, our study is the first explainable Machine Learning
study of the mental health data collected during Covid-19 pandemics.",http://arxiv.org/abs/2105.13430v1
"""For how many days during the past 30 days was your mental health not good?""
The responses to this question measure self-reported mental health and can be
linked to important covariates in the National Health and Nutrition Examination
Survey (NHANES). However, these count variables present major distributional
challenges: the data are overdispersed, zero-inflated, bounded by 30, and
heaped in five- and seven-day increments. To meet these challenges, we design a
semiparametric estimation and inference framework for count data regression.
The data-generating process is defined by simultaneously transforming and
rounding (STAR) a latent Gaussian regression model. The transformation is
estimated nonparametrically and the rounding operator ensures the correct
support for the discrete and bounded data. Maximum likelihood estimators are
computed using an EM algorithm that is compatible with any continuous data
model estimable by least squares. STAR regression includes asymptotic
hypothesis testing and confidence intervals, variable selection via information
criteria, and customized diagnostics. Simulation studies validate the utility
of this framework. STAR is deployed to study the factors associated with
self-reported mental health and demonstrates substantial improvements in
goodness-of-fit compared to existing count data regression models.",http://arxiv.org/abs/2106.09114v2
"Student's mental health problems have been explored previously in higher
education literature in various contexts including empirical work involving
quantitative and qualitative methods. Nevertheless, comparatively few research
could be found, aiming for computational methods that learn information
directly from data without relying on set parameters for a predetermined
equation as an analytical method. This study aims to investigate the
performance of Machine learning (ML) models used in higher education. ML models
considered are Naive Bayes, Support Vector Machine, K-Nearest Neighbor,
Logistic regression, Stochastic Gradient Descent, Decision Tree, Random Forest,
XGBoost (Extreme Gradient Boosting Decision Tree), and NGBoost (Natural)
algorithm. Considering the factors of mental health illness among students, we
follow three phases of data processing: segmentation, feature extraction, and
classification. We evaluate these ML models against classification performance
metrics such as accuracy, precision, recall, F1 score, and predicted run time.
The empirical analysis includes two contributions: 1. It examines the
performance of various ML models on a survey-based educational dataset,
inferring a significant classification performance by a tree-based XGBoost
algorithm; 2. It explores the feature importance [variables] from the datasets
to infer the significant importance of social support, learning environment,
and childhood adversities on a student's mental health illness.",http://arxiv.org/abs/2202.13495v1
"This paper studies the short-term effects of ambient temperature on mental
health using data on nearly half a million helpline calls in Germany.
Leveraging location-based routing of helpline calls and random day-to-day
weather fluctuations, I find a negative effect of temperature extremes on
mental health as revealed by an increase in the demand for telephone counseling
services. On days with an average temperature above 25{\deg}C (77{\deg}F) and
below 0{\deg}C (32{\deg}F), call volume is 3.4 and 5.1 percent higher,
respectively, than on mid-temperature days. Mechanism analysis reveals
pronounced adverse effects of cold temperatures on social and psychological
well-being and of hot temperatures on psychological well-being and violence.
More broadly, the findings of this work contribute to our understanding of how
changing climatic conditions will affect population mental health and
associated social costs in the near future.",http://arxiv.org/abs/2207.04992v2
"Mental health disorders may cause severe consequences on all the countries'
economies and health. For example, the impacts of the COVID-19 pandemic, such
as isolation and travel ban, can make us feel depressed. Identifying early
signs of mental health disorders is vital. For example, depression may increase
an individual's risk of suicide. The state-of-the-art research in identifying
mental disorder patterns from textual data, uses hand-labelled training sets,
especially when a domain expert's knowledge is required to analyse various
symptoms. This task could be time-consuming and expensive. To address this
challenge, in this paper, we study and analyse the various clinical and
non-clinical approaches to identifying mental health disorders. We leverage the
domain knowledge and expertise in cognitive science to build a domain-specific
Knowledge Base (KB) for the mental health disorder concepts and patterns. We
present a weaker form of supervision by facilitating the generating of training
data from a domain-specific Knowledge Base (KB). We adopt a typical scenario
for analysing social media to identify major depressive disorder symptoms from
the textual content generated by social users. We use this scenario to evaluate
how our knowledge-based approach significantly improves the quality of results.",http://arxiv.org/abs/2207.06254v1
"There has been a significant expansion in the use of online social networks
(OSNs) to support people experiencing mental health issues. This paper studies
the role of Instagram influencers who specialize in coaching people with mental
health issues. Using a dataset of 97k posts, we characterize such users'
linguistic and behavioural features. We explore how these observations impact
audience engagement (as measured by likes). We show that the support provided
by these accounts varies based on their self-declared professional identities.
For instance, Instagram accounts that declare themselves as Authors offer less
support than accounts that label themselves as Coach. We show that increasing
information support in general communication positively affects user
engagement. However, the effect of vocabulary on engagement is not consistent
across the Instagram account types. Our findings shed light on this
understudied topic and guide how mental health practitioners can improve
outreach.",http://arxiv.org/abs/2211.06013v1
"Proper allocation of law enforcement resources remains a critical issue in
crime prediction and prevention that operates by characterizing spatially
aggregated crime activities and a multitude of predictor variables of interest.
Despite the critical nature of proper resource allocation for mental health
incidents, there has been little progress in statistical modeling of the
geo-spatial nature of mental health events in Little Rock, Arkansas. In this
article, we provide insights into the spatial nature of mental health data from
Little Rock, Arkansas between 2015 and 2018, under a supervised spatial
modeling framework while extending the popular risk terrain modeling (Caplan et
al., 2011, 2015; Drawve, 2016) approach. We provide evidence of spatial
clustering and identify the important features influencing such heterogeneity
via a spatially informed hierarchy of generalized linear models, spatial
regression models and a tree based method, viz., Poisson regression, spatial
Durbin error model, Manski model and Random Forest. The insights obtained from
these different models are presented here along with their relative predictive
performances. The inferential tools developed here can be used in a broad
variety of spatial modeling contexts and have the potential to aid both law
enforcement agencies and the city in properly allocating resources.",http://arxiv.org/abs/2212.05486v1
"In recent years, there has been a surge of interest in research on automatic
mental health detection (MHD) from social media data leveraging advances in
natural language processing and machine learning techniques. While significant
progress has been achieved in this interdisciplinary research area, the vast
majority of work has treated MHD as a binary classification task. The
multiclass classification setup is, however, essential if we are to uncover the
subtle differences among the statistical patterns of language use associated
with particular mental health conditions. Here, we report on experiments aimed
at predicting six conditions (anxiety, attention deficit hyperactivity
disorder, bipolar disorder, post-traumatic stress disorder, depression, and
psychological stress) from Reddit social media posts. We explore and compare
the performance of hybrid and ensemble models leveraging transformer-based
architectures (BERT and RoBERTa) and BiLSTM neural networks trained on
within-text distributions of a diverse set of linguistic features. This set
encompasses measures of syntactic complexity, lexical sophistication and
diversity, readability, and register-specific ngram frequencies, as well as
sentiment and emotion lexicons. In addition, we conduct feature ablation
experiments to investigate which types of features are most indicative of
particular mental health conditions.",http://arxiv.org/abs/2212.09839v1
"Mental health counseling remains a major challenge in modern society due to
cost, stigma, fear, and unavailability. We posit that generative artificial
intelligence (AI) models designed for mental health counseling could help
improve outcomes by lowering barriers to access. To this end, we have developed
a deep learning (DL) dialogue system called Serena. The system consists of a
core generative model and post-processing algorithms. The core generative model
is a 2.7 billion parameter Seq2Seq Transformer fine-tuned on thousands of
transcripts of person-centered-therapy (PCT) sessions. The series of
post-processing algorithms detects contradictions, improves coherency, and
removes repetitive answers. Serena is implemented and deployed on
\url{https://serena.chat}, which currently offers limited free services. While
the dialogue system is capable of responding in a qualitatively empathetic and
engaging manner, occasionally it displays hallucination and long-term
incoherence. Overall, we demonstrate that a deep learning mental health
dialogue system has the potential to provide a low-cost and effective
complement to traditional human counselors with less barriers to access.",http://arxiv.org/abs/2301.09412v1
"Large language models (LLM) have been successful in several natural language
understanding tasks and could be relevant for natural language processing
(NLP)-based mental health application research. In this work, we report the
performance of LLM-based ChatGPT (with gpt-3.5-turbo backend) in three
text-based mental health classification tasks: stress detection (2-class
classification), depression detection (2-class classification), and suicidality
detection (5-class classification). We obtained annotated social media posts
for the three classification tasks from public datasets. Then ChatGPT API
classified the social media posts with an input prompt for classification. We
obtained F1 scores of 0.73, 0.86, and 0.37 for stress detection, depression
detection, and suicidality detection, respectively. A baseline model that
always predicted the dominant class resulted in F1 scores of 0.35, 0.60, and
0.19. The zero-shot classification accuracy obtained with ChatGPT indicates a
potential use of language models for mental health classification tasks.",http://arxiv.org/abs/2303.15727v1
"Psychiatrists diagnose mental disorders via the linguistic use of patients.
Still, due to data privacy, existing passive mental health monitoring systems
use alternative features such as activity, app usage, and location via mobile
devices. We propose FedTherapist, a mobile mental health monitoring system that
utilizes continuous speech and keyboard input in a privacy-preserving way via
federated learning. We explore multiple model designs by comparing their
performance and overhead for FedTherapist to overcome the complex nature of
on-device language model training on smartphones. We further propose a
Context-Aware Language Learning (CALL) methodology to effectively utilize
smartphones' large and noisy text for mental health signal sensing. Our
IRB-approved evaluation of the prediction of self-reported depression, stress,
anxiety, and mood from 46 participants shows higher accuracy of FedTherapist
compared with the performance with non-language features, achieving 0.15 AUROC
improvement and 8.21% MAE reduction.",http://arxiv.org/abs/2310.16538v1
"People with dementia (PwD) often present verbal agitation such as cursing,
screaming, and persistently complaining. Verbal agitation can impose mental
distress on informal caregivers (e.g., family, friends), which may cause severe
mental illnesses, such as depression and anxiety disorders. To improve informal
caregivers' mental health, we explore design opportunities by interviewing 11
informal caregivers suffering from verbal agitation of PwD. In particular, we
first characterize how the predictability of verbal agitation impacts informal
caregivers' mental health and how caregivers' coping strategies vary before,
during, and after verbal agitation. Based on our findings, we propose design
opportunities to improve the mental health of informal caregivers suffering
from verbal agitation: distracting PwD (in-situ support; before), prompting
just-in-time maneuvers (information support; during), and comfort and education
(social & information support; after). We discuss our reflections on cultural
disparities between participants. Our work envisions a broader design space for
supporting informal caregivers' well-being and describes when and how that
support could be provided.",http://arxiv.org/abs/2311.10912v1
"Large Language Models (LLMs) have become valuable assets in mental health,
showing promise in both classification tasks and counseling applications. This
paper offers a perspective on using LLMs in mental health applications. It
discusses the instability of generative models for prediction and the potential
for generating hallucinatory outputs, underscoring the need for ongoing audits
and evaluations to maintain their reliability and dependability. The paper also
distinguishes between the often interchangeable terms ``explainability'' and
``interpretability'', advocating for developing inherently interpretable
methods instead of relying on potentially hallucinated self-explanations
generated by LLMs. Despite the advancements in LLMs, human counselors'
empathetic understanding, nuanced interpretation, and contextual awareness
remain irreplaceable in the sensitive and complex realm of mental health
counseling. The use of LLMs should be approached with a judicious and
considerate mindset, viewing them as tools that complement human expertise
rather than seeking to replace it.",http://arxiv.org/abs/2311.11267v2
"Dialogue systems are increasingly integrated into mental health support to
help clients facilitate exploration, gain insight, take action, and ultimately
heal themselves. A practical and user-friendly dialogue system should be
client-centric, focusing on the client's behaviors. However, existing dialogue
systems publicly available for mental health support often concentrate solely
on the counselor's strategies rather than the behaviors expressed by clients.
This can lead to unreasonable or inappropriate counseling strategies and
corresponding responses generated by the dialogue system. To address this
issue, we propose PsyChat, a client-centric dialogue system that provides
psychological support through online chat. The client-centric dialogue system
comprises five modules: client behavior recognition, counselor strategy
selection, input packer, response generator, and response selection. Both
automatic and human evaluations demonstrate the effectiveness and practicality
of our proposed dialogue system for real-life mental health support.
Furthermore, the case study demonstrates that the dialogue system can predict
the client's behaviors, select appropriate counselor strategies, and generate
accurate and suitable responses.",http://arxiv.org/abs/2312.04262v2
"Social media usage has been shown to have both positive and negative
consequences for users' mental health. Several studies indicated that peer
feedback plays an important role in the relationship between social media use
and mental health. In this research, we analyse the impact of receiving online
feedback on users' emotional experience, social connectedness and self-esteem.
In an experimental study, we let users interact with others on a Facebook-like
system over the course of a week while controlling for the amount of positive
reactions they receive from their peers. We find that experiencing little to no
reaction from others does not only elicit negative emotions and stress amongst
users, but also induces low levels of self-esteem. In contrast, receiving much
positive online feedback, evokes feelings of social connectedness and reduces
overall loneliness. On a societal level, our study can help to better
understand the mechanisms through which social media use impacts mental health
in a positive or negative way. On a methodological level, we provide a new
open-source tool for designing and conducting social media experiments.",http://arxiv.org/abs/2312.11914v1
"Mental health challenges pose considerable global burdens on individuals and
communities. Recent data indicates that more than 20% of adults may encounter
at least one mental disorder in their lifetime. On the one hand, the
advancements in large language models have facilitated diverse applications,
yet a significant research gap persists in understanding and enhancing the
potential of large language models within the domain of mental health. On the
other hand, across various applications, an outstanding question involves the
capacity of large language models to comprehend expressions of human mental
health conditions in natural language. This study presents an initial
evaluation of large language models in addressing this gap. Due to this, we
compare the performance of Llama-2 and ChatGPT with classical Machine as well
as Deep learning models. Our results on the DAIC-WOZ dataset show that
transformer-based models, like BERT or XLNet, outperform the large language
models.",http://arxiv.org/abs/2401.04592v2
"Mental health is a pressing concern in today's digital age, particularly
among youth who are deeply intertwined with technology. Despite the influx of
technology solutions addressing mental health issues, youth often remain
sidelined during the design process. While co-design methods have been employed
to improve participation by youth, many such initiatives are limited to design
activities and lack training for youth to research and develop solutions for
themselves. In this case study, we detail our 8-week remote, collaborative
research initiative called Youth WellTech, designed to facilitate remote
co-design sprints aimed at equipping youth with the tools and knowledge to
envision and design tech futures for their own communities. We pilot this
initiative with 12 student technology evangelists across 8 countries globally
to foster the sharing of mental health challenges and diverse perspectives. We
highlight insights from our experiences running this global program remotely,
its structure, and recommendations for co-research.",http://arxiv.org/abs/2401.05824v1
"Prior research on young adults' mental health help-seeking mostly focuses on
one particular resource such as a mobile app or digital platform, paying less
attention to their lived experiences interacting with the ecosystem of
resources. We conducted in-depth interviews with 18 participants about their
help-seeking and non-help-seeking experiences. Guided by Social Ecological
Theory, we proposed a Socio-technical Ecosystem Framework for mental health
care, consisting of four levels of resources, including technological-,
interpersonal-, community-, and societal level resources. Using this framework,
we identified two types of support systems for help-seeking, single-resource
support system and multi-resource support system. These resources support young
adults' help-seeking via three mechanisms, \textit{care-giving},
\textit{care-mediating}, and \textit{care-outreaching}, forming various
pathways to care. We then pointed out the barriers to resource use at each
level and the general challenges in finding a support system. Our findings
contributed to a conceptual framework to categorize mental health care. It also
serves as a practical framework to identify challenges in the pathways to care
and discover design implications.",http://arxiv.org/abs/2401.08994v1
"LGBTQ+ individuals are increasingly turning to chatbots powered by large
language models (LLMs) to meet their mental health needs. However, little
research has explored whether these chatbots can adequately and safely provide
tailored support for this demographic. We interviewed 18 LGBTQ+ and 13
non-LGBTQ+ participants about their experiences with LLM-based chatbots for
mental health needs. LGBTQ+ participants relied on these chatbots for mental
health support, likely due to an absence of support in real life. Notably,
while LLMs offer prompt support, they frequently fall short in grasping the
nuances of LGBTQ-specific challenges. Although fine-tuning LLMs to address
LGBTQ+ needs can be a step in the right direction, it isn't the panacea. The
deeper issue is entrenched in societal discrimination. Consequently, we call on
future researchers and designers to look beyond mere technical refinements and
advocate for holistic strategies that confront and counteract the societal
biases burdening the LGBTQ+ community.",http://arxiv.org/abs/2402.09260v1
"Despite the increasing demand for AI-based mental health monitoring tools,
their practical utility for clinicians is limited by the lack of
interpretability.The CLPsych 2024 Shared Task (Chim et al., 2024) aims to
enhance the interpretability of Large Language Models (LLMs), particularly in
mental health analysis, by providing evidence of suicidality through linguistic
content. We propose a dual-prompting approach: (i) Knowledge-aware evidence
extraction by leveraging the expert identity and a suicide dictionary with a
mental health-specific LLM; and (ii) Evidence summarization by employing an
LLM-based consistency evaluator. Comprehensive experiments demonstrate the
effectiveness of combining domain-specific information, revealing performance
improvements and the approach's potential to aid clinicians in assessing mental
state progression.",http://arxiv.org/abs/2402.14854v1
"This paper addresses the quality of annotations in mental health datasets
used for NLP-based depression level estimation from social media texts. While
previous research relies on social media-based datasets annotated with binary
categories, i.e. depressed or non-depressed, recent datasets such as D2S and
PRIMATE aim for nuanced annotations using PHQ-9 symptoms. However, most of
these datasets rely on crowd workers without the domain knowledge for
annotation. Focusing on the PRIMATE dataset, our study reveals concerns
regarding annotation validity, particularly for the lack of interest or
pleasure symptom. Through reannotation by a mental health professional, we
introduce finer labels and textual spans as evidence, identifying a notable
number of false positives. Our refined annotations, to be released under a Data
Use Agreement, offer a higher-quality test set for anhedonia detection. This
study underscores the necessity of addressing annotation quality issues in
mental health datasets, advocating for improved methodologies to enhance NLP
model reliability in mental health assessments.",http://arxiv.org/abs/2403.00438v1
"The intersections of mental health and computing education is under-examined.
In this systematic literature review, we evaluate the state-of-the-art of
research in mental health and well-being interventions, assessments, and
concerns like anxiety and depression in computer science and computing
education. The studies evaluated occurred across the computing education
pipeline from introductory to PhD courses and found some commonalities
contributing to high reporting of anxiety and depression in those studied. In
addition, interventions that were designed to address mental health topics
often revolved around self-guidance. Based on our review of the literature, we
recommend increasing sample sizes and focusing on the design and development of
tools and interventions specifically designed for computing professionals and
students.",http://arxiv.org/abs/2405.03416v1
"The limited availability of psychologists necessitates efficient
identification of individuals requiring urgent mental healthcare. This study
explores the use of Natural Language Processing (NLP) pipelines to analyze text
data from online mental health forums used for consultations. By analyzing
forum posts, these pipelines can flag users who may require immediate
professional attention. A crucial challenge in this domain is data privacy and
scarcity. To address this, we propose utilizing readily available curricular
texts used in institutes specializing in mental health for pre-training the NLP
pipelines. This helps us mimic the training process of a psychologist. Our work
presents CASE-BERT that flags potential mental health disorders based on forum
text. CASE-BERT demonstrates superior performance compared to existing methods,
achieving an f1 score of 0.91 for Depression and 0.88 for Anxiety, two of the
most commonly reported mental health disorders. Our code and data are publicly
available.",http://arxiv.org/abs/2406.00314v3
"The advancement of large language models (LLMs) has demonstrated strong
capabilities across various applications, including mental health analysis.
However, existing studies have focused on predictive performance, leaving the
critical issue of fairness underexplored, posing significant risks to
vulnerable populations. Despite acknowledging potential biases, previous works
have lacked thorough investigations into these biases and their impacts. To
address this gap, we systematically evaluate biases across seven social factors
(e.g., gender, age, religion) using ten LLMs with different prompting methods
on eight diverse mental health datasets. Our results show that GPT-4 achieves
the best overall balance in performance and fairness among LLMs, although it
still lags behind domain-specific models like MentalRoBERTa in some cases.
Additionally, our tailored fairness-aware prompts can effectively mitigate bias
in mental health predictions, highlighting the great potential for fair
analysis in this field.",http://arxiv.org/abs/2406.12033v2
"As we build towards developing interactive systems that can recognize human
emotional states and respond to individual needs more intuitively and
empathetically in more personalized and context-aware computing time. This is
especially important regarding mental health support, with a rising need for
immediate, non-intrusive help tailored to each individual. Individual mental
health and the complex nature of human emotions call for novel approaches
beyond conventional proactive and reactive-based chatbot approaches. In this
position paper, we will explore how to create Chatbots that can sense,
interpret, and intervene in emotional signals by combining real-time facial
expression analysis, physiological signal interpretation, and language models.
This is achieved by incorporating facial affect detection into existing
practical and ubiquitous passive sensing contexts, thus empowering them with
the capabilities to the ubiquity of sensing behavioral primitives to recognize,
interpret, and respond to human emotions. In parallel, the system employs
cognitive-behavioral therapy tools such as cognitive reframing and mood
journals, leveraging the therapeutic intervention potential of Chatbots in
mental health contexts. Finally, we propose a project to build a system that
enhances the emotional understanding of Chatbots to engage users in chat-based
intervention, thereby helping manage their mood.",http://arxiv.org/abs/2406.15942v1
"We aim to develop a tool for understanding how the mental health of youth
aged less than 18 years evolve over time through administrative records of
mental health related emergency department (MHED) visits in two decades.
Administrative health data usually contain rich information for investigating
public health issues; however, many restrictions and regulations apply to their
use. Moreover, the data are usually not in a conventional format since
administrative databases are created and maintained to serve non-research
purposes and only information for people who seek health services is
accessible. Analysis of administrative health data is thus challenging in
general. In the MHED data analyses, we are particularly concerned with (i)
evaluating dynamic patterns and impacts with doubly-censored recurrent event
data, and (ii) re-calibrating estimators developed based on truncated data by
leveraging summary statistics from the population. The findings are verified
empirically via simulation. We have established the asymptotic properties of
the inference procedures. The contributions of this paper are twofold. We
present innovative strategies for processing doubly-censored recurrent event
data, and overcoming the truncation induced by the data collection. In
addition, through exploring the pediatric MHED visit records, we provide new
insights into children/youths mental health changes over time.",http://arxiv.org/abs/2407.09761v1
"This study introduces 'Psycho Analyst', a custom GPT model based on OpenAI's
GPT-4, optimized for pre-screening mental health disorders. Enhanced with
DSM-5, PHQ-8, detailed data descriptions, and extensive training data, the
model adeptly decodes nuanced linguistic indicators of mental health disorders.
It utilizes a dual-task framework that includes binary classification and a
three-stage PHQ-8 score computation involving initial assessment, detailed
breakdown, and independent assessment, showcasing refined analytic
capabilities. Validation with the DAIC-WOZ dataset reveals F1 and Macro-F1
scores of 0.929 and 0.949, respectively, along with the lowest MAE and RMSE of
2.89 and 3.69 in PHQ-8 scoring. These results highlight the model's precision
and transformative potential in enhancing public mental health support,
improving accessibility, cost-effectiveness, and serving as a second opinion
for professionals.",http://arxiv.org/abs/2408.01614v2
"Integrating physiological signals such as electroencephalogram (EEG), with
other data such as interview audio, may offer valuable multimodal insights into
psychological states or neurological disorders. Recent advancements with Large
Language Models (LLMs) position them as prospective ``health agents'' for
mental health assessment. However, current research predominantly focus on
single data modalities, presenting an opportunity to advance understanding
through multimodal data. Our study aims to advance this approach by
investigating multimodal data using LLMs for mental health assessment,
specifically through zero-shot and few-shot prompting. Three datasets are
adopted for depression and emotion classifications incorporating EEG, facial
expressions, and audio (text). The results indicate that multimodal information
confers substantial advantages over single modality approaches in mental health
assessment. Notably, integrating EEG alongside commonly used LLM modalities
such as audio and images demonstrates promising potential. Moreover, our
findings reveal that 1-shot learning offers greater benefits compared to
zero-shot learning methods.",http://arxiv.org/abs/2408.07313v1
"In this study, we introduce ANGST, a novel, first-of-its kind benchmark for
depression-anxiety comorbidity classification from social media posts. Unlike
contemporary datasets that often oversimplify the intricate interplay between
different mental health disorders by treating them as isolated conditions,
ANGST enables multi-label classification, allowing each post to be
simultaneously identified as indicating depression and/or anxiety. Comprising
2876 meticulously annotated posts by expert psychologists and an additional
7667 silver-labeled posts, ANGST posits a more representative sample of online
mental health discourse. Moreover, we benchmark ANGST using various
state-of-the-art language models, ranging from Mental-BERT to GPT-4. Our
results provide significant insights into the capabilities and limitations of
these models in complex diagnostic scenarios. While GPT-4 generally outperforms
other models, none achieve an F1 score exceeding 72% in multi-class comorbid
classification, underscoring the ongoing challenges in applying language models
to mental health diagnostics.",http://arxiv.org/abs/2410.03908v1
"In domain-specific contexts, particularly mental health, abstractive
summarization requires advanced techniques adept at handling specialized
content to generate domain-relevant and faithful summaries. In response to
this, we introduce a guided summarizer equipped with a dual-encoder and an
adapted decoder that utilizes novel domain-specific guidance signals, i.e.,
mental health terminologies and contextually rich sentences from the source
document, to enhance its capacity to align closely with the content and context
of guidance, thereby generating a domain-relevant summary. Additionally, we
present a post-editing correction model to rectify errors in the generated
summary, thus enhancing its consistency with the original content in detail.
Evaluation on the MentSum dataset reveals that our model outperforms existing
baseline models in terms of both ROUGE and FactCC scores. Although the
experiments are specifically designed for mental health posts, the methodology
we've developed offers broad applicability, highlighting its versatility and
effectiveness in producing high-quality domain-specific summaries.",http://arxiv.org/abs/2411.01485v1
"The intersection of technology and mental health has spurred innovative
approaches to assessing emotional well-being, particularly through
computational techniques applied to audio data analysis. This study explores
the application of Convolutional Neural Network (CNN) and Long Short-Term
Memory (LSTM) models on wavelet extracted features and Mel-frequency Cepstral
Coefficients (MFCCs) for emotion detection from spoken speech. Data
augmentation techniques, feature extraction, normalization, and model training
were conducted to evaluate the models' performance in classifying emotional
states. Results indicate that the CNN model achieved a higher accuracy of 61%
compared to the LSTM model's accuracy of 56%. Both models demonstrated better
performance in predicting specific emotions such as surprise and anger,
leveraging distinct audio features like pitch and speed variations.
Recommendations include further exploration of advanced data augmentation
techniques, combined feature extraction methods, and the integration of
linguistic analysis with speech characteristics for improved accuracy in mental
health diagnostics. Collaboration for standardized dataset collection and
sharing is recommended to foster advancements in affective computing and mental
health care interventions.",http://arxiv.org/abs/2412.10469v1
"The increasing demand for mental health services has highlighted the need for
innovative solutions, particularly in the realm of psychological conversational
AI, where the availability of sensitive data is scarce. In this work, we
explored the development of a system tailored for mental health support with a
novel approach to psychological assessment based on explainable emotional
profiles in combination with empathetic conversational models, offering a
promising tool for augmenting traditional care, particularly where immediate
expertise is unavailable. Our work can be divided into two main parts,
intrinsecaly connected to each other. First, we present RACLETTE, a
conversational system that demonstrates superior emotional accuracy compared to
state-of-the-art benchmarks in both understanding users' emotional states and
generating empathetic responses during conversations, while progressively
building an emotional profile of the user through their interactions. Second,
we show how the emotional profiles of a user can be used as interpretable
markers for mental health assessment. These profiles can be compared with
characteristic emotional patterns associated with different mental disorders,
providing a novel approach to preliminary screening and support.",http://arxiv.org/abs/2412.20068v1
"Advances in large language models (LLMs) have empowered a variety of
applications. However, there is still a significant gap in research when it
comes to understanding and enhancing the capabilities of LLMs in the field of
mental health. In this work, we present a comprehensive evaluation of multiple
LLMs on various mental health prediction tasks via online text data, including
Alpaca, Alpaca-LoRA, FLAN-T5, GPT-3.5, and GPT-4. We conduct a broad range of
experiments, covering zero-shot prompting, few-shot prompting, and instruction
fine-tuning. The results indicate a promising yet limited performance of LLMs
with zero-shot and few-shot prompt designs for mental health tasks. More
importantly, our experiments show that instruction finetuning can significantly
boost the performance of LLMs for all tasks simultaneously. Our best-finetuned
models, Mental-Alpaca and Mental-FLAN-T5, outperform the best prompt design of
GPT-3.5 (25 and 15 times bigger) by 10.9% on balanced accuracy and the best of
GPT-4 (250 and 150 times bigger) by 4.8%. They further perform on par with the
state-of-the-art task-specific language model. We also conduct an exploratory
case study on LLMs' capability on mental health reasoning tasks, illustrating
the promising capability of certain models such as GPT-4. We summarize our
findings into a set of action guidelines for potential methods to enhance LLMs'
capability for mental health tasks. Meanwhile, we also emphasize the important
limitations before achieving deployability in real-world mental health
settings, such as known racial and gender bias. We highlight the important
ethical risks accompanying this line of research.",http://arxiv.org/abs/2307.14385v4
"With the development of web technology, social media texts are becoming a
rich source for automatic mental health analysis. As traditional discriminative
methods bear the problem of low interpretability, the recent large language
models have been explored for interpretable mental health analysis on social
media, which aims to provide detailed explanations along with predictions. The
results show that ChatGPT can generate approaching-human explanations for its
correct classifications. However, LLMs still achieve unsatisfactory
classification performance in a zero-shot/few-shot manner. Domain-specific
finetuning is an effective solution, but faces 2 challenges: 1) lack of
high-quality training data. 2) no open-source LLMs for interpretable mental
health analysis were released to lower the finetuning cost. To alleviate these
problems, we build the first multi-task and multi-source interpretable mental
health instruction (IMHI) dataset on social media, with 105K data samples. The
raw social media data are collected from 10 existing sources covering 8 mental
health analysis tasks. We use expert-written few-shot prompts and collected
labels to prompt ChatGPT and obtain explanations from its responses. To ensure
the reliability of the explanations, we perform strict automatic and human
evaluations on the correctness, consistency, and quality of generated data.
Based on the IMHI dataset and LLaMA2 foundation models, we train MentalLLaMA,
the first open-source LLM series for interpretable mental health analysis with
instruction-following capability. We also evaluate the performance of
MentalLLaMA on the IMHI evaluation benchmark with 10 test sets, where their
correctness for making predictions and the quality of explanations are
examined. The results show that MentalLLaMA approaches state-of-the-art
discriminative methods in correctness and generates high-quality explanations.",http://arxiv.org/abs/2309.13567v3
"The integration of large language models (LLMs) in mental health care is an
emerging field. There is a need to systematically review the application
outcomes and delineate the advantages and limitations in clinical settings.
This review aims to provide a comprehensive overview of the use of LLMs in
mental health care, assessing their efficacy, challenges, and potential for
future applications. A systematic search was conducted across multiple
databases including PubMed, Web of Science, Google Scholar, arXiv, medRxiv, and
PsyArXiv in November 2023. All forms of original research, peer-reviewed or
not, published or disseminated between October 1, 2019, and December 2, 2023,
are included without language restrictions if they used LLMs developed after T5
and directly addressed research questions in mental health care settings. From
an initial pool of 313 articles, 34 met the inclusion criteria based on their
relevance to LLM application in mental health care and the robustness of
reported outcomes. Diverse applications of LLMs in mental health care are
identified, including diagnosis, therapy, patient engagement enhancement, etc.
Key challenges include data availability and reliability, nuanced handling of
mental states, and effective evaluation methods. Despite successes in accuracy
and accessibility improvement, gaps in clinical applicability and ethical
considerations were evident, pointing to the need for robust data, standardized
evaluations, and interdisciplinary collaboration. LLMs hold substantial promise
for enhancing mental health care. For their full potential to be realized,
emphasis must be placed on developing robust datasets, development and
evaluation frameworks, ethical guidelines, and interdisciplinary collaborations
to address current limitations.",http://arxiv.org/abs/2401.02984v2
"Mental health conditions cause a great deal of distress or impairment;
depression alone will affect 11% of the world's population. The application of
Artificial Intelligence (AI) and big-data technologies to mental health has
great potential for personalizing treatment selection, prognosticating,
monitoring for relapse, detecting and helping to prevent mental health
conditions before they reach clinical-level symptomatology, and even delivering
some treatments. However, unlike similar applications in other fields of
medicine, there are several unique challenges in mental health applications
which currently pose barriers towards the implementation of these technologies.
Specifically, there are very few widely used or validated biomarkers in mental
health, leading to a heavy reliance on patient and clinician derived
questionnaire data as well as interpretation of new signals such as digital
phenotyping. In addition, diagnosis also lacks the same objective 'gold
standard' as in other conditions such as oncology, where clinicians and
researchers can often rely on pathological analysis for confirmation of
diagnosis. In this chapter we discuss the major opportunities, limitations and
techniques used for improving mental healthcare through AI and big-data. We
explore both the computational, clinical and ethical considerations and best
practices as well as lay out the major researcher directions for the near
future.",http://arxiv.org/abs/1903.12071v1
"An increasing number of mental health services are offered through mobile
systems, a paradigm called mHealth. Although there is an unprecedented growth
in the adoption of mHealth systems, partly due to the COVID-19 pandemic,
concerns about data privacy risks due to security breaches are also increasing.
Whilst some studies have analyzed mHealth apps from different angles, including
security, there is relatively little evidence for data privacy issues that may
exist in mHealth apps used for mental health services, whose recipients can be
particularly vulnerable. This paper reports an empirical study aimed at
systematically identifying and understanding data privacy incorporated in
mental health apps. We analyzed 27 top-ranked mental health apps from Google
Play Store. Our methodology enabled us to perform an in-depth privacy analysis
of the apps, covering static and dynamic analysis, data sharing behaviour,
server-side tests, privacy impact assessment requests, and privacy policy
evaluation. Furthermore, we mapped the findings to the LINDDUN threat taxonomy,
describing how threats manifest on the studied apps. The findings reveal
important data privacy issues such as unnecessary permissions, insecure
cryptography implementations, and leaks of personal data and credentials in
logs and web requests. There is also a high risk of user profiling as the apps'
development do not provide foolproof mechanisms against linkability,
detectability and identifiability. Data sharing among third parties and
advertisers in the current apps' ecosystem aggravates this situation. Based on
the empirical findings of this study, we provide recommendations to be
considered by different stakeholders of mHealth apps in general and apps
developers in particular. [...]",http://arxiv.org/abs/2201.09006v1
"Introduction: To improve current public health strategies in suicide
prevention and mental health, governments, researchers and private companies
increasingly use information and communication technologies, and more
specifically Artificial Intelligence and Big Data. These technologies are
promising but raise ethical challenges rarely covered by current legal systems.
It is essential to better identify, and prevent potential ethical risks.
Objectives: The Canada Protocol - MHSP is a tool to guide and support
professionals, users, and researchers using AI in mental health and suicide
prevention. Methods: A checklist was constructed based upon ten international
reports on AI and ethics and two guides on mental health and new technologies.
329 recommendations were identified, of which 43 were considered as applicable
to Mental Health and AI. The checklist was validated, using a two round Delphi
Consultation. Results: 16 experts participated in the first round of the Delphi
Consultation and 8 participated in the second round. Of the original 43 items,
38 were retained. They concern five categories: ""Description of the Autonomous
Intelligent System"" (n=8), ""Privacy and Transparency"" (n=8), ""Security"" (n=6),
""Health-Related Risks"" (n=8), ""Biases"" (n=8). The checklist was considered
relevant by most users, and could need versions tailored to each category of
target users.",http://arxiv.org/abs/1907.07493v1
"COVID-19 pandemic has adversely and disproportionately impacted people
suffering from mental health issues and substance use problems. This has been
exacerbated by social isolation during the pandemic and the social stigma
associated with mental health and substance use disorders, making people
reluctant to share their struggles and seek help. Due to the anonymity and
privacy they provide, social media emerged as a convenient medium for people to
share their experiences about their day to day struggles. Reddit is a
well-recognized social media platform that provides focused and structured
forums called subreddits, that users subscribe to and discuss their experiences
with others. Temporal assessment of the topical correlation between social
media postings about mental health/substance use and postings about Coronavirus
is crucial to better understand public sentiment on the pandemic and its
evolving impact, especially related to vulnerable populations. In this study,
we conduct a longitudinal topical analysis of postings between subreddits
r/depression, r/Anxiety, r/SuicideWatch, and r/Coronavirus, and postings
between subreddits r/opiates, r/OpiatesRecovery, r/addiction, and r/Coronavirus
from January 2020 - October 2020. Our results show a high topical correlation
between postings in r/depression and r/Coronavirus in September 2020. Further,
the topical correlation between postings on substance use disorders and
Coronavirus fluctuates, showing the highest correlation in August 2020. By
monitoring these trends from platforms such as Reddit, epidemiologists, and
mental health professionals can gain insights into the challenges faced by
communities for targeted interventions.",http://arxiv.org/abs/2011.10518v1
"In this paper, we present novel research methods for collecting and analyzing
personal financial data alongside mental health factors, illustrated through a
N=1 case study using data from one individual with bipolar disorder. While we
have not found statistically significant trends nor our findings are
generalizable beyond this case, our approach provides an insight into the
challenges of accessing objective financial data. We outline what data is
currently available, what can be done with it, and what factors to consider
when working with financial data. More specifically, using these methods
researchers might be able to identify symptomatic traces of mental ill health
in personal financial data such as identifying early warning signs and thereby
enable preemptive care for individuals with serious mental illnesses. Based on
this work, we have also explored future directions for developing interventions
to support financial wellbeing. Furthermore, we have described the technical,
ethical, and equity challenges for financial data-driven assessments and
intervention methods, as well as provided a broad research agenda to address
these challenges. By leveraging objective, personalized financial data in a
privacy-preserving and ethical manner help lead to a shift in mental health
care.",http://arxiv.org/abs/2204.05448v4
"People often utilise online media (e.g., Facebook, Reddit) as a platform to
express their psychological distress and seek support. State-of-the-art NLP
techniques demonstrate strong potential to automatically detect mental health
issues from text. Research suggests that mental health issues are reflected in
emotions (e.g., sadness) indicated in a person's choice of language. Therefore,
we developed a novel emotion-annotated mental health corpus (EmoMent),
consisting of 2802 Facebook posts (14845 sentences) extracted from two South
Asian countries - Sri Lanka and India. Three clinical psychology postgraduates
were involved in annotating these posts into eight categories, including
'mental illness' (e.g., depression) and emotions (e.g., 'sadness', 'anger').
EmoMent corpus achieved 'very good' inter-annotator agreement of 98.3% (i.e. %
with two or more agreement) and Fleiss' Kappa of 0.82. Our RoBERTa based models
achieved an F1 score of 0.76 and a macro-averaged F1 score of 0.77 for the
first task (i.e. predicting a mental health condition from a post) and the
second task (i.e. extent of association of relevant posts with the categories
defined in our taxonomy), respectively.",http://arxiv.org/abs/2208.08486v1
"Dialogue safety remains a pervasive challenge in open-domain human-machine
interaction. Existing approaches propose distinctive dialogue safety taxonomies
and datasets for detecting explicitly harmful responses. However, these
taxonomies may not be suitable for analyzing response safety in mental health
support. In real-world interactions, a model response deemed acceptable in
casual conversations might have a negligible positive impact on users seeking
mental health support. To address these limitations, this paper aims to develop
a theoretically and factually grounded taxonomy that prioritizes the positive
impact on help-seekers. Additionally, we create a benchmark corpus with
fine-grained labels for each dialogue session to facilitate further research.
We analyze the dataset using popular language models, including BERT-base,
RoBERTa-large, and ChatGPT, to detect and understand unsafe responses within
the context of mental health support. Our study reveals that ChatGPT struggles
to detect safety categories with detailed safety definitions in a zero- and
few-shot paradigm, whereas the fine-tuned model proves to be more suitable. The
developed dataset and findings serve as valuable benchmarks for advancing
research on dialogue safety in mental health support, with significant
implications for improving the design and deployment of conversation agents in
real-world applications. We release our code and data here:
https://github.com/qiuhuachuan/DialogueSafety.",http://arxiv.org/abs/2307.16457v1
"Online Mental Health Communities (OMHCs), such as Reddit, have witnessed a
surge in popularity as go-to platforms for seeking information and support in
managing mental health needs. Platforms like Reddit offer immediate
interactions with peers, granting users a vital space for seeking mental health
assistance. However, the largely unregulated nature of these platforms
introduces intricate challenges for both users and society at large. This study
explores the factors that drive peer engagement within counseling threads,
aiming to enhance our understanding of this critical phenomenon. We introduce
BeCOPE, a novel behavior encoded Peer counseling dataset comprising over 10,118
posts and 58,279 comments sourced from 21 mental health-specific subreddits.
The dataset is annotated using three major fine-grained behavior labels: (a)
intent, (b) criticism, and (c) readability, along with the emotion labels. Our
analysis indicates the prominence of ``self-criticism'' as the most prevalent
form of criticism expressed by help-seekers, accounting for a significant 43%
of interactions. Intriguingly, we observe that individuals who explicitly
express their need for help are 18.01% more likely to receive assistance
compared to those who present ``surveys'' or engage in ``rants.'' Furthermore,
we highlight the pivotal role of well-articulated problem descriptions, showing
that superior readability effectively doubles the likelihood of receiving the
sought-after support. Our study emphasizes the essential role of OMHCs in
offering personalized guidance and unveils behavior-driven engagement patterns.",http://arxiv.org/abs/2309.01618v1
"Research in psychopathology has shown that, at an aggregate level, the
patterns of emotional change over time -- emotion dynamics -- are indicators of
one's mental health. One's patterns of emotion change have traditionally been
determined through self-reports of emotions; however, there are known issues
with accuracy, bias, and ease of data collection. Recent approaches to
determining emotion dynamics from one's everyday utterances addresses many of
these concerns, but it is not yet known whether these measures of utterance
emotion dynamics (UED) correlate with mental health diagnoses. Here, for the
first time, we study the relationship between tweet emotion dynamics and mental
health disorders. We find that each of the UED metrics studied varied by the
user's self-disclosed diagnosis. For example: average valence was significantly
higher (i.e., more positive text) in the control group compared to users with
ADHD, MDD, and PTSD. Valence variability was significantly lower in the control
group compared to ADHD, depression, bipolar disorder, MDD, PTSD, and OCD but
not PPD. Rise and recovery rates of valence also exhibited significant
differences from the control. This work provides important early evidence for
how linguistic cues pertaining to emotion dynamics can play a crucial role as
biosocial markers for mental illnesses and aid in the understanding, diagnosis,
and management of mental health disorders.",http://arxiv.org/abs/2310.17369v2
"Digital mental health (DMH) interventions, such as text-message-based lessons
and activities, offer immense potential for accessible mental health support.
While these interventions can be effective, real-world experimental testing can
further enhance their design and impact. Adaptive experimentation, utilizing
algorithms like Thompson Sampling for (contextual) multi-armed bandit (MAB)
problems, can lead to continuous improvement and personalization. However, it
remains unclear when these algorithms can simultaneously increase user
experience rewards and facilitate appropriate data collection for
social-behavioral scientists to analyze with sufficient statistical confidence.
Although a growing body of research addresses the practical and statistical
aspects of MAB and other adaptive algorithms, further exploration is needed to
assess their impact across diverse real-world contexts. This paper presents a
software system developed over two years that allows text-messaging
intervention components to be adapted using bandit and other algorithms while
collecting data for side-by-side comparison with traditional uniform random
non-adaptive experiments. We evaluate the system by deploying a
text-message-based DMH intervention to 1100 users, recruited through a large
mental health non-profit organization, and share the path forward for deploying
this system at scale. This system not only enables applications in mental
health but could also serve as a model testbed for adaptive experimentation
algorithms in other domains.",http://arxiv.org/abs/2310.18326v1
"Amid growing global mental health concerns, particularly among vulnerable
groups, natural language processing offers a tremendous potential for early
detection and intervention of people's mental disorders via analyzing their
postings and discussions on social media platforms. However, ultra-sparse
training data, often due to vast vocabularies and low-frequency words, hinders
the analysis accuracy. Multi-labeling and Co-occurrences of symptoms may also
blur the boundaries in distinguishing similar/co-related disorders. To address
these issues, we propose a novel semantic feature preprocessing technique with
a three-folded structure: 1) mitigating the feature sparsity with a weak
classifier, 2) adaptive feature dimension with modulus loops, and 3)
deep-mining and extending features among the contexts. With enhanced semantic
features, we train a machine learning model to predict and classify mental
disorders. We utilize the Reddit Mental Health Dataset 2022 to examine
conditions such as Anxiety, Borderline Personality Disorder (BPD), and
Bipolar-Disorder (BD) and present solutions to the data sparsity challenge,
highlighted by 99.81% non-zero elements. After applying our preprocessing
technique, the feature sparsity decreases to 85.4%. Overall, our methods, when
compared to seven benchmark models, demonstrate significant performance
improvements: 8.0% in accuracy, 0.069 in precision, 0.093 in recall, 0.102 in
F1 score, and 0.059 in AUC. This research provides foundational insights for
mental health prediction and monitoring, providing innovative solutions to
navigate challenges associated with ultra-sparse data feature and intricate
multi-label classification in the domain of mental health analysis.",http://arxiv.org/abs/2311.05075v1
"Employee well-being is a critical concern in the contemporary workplace, as
highlighted by the American Psychological Association's 2021 report, indicating
that 71% of employees experience stress or tension. This stress contributes
significantly to workplace attrition and absenteeism, with 61% of attrition and
16% of sick days attributed to poor mental health. A major challenge for
employers is that employees often remain unaware of their mental health issues
until they reach a crisis point, resulting in limited utilization of corporate
well-being benefits. This research addresses this challenge by presenting a
groundbreaking stress detection algorithm that provides real-time support
preemptively. Leveraging automated chatbot technology, the algorithm
objectively measures mental health levels by analyzing chat conversations,
offering personalized treatment suggestions in real-time based on linguistic
biomarkers. The study explores the feasibility of integrating these innovations
into practical learning applications within real-world contexts and introduces
a chatbot-style system integrated into the broader employee experience
platform. This platform, encompassing various features, aims to enhance overall
employee well-being, detect stress in real time, and proactively engage with
individuals to improve support effectiveness, demonstrating a 22% increase when
assistance is provided early. Overall, the study emphasizes the importance of
fostering a supportive workplace environment for employees' mental health.",http://arxiv.org/abs/2402.01592v1
"Understanding the conversation abilities of Large Language Models (LLMs) can
help lead to its more cautious and appropriate deployment. This is especially
important for safety-critical domains like mental health, where someone's life
may depend on the exact wording of a response to an urgent question. In this
paper, we propose a novel framework for evaluating the nuanced conversation
abilities of LLMs. Within it, we develop a series of quantitative metrics
developed from literature on using psychotherapy conversation analysis
literature. While we ensure that our framework and metrics are transferable by
researchers to relevant adjacent domains, we apply them to the mental health
field. We use our framework to evaluate several popular frontier LLMs,
including some GPT and Llama models, through a verified mental health dataset.
Our results show that GPT4 Turbo can perform significantly more similarly to
verified therapists than other selected LLMs. We conduct additional analysis to
examine how LLM conversation performance varies across specific mental health
topics. Our results indicate that GPT4 Turbo performs well in achieving high
correlation with verified therapists in particular topics such as Parenting and
Relationships. We believe our contributions will help researchers develop
better LLMs that, in turn, will more positively support people's lives.",http://arxiv.org/abs/2403.09705v1
"Timely identification is essential for the efficient handling of mental
health illnesses such as depression. However, the current research fails to
adequately address the prediction of mental health conditions from social media
data in low-resource African languages like Swahili. This study introduces two
distinct approaches utilising model-agnostic meta-learning and leveraging large
language models (LLMs) to address this gap. Experiments are conducted on three
datasets translated to low-resource language and applied to four mental health
tasks, which include stress, depression, depression severity and suicidal
ideation prediction. we first apply a meta-learning model with
self-supervision, which results in improved model initialisation for rapid
adaptation and cross-lingual transfer. The results show that our meta-trained
model performs significantly better than standard fine-tuning methods,
outperforming the baseline fine-tuning in macro F1 score with 18\% and 0.8\%
over XLM-R and mBERT. In parallel, we use LLMs' in-context learning
capabilities to assess their performance accuracy across the Swahili mental
health prediction tasks by analysing different cross-lingual prompting
approaches. Our analysis showed that Swahili prompts performed better than
cross-lingual prompts but less than English prompts. Our findings show that
in-context learning can be achieved through cross-lingual transfer through
carefully crafted prompt templates with examples and instructions.",http://arxiv.org/abs/2404.09045v1
"Large language models (LLMs) are already being piloted for clinical use in
hospital systems like NYU Langone, Dana-Farber and the NHS. A proposed
deployment use case is psychotherapy, where a LLM-powered chatbot can treat a
patient undergoing a mental health crisis. Deployment of LLMs for mental health
response could hypothetically broaden access to psychotherapy and provide new
possibilities for personalizing care. However, recent high-profile failures,
like damaging dieting advice offered by the Tessa chatbot to patients with
eating disorders, have led to doubt about their reliability in high-stakes and
safety-critical settings.
  In this work, we develop an evaluation framework for determining whether LLM
response is a viable and ethical path forward for the automation of mental
health treatment. Our framework measures equity in empathy and adherence of LLM
responses to motivational interviewing theory. Using human evaluation with
trained clinicians and automatic quality-of-care metrics grounded in psychology
research, we compare the responses provided by peer-to-peer responders to those
provided by a state-of-the-art LLM.
  We show that LLMs like GPT-4 use implicit and explicit cues to infer patient
demographics like race. We then show that there are statistically significant
discrepancies between patient subgroups: Responses to Black posters
consistently have lower empathy than for any other demographic group (2%-13%
lower than the control group). Promisingly, we do find that the manner in which
responses are generated significantly impacts the quality of the response. We
conclude by proposing safety guidelines for the potential deployment of LLMs
for mental health response.",http://arxiv.org/abs/2405.12021v2
"Large language models (LLMs) are raging over the medical domain, and their
momentum has carried over into the mental health domain, leading to the
emergence of few mental health LLMs. Although such mental health LLMs could
provide reasonable suggestions for psychological counseling, how to develop an
authentic and effective doctor-patient relationship (DPR) through LLMs is still
an important problem. To fill this gap, we dissect DPR into two key attributes,
i.e., the psychologist's empathy and proactive guidance. We thus present
WundtGPT, an empathetic and proactive mental health large language model that
is acquired by fine-tuning it with instruction and real conversation between
psychologists and patients. It is designed to assist psychologists in diagnosis
and help patients who are reluctant to communicate face-to-face understand
their psychological conditions. Its uniqueness lies in that it could not only
pose purposeful questions to guide patients in detailing their symptoms but
also offer warm emotional reassurance. In particular, WundtGPT incorporates
Collection of Questions, Chain of Psychodiagnosis, and Empathy Constraints into
a comprehensive prompt for eliciting LLMs' questions and diagnoses.
Additionally, WundtGPT proposes a reward model to promote alignment with
empathetic mental health professionals, which encompasses two key factors:
cognitive empathy and emotional empathy. We offer a comprehensive evaluation of
our proposed model. Based on these outcomes, we further conduct the manual
evaluation based on proactivity, effectiveness, professionalism and coherence.
We notice that WundtGPT can offer professional and effective consultation. The
model is available at huggingface.",http://arxiv.org/abs/2406.15474v1
"Over one in five adults in the US lives with a mental illness. In the face of
a shortage of mental health professionals and offline resources, online
short-form video content has grown to serve as a crucial conduit for
disseminating mental health help and resources. However, the ease of content
creation and access also contributes to the spread of misinformation, posing
risks to accurate diagnosis and treatment. Detecting and understanding
engagement with such content is crucial to mitigating their harmful effects on
public health. We perform the first quantitative study of the phenomenon using
YouTube Shorts and Bitchute as the sites of study. We contribute MentalMisinfo,
a novel labeled mental health misinformation (MHMisinfo) dataset of 739 videos
(639 from Youtube and 100 from Bitchute) and 135372 comments in total, using an
expert-driven annotation schema. We first found that few-shot in-context
learning with large language models (LLMs) are effective in detecting MHMisinfo
videos. Next, we discover distinct and potentially alarming linguistic patterns
in how audiences engage with MHMisinfo videos through commentary on both
video-sharing platforms. Across the two platforms, comments could exacerbate
prevailing stigma with some groups showing heightened susceptibility to and
alignment with MHMisinfo. We discuss technical and public health-driven
adaptive solutions to tackling the ""epidemic"" of mental health misinformation
online.",http://arxiv.org/abs/2407.02662v1
"The significance of mental health classification is paramount in contemporary
society, where digital platforms serve as crucial sources for monitoring
individuals' well-being. However, existing social media mental health datasets
primarily consist of text-only samples, potentially limiting the efficacy of
models trained on such data. Recognising that humans utilise cross-modal
information to comprehend complex situations or issues, we present a novel
approach to address the limitations of current methodologies. In this work, we
introduce a Multimodal and Multi-Teacher Knowledge Distillation model for
Mental Health Classification, leveraging insights from cross-modal human
understanding. Unlike conventional approaches that often rely on simple
concatenation to integrate diverse features, our model addresses the challenge
of appropriately representing inputs of varying natures (e.g., texts and
sounds). To mitigate the computational complexity associated with integrating
all features into a single model, we employ a multimodal and multi-teacher
architecture. By distributing the learning process across multiple teachers,
each specialising in a particular feature extraction aspect, we enhance the
overall mental health classification performance. Through experimental
validation, we demonstrate the efficacy of our model in achieving improved
performance.",http://arxiv.org/abs/2407.09020v3
"Mental health disorders are among the most prevalent diseases worldwide,
affecting nearly one in four people. Despite their widespread impact, the
intervention rate remains below 25%, largely due to the significant cooperation
required from patients for both diagnosis and intervention. The core issue
behind this low treatment rate is stigma, which discourages over half of those
affected from seeking help. This paper presents MindGuard, an accessible,
stigma-free, and professional mobile mental healthcare system designed to
provide mental health first aid. The heart of MindGuard is an innovative edge
LLM, equipped with professional mental health knowledge, that seamlessly
integrates objective mobile sensor data with subjective Ecological Momentary
Assessment records to deliver personalized screening and intervention
conversations. We conduct a broad evaluation of MindGuard using open datasets
spanning four years and real-world deployment across various mobile devices
involving 20 subjects for two weeks. Remarkably, MindGuard achieves results
comparable to GPT-4 and outperforms its counterpart with more than 10 times the
model size. We believe that MindGuard paves the way for mobile LLM
applications, potentially revolutionizing mental healthcare practices by
substituting self-reporting and intervention conversations with passive,
integrated monitoring within daily life, thus ensuring accessible and
stigma-free mental health support.",http://arxiv.org/abs/2409.10064v1
"Computational approaches to predicting mental health conditions in social
media have been substantially explored in the past years. Multiple surveys have
been published on this topic, providing the community with comprehensive
accounts of the research in this area. Among all mental health conditions,
depression is the most widely studied due to its worldwide prevalence. The
COVID-19 global pandemic, starting in early 2020, has had a great impact on
mental health worldwide. Harsh measures employed by governments to slow the
spread of the virus (e.g., lockdowns) and the subsequent economic downturn
experienced in many countries have significantly impacted people's lives and
mental health. Studies have shown a substantial increase of above 50% in the
rate of depression in the population. In this context, we present a survey on
natural language processing (NLP) approaches to modeling depression in social
media, providing the reader with a post-COVID-19 outlook. This survey
contributes to the understanding of the impacts of the pandemic on modeling
depression in social media. We outline how state-of-the-art approaches and new
datasets have been used in the context of the COVID-19 pandemic. Finally, we
also discuss ethical issues in collecting and processing mental health data,
considering fairness, accountability, and ethics.",http://arxiv.org/abs/2410.08793v1
"Neurofeedback is a non-invasive brain training with long-term medical and
non-medical applications. Despite the existence of several emotion regulation
studies using neurofeedback, further investigation is needed to understand
interactions of the brain regions involved in the process. We implemented EEG
neurofeedback with simultaneous fMRI using a modified happiness-inducing task
through autobiographical memories to upregulate positive emotion. The results
showed increased activity of prefrontal, occipital, parietal, and limbic
regions and increased functional connectivity between prefrontal, parietal,
limbic system, and insula in the experimental group. New connectivity links
were identified by comparing the functional connectivity of different
experimental conditions within the experimental group and between the
experimental and control groups. The proposed multimodal approach quantified
the changes in the brain activity (up to 1.9% increase) and connectivity
(FDR-corrected for multiple comparison, q = 0.05) during emotion regulation
in/between prefrontal, parietal, limbic, and insula regions. Psychometric
assessments confirmed significant changes in positive and negative mood states
by neurofeedback with a p-value smaller than 0.002 in the experimental group.
This study quantifies the effects of EEG neurofeedback in changing functional
connectivity of all brain regions involved in emotion regulation. For the brain
regions involved in emotion regulation, we found significant BOLD and
functional connectivity increases due to neurofeedback in the experimental
group but no learning effect was observed in the control group. The results
reveal the neurobiological substrate of emotion regulation by the EEG
neurofeedback and separate the effect of the neurofeedback and the recall of
the autobiographical memories.",http://arxiv.org/abs/2006.06829v1
"Delivering treatment recommendations via pervasive electronic devices such as
mobile phones has the potential to be a viable and scalable treatment medium
for long-term health behavior management. But active experimentation of
treatment options can be time-consuming, expensive and altogether unethical in
some cases. There is a growing interest in methodological approaches that allow
an experimenter to learn and evaluate the usefulness of a new treatment
strategy before deployment. We present the first development of a treatment
recommender system for emotion regulation using real-world historical mobile
digital data from n = 114 high socially anxious participants to test the
usefulness of new emotion regulation strategies. We explore a number of offline
contextual bandits estimators for learning and propose a general framework for
learning algorithms. Our experimentation shows that the proposed doubly robust
offline learning algorithms performed significantly better than baseline
approaches, suggesting that this type of recommender algorithm could improve
emotion regulation. Given that emotion regulation is impaired across many
mental illnesses and such a recommender algorithm could be scaled up easily,
this approach holds potential to increase access to treatment for many people.
We also share some insights that allow us to translate contextual bandit models
to this complex real-world data, including which contextual features appear to
be most important for predicting emotion regulation strategy effectiveness.",http://arxiv.org/abs/2008.09472v1
"Background: Mobile phone sensor technology has great potential in providing
behavioral markers of mental health. However, this promise has not yet been
brought to fruition. Objective: The objective of our study was to examine
challenges involved in developing an app to extract behavioral markers of
mental health from passive sensor data. Methods: Both technical challenges and
acceptability of passive data collection for mental health research were
assessed based on literature review and results obtained from a feasibility
study. Socialise, a mobile phone app developed at the Black Dog Institute, was
used to collect sensor data (Bluetooth, global positioning system, and battery
status) and investigate views and experiences of a group of people with lived
experience of mental health challenges (N=32). Results: On average, sensor data
were obtained for 55% (Android) and 45% (iPhone OS) of scheduled scans. Battery
life was reduced from 21.3 hours to 18.8 hours when scanning every 5 minutes
with a reduction of 2.5 hours or 12%. Despite this relatively small reduction,
most participants reported that the app had a noticeable effect on their
battery life. In addition to battery life, the purpose of data collection,
trust in the organization that collects data, and perceived impact on privacy
were identified as main factors for acceptability. Conclusions: Based on the
findings of the feasibility study and literature review, we recommend a
commitment to open science and transparent reporting and stronger partnerships
and communication with users. Sensing technology has the potential to greatly
enhance the delivery and impact of mental health care. Realizing this requires
all aspects of mobile phone sensor technology to be rigorously assessed.",http://arxiv.org/abs/1805.09158v2
"Purpose. We present an approach for forecasting mental health conditions and
emotions of a given population during the COVID-19 pandemic in Argentina based
on language expressions used in social media. This approach permits
anticipating high prevalence periods in short- to medium-term time horizons.
Design. Mental health conditions and emotions are captured via markers, which
link social media contents with lexicons. First, we build descriptive timelines
for decision makers to monitor the evolution of markers, and their correlation
with crisis events. Second, we model the timelines as time series, and support
their forecasting, which in turn serve to identify high prevalence points for
the estimated markers. Findings. Results showed that different time series
forecasting strategies offer different capabilities. In the best scenario, the
emergence of high prevalence periods of emotions and mental health disorders
can be satisfactorily predicted with a neural network strategy, even when
limited data is available in early stages of a crisis (e.g., 7 days).
Originality. Although there have been efforts in the literature to predict
mental states of individuals, the analysis of mental health at the collective
level has received scarce attention. We take a step forward by proposing a
forecasting approach for analyzing the mental health of a given population (or
group of individuals) at a larger scale. Practical implications. We believe
that this work contributes to a better understanding of how psychological
processes related to crisis manifest in social media, being a valuable asset
for the design, implementation and monitoring of health prevention and
communication policies.",http://arxiv.org/abs/2101.04540v4
"Objective: This study aims to identify the social determinants of mental
health among undergraduate students in Bangladesh, a developing nation in South
Asia. Our goal is to identify the broader social determinants of mental health
among this population, study the manifestation of these determinants in their
day-to-day life, and explore the feasibility of self-monitoring tools in
helping them identify the specific factors or relationships that impact their
mental health. Methods: We conducted a 21-day study with 38 undergraduate
students from seven universities in Bangladesh. We conducted two
semi-structured interviews: one pre-study and one post-study. During the 21-day
study, participants used an Android application to self-report and self-monitor
their mood after each phone conversation. The app prompted participants to
report their mood after each phone conversation and provided graphs and charts
so that participants could independently review their mood and conversation
patterns.
  Results: Our results show that academics, family, job and economic condition,
romantic relationships, and religion are the major social determinants of
mental health among undergraduate students in Bangladesh. Our app helped the
participants pinpoint the specific issues related to these factors as
participants could review the pattern of their moods and emotions from past
conversation history. Although our app does not provide any explicit
recommendation, participants took certain steps on their own to improve their
mental health (e.g., reduced the frequency of communication with certain
persons).
  Conclusions: Overall, the findings from this study would provide better
insights for the researchers to design better solutions to help the younger
population from this part of the world.",http://arxiv.org/abs/2109.02838v1
"Traditionally, the regime of mental healthcare has followed an episodic
psychotherapy model wherein patients seek care from a provider through a
prescribed treatment plan developed over multiple provider visits. Recent
advances in wearable and mobile technology have generated increased interest in
digital mental healthcare that enables individuals to address episodic mental
health symptoms. However, these efforts are typically reactive and
symptom-focused and do not provide comprehensive, wrap-around, customized
treatments that capture an individual's holistic mental health model as it
unfolds over time. Recognizing that each individual is unique, we present the
notion of Personalized Mental Health Navigation (MHN): a therapist-in-the-loop,
cybernetic goal-based system that deploys a continuous cyclic loop of
measurement, estimation, guidance, to steer the individual's mental health
state towards a healthy zone. We outline the major components of MHN that is
premised on the development of an individual's personal mental health state,
holistically represented by a high-dimensional cover of multiple knowledge
layers such as emotion, biological patterns, sociology, behavior, and
cognition. We demonstrate the feasibility of the personalized MHN approach via
a 12-month pilot case study for holistic stress management in college students
and highlight an instance of a therapist-in-the-loop intervention using MHN for
monitoring, estimating, and proactively addressing moderately severe depression
over a sustained period of time. We believe MHN paves the way to transform
mental healthcare from the current passive, episodic, reactive process (where
individuals seek help to address symptoms that have already manifested) to a
continuous and navigational paradigm that leverages a personalized model of the
individual, promising to deliver timely interventions to individuals in a
holistic manner.",http://arxiv.org/abs/2012.09131v1
"Mental health problems impact quality of life of millions of people around
the world. However, diagnosis of mental health disorders is a challenging
problem that often relies on self-reporting by patients about their behavioral
patterns. Therefore, there is a need for new strategies for diagnosis of mental
health problems. The recent introduction of body-area networks consisting of a
plethora of accurate sensors embedded in smartwatches and smartphones and deep
neural networks (DNNs) points towards a possible solution. However, disease
diagnosis based on WMSs and DNNs, and their deployment on edge devices, remains
a challenging problem. To this end, we propose a framework called MHDeep that
utilizes commercially available WMSs and efficient DNN models to diagnose three
important mental health disorders: schizoaffective, major depressive, and
bipolar. MHDeep uses eight different categories of data obtained from sensors
integrated in a smartwatch and smartphone. Due to limited available data,
MHDeep uses a synthetic data generation module to augment real data with
synthetic data drawn from the same probability distribution. We use the
synthetic dataset to pre-train the DNN models, thus imposing a prior on the
weights. We use a grow-and-prune DNN synthesis approach to learn both the
architecture and weights during the training process. We use three different
data partitions to evaluate the MHDeep models trained with data collected from
74 individuals. We conduct data instance level and patient level evaluations.
MHDeep achieves an average test accuracy of 90.4%, 87.3%, and 82.4%,
respectively, for classifications between healthy instances and schizoaffective
disorder instances, major depressive disorder instances, and bipolar disorder
instances. At the patient level, MHDeep DNNs achieve an accuracy of 100%, 100%,
and 90.0% for the three mental health disorders, respectively.",http://arxiv.org/abs/2102.10435v1
"Mental health disorders are the leading cause of health-related problems
globally. It is projected that mental health disorders will be the leading
cause of morbidity among adults as the incidence rates of anxiety and
depression grows globally. Recently, extended reality (XR), a general term
covering virtual reality (VR), augmented reality (AR) and mixed reality (MR),
is paving a new way to deliver mental health care. In this paper, we conduct a
scoping review on the development and application of XR in the area of mental
disorders. We performed a scoping database search to identify the relevant
studies indexed in Google Scholar, PubMed, and the ACM Digital Library. A
search period between August 2016 and December 2023 was defined to select
articles related to the usage of VR, AR, and MR in a mental health context. We
identified a total of 85 studies from 27 countries across the globe. By
performing data analysis, we found that most of the studies focused on
developed countries such as the US (16.47%) and Germany (12.94%). None of the
studies were for African countries. The majority of the articles reported that
XR techniques led to a significant reduction in symptoms of anxiety or
depression. More studies were published in the year 2021, i.e., 31.76% (n =
31). This could indicate that mental disorder intervention received a higher
attention when COVID-19 emerged. Most studies (n = 65) focused on a population
between 18 and 65 years old, only a few studies focused on teenagers (n = 2).
Also, more studies were done experimentally (n = 67, 78.82%) rather than by
analytical and modeling approaches (n = 8, 9.41%). This shows that there is a
rapid development of XR technology for mental health care. Furthermore, these
studies showed that XR technology can effectively be used for evaluating mental
disorders in similar or better way as the conventional approaches.",http://arxiv.org/abs/2204.01348v2
"Virtual Mental Health Assistants (VMHAs) have become a prevalent method for
receiving mental health counseling in the digital healthcare space. An
assistive counseling conversation commences with natural open-ended topics to
familiarize the client with the environment and later converges into more
fine-grained domain-specific topics. Unlike other conversational systems, which
are categorized as open-domain or task-oriented systems, VMHAs possess a hybrid
conversational flow. These counseling bots need to comprehend various aspects
of the conversation, such as dialogue-acts, intents, etc., to engage the client
in an effective conversation. Although the surge in digital health research
highlights applications of many general-purpose response generation systems,
they are barely suitable in the mental health domain -- the prime reason is the
lack of understanding in mental health counseling. Moreover, in general,
dialogue-act guided response generators are either limited to a template-based
paradigm or lack appropriate semantics. To this end, we propose READER -- a
REsponse-Act guided reinforced Dialogue genERation model for the mental health
counseling conversations. READER is built on transformer to jointly predict a
potential dialogue-act d(t+1) for the next utterance (aka response-act) and to
generate an appropriate response u(t+1). Through the
transformer-reinforcement-learning (TRL) with Proximal Policy Optimization
(PPO), we guide the response generator to abide by d(t+1) and ensure the
semantic richness of the responses via BERTScore in our reward computation. We
evaluate READER on HOPE, a benchmark counseling conversation dataset and
observe that it outperforms several baselines across several evaluation metrics
-- METEOR, ROUGE, and BERTScore. We also furnish extensive qualitative and
quantitative analyses on results, including error analysis, human evaluation,
etc.",http://arxiv.org/abs/2301.12729v1
"Sustainable Development Goals (SDGs) give the UN a road map for development
with Agenda 2030 as a target. SDG3 ""Good Health and Well-Being"" ensures healthy
lives and promotes well-being for all ages. Digital technologies can support
SDG3. Burnout and even depression could be reduced by encouraging better
preventive health. Due to the lack of patient knowledge and focus to take care
of their health, it is necessary to help patients before it is too late. New
trends such as positive psychology and mindfulness are highly encouraged in the
USA. Digital Twins (DTs) can help with the continuous monitoring of emotion
using physiological signals (e.g., collected via wearables). DTs facilitate
monitoring and provide constant health insight to improve quality of life and
well-being with better personalization. Healthcare DTs challenges are
standardizing data formats, communication protocols, and data exchange
mechanisms. As an example, ISO has the ISO/IEC JTC 1/SC 41 Internet of Things
(IoT) and DTs Working Group, with standards such as ""ISO/IEC 21823-3:2021 IoT -
Interoperability for IoT Systems - Part 3 Semantic interoperability"", ""ISO/IEC
CD 30178 - IoT - Data format, value and coding"". To achieve those data
integration and knowledge challenges, we designed the Mental Health Knowledge
Graph (ontology and dataset) to boost mental health. As an example, explicit
knowledge is described such as chocolate contains magnesium which is
recommended for depression. The Knowledge Graph (KG) acquires knowledge from
ontology-based mental health projects classified within the LOV4IoT ontology
catalog (Emotion, Depression, and Mental Health). Furthermore, the KG is mapped
to standards when possible. Standards from ETSI SmartM2M can be used such as
SAREF4EHAW to represent medical devices and sensors, but also ITU/WHO, ISO,
W3C, NIST, and IEEE standards relevant to mental health can be considered.",http://arxiv.org/abs/2406.13791v3
"Objective: This study aims to develop and validate an evaluation framework to
ensure the safety and reliability of mental health chatbots, which are
increasingly popular due to their accessibility, human-like interactions, and
context-aware support. Materials and Methods: We created an evaluation
framework with 100 benchmark questions and ideal responses, and five guideline
questions for chatbot responses. This framework, validated by mental health
experts, was tested on a GPT-3.5-turbo-based chatbot. Automated evaluation
methods explored included large language model (LLM)-based scoring, an agentic
approach using real-time data, and embedding models to compare chatbot
responses against ground truth standards. Results: The results highlight the
importance of guidelines and ground truth for improving LLM evaluation
accuracy. The agentic method, dynamically accessing reliable information,
demonstrated the best alignment with human assessments. Adherence to a
standardized, expert-validated framework significantly enhanced chatbot
response safety and reliability. Discussion: Our findings emphasize the need
for comprehensive, expert-tailored safety evaluation metrics for mental health
chatbots. While LLMs have significant potential, careful implementation is
necessary to mitigate risks. The superior performance of the agentic approach
underscores the importance of real-time data access in enhancing chatbot
reliability. Conclusion: The study validated an evaluation framework for mental
health chatbots, proving its effectiveness in improving safety and reliability.
Future work should extend evaluations to accuracy, bias, empathy, and privacy
to ensure holistic assessment and responsible integration into healthcare.
Standardized evaluations will build trust among users and professionals,
facilitating broader adoption and improved mental health support through
technology.",http://arxiv.org/abs/2408.04650v1
"Emotion regulation plays a key role in human behavior and overall well-being.
Neurofeedback is a non-invasive self-brain training technique used for emotion
regulation to enhance brain function and treatment of mental disorders through
behavioral changes. Previous neurofeedback research often focused on using
activity from a single brain region as measured by fMRI or power from one or
two EEG electrodes. In a new study, we employed connectivity-based EEG
neurofeedback through recalling positive autobiographical memories and
simultaneous fMRI to upregulate positive emotion. In our novel approach, the
feedback was determined by the coherence of EEG electrodes rather than the
power of one or two electrodes. We compared the efficiency of this
connectivity-based neurofeedback to traditional activity-based neurofeedback
through multiple experiments. The results showed that connectivity-based
neurofeedback effectively improved BOLD signal change and connectivity in key
emotion regulation regions such as the amygdala, thalamus, and insula, and
increased EEG frontal asymmetry, which is a biomarker for emotion regulation
and treatment of mental disorders such as PTSD, anxiety, and depression and
coherence among EEG channels. The psychometric evaluations conducted both
before and after the neurofeedback experiments revealed that participants
demonstrated improvements in enhancing positive emotions and reducing negative
emotions when utilizing connectivity-based neurofeedback, as compared to
traditional activity-based and sham neurofeedback approaches. These findings
suggest that connectivity-based neurofeedback may be a superior method for
regulating emotions and could be a useful alternative therapy for mental
disorders, providing individuals with greater control over their brain and
mental functions.",http://arxiv.org/abs/2204.01087v3
"Interpersonal communication plays a key role in managing people's emotions,
especially on digital platforms. Studies have shown that people use social
media and consume online content to regulate their emotions and find support
for rest and recovery. However, these platforms are not designed for emotion
regulation, which limits their effectiveness in this regard. To address this
issue, we propose an approach to enhance Interpersonal Emotion Regulation (IER)
on online platforms through content recommendation. The objective is to empower
users to regulate their emotions while actively or passively engaging in online
platforms by crafting media content that aligns with IER strategies,
particularly empathic responding. The proposed recommendation system is
expected to blend system-initiated and user-initiated emotion regulation,
paving the way for real-time IER practices on digital media platforms. To
assess the efficacy of this approach, a mixed-method research design is used,
including the analysis of text-based social media data and a user survey.
Digital applications has served as facilitators in this process, given the
widespread recognition of digital media applications for Digital Emotion
Regulation (DER). The study collects 37.5K instances of user posts and
interactions on Reddit over a year to design a Contextual Multi-Armed Bandits
(CMAB) based recommendation system using features from user activity and
preferences. The experimentation shows that the empathic recommendations
generated by the proposed recommendation system are preferred by users over
widely accepted ER strategies such as distraction and avoidance.",http://arxiv.org/abs/2408.07704v1
"Online mental health treatment has the premise to meet the increasing demand
for mental health treatment at a lower cost than traditional treatment.
However, online treatment suffers from high drop-out rates, which might negate
their cost effectiveness. Predictive models might aid in early identification
of deviating clients which allows to target them directly to prevent drop-out
and improve treatment outcomes. We propose a two-staged multi-objective
optimization process to automatically infer model structures based on
ecological momentary assessment for prediction of future symptom development.
The proposed multi-objective optimization approach results in a temporal-causal
network model with the best prediction performance for each concept. This
allows for a selection of a disorder-specific model structure based on the
envisioned field of application.",http://arxiv.org/abs/1809.04494v1
"Mental healthcare has seen numerous benefits from interactive technologies
and artificial intelligence. Various interventions have successfully used
intelligent technologies to automate the assessment and evaluation of
psychological treatments and mental well-being and functioning. These
technologies include different types of robots, video games, and conversational
agents. The paper critically analyzes existing solutions with the outlooks for
their future. In particular, we: i)give an overview of the technology for
mental health, ii) critically analyze the technology against the proposed
criteria, and iii) provide the design outlooks for these technologies.",http://arxiv.org/abs/2105.05306v1
"The popularization of the internet created a revitalized digital media. With
monetization driven by clicks, journalists have reprioritized their content for
the highly competitive atmosphere of online news. The resulting negativity bias
is harmful and can lead to anxiety and mood disturbance. We utilized a pipeline
of 4 sentiment analysis models trained on various datasets - using Sequential,
LSTM, BERT, and SVM models. When combined, the application, a mobile app,
solely displays uplifting and inspiring stories for users to read. Results have
been successful - 1,300 users rate the app at 4.9 stars, and 85% report
improved mental health by using it.",http://arxiv.org/abs/2108.07706v1
"This position paper describes the implementation and initial findings of a
game called Personal Investigator (PI). PI is an online 3D detective game that
implements a model of Brief Solution Focused Therapy (BSFT). It aims to help
teenagers overcome mental health problems and engage with traditional mental
health care services. It is predicted that the combination of goal-oriented
gaming with a model of goal-oriented therapy will help to attract and sustain
the interest of teenagers, a group that therapists often have difficulty
engaging with. PI is the first game to integrate this established psychotherapy
approach into an engaging online 3D game.",http://arxiv.org/abs/2207.02310v1
"Barriers to accessing mental health assessments including cost and stigma
continues to be an impediment in mental health diagnosis and treatment. Machine
learning approaches based on speech samples could help in this direction. In
this work, we develop machine learning solutions to diagnose anxiety disorders
from audio journals of patients. We work on a novel anxiety dataset (provided
through collaboration with Kintsugi Mindful Wellness Inc.) and experiment with
several models of varying complexity utilizing audio, text and a combination of
multiple modalities. We show that the multi-modal and audio embeddings based
approaches achieve good performance in the task achieving an AUC ROC score of
0.68-0.69.",http://arxiv.org/abs/2312.15272v1
"This article presents a method for prompt-based mental health screening from
a large and noisy dataset of social media text. Our method uses GPT 3.5.
prompting to distinguish publications that may be more relevant to the task,
and then uses a straightforward bag-of-words text classifier to predict actual
user labels. Results are found to be on pair with a BERT mixture of experts
classifier, and incurring only a fraction of its training costs.",http://arxiv.org/abs/2401.05912v2
"This research project aims to tackle the growing mental health challenges in
today's digital age. It employs a modified pre-trained BERT model to detect
depressive text within social media and users' web browsing data, achieving an
impressive 93% test accuracy. Simultaneously, the project aims to incorporate
physiological signals from wearable devices, such as smartwatches and EEG
sensors, to provide long-term tracking and prognosis of mood disorders and
emotional states. This comprehensive approach holds promise for enhancing early
detection of depression and advancing overall mental health outcomes.",http://arxiv.org/abs/2401.13722v1
"Dialogue systems for mental health care aim to provide appropriate support to
individuals experiencing mental distress. While extensive research has been
conducted to deliver adequate emotional support, existing studies cannot
identify individuals who require professional medical intervention and cannot
offer suitable guidance. We introduce the Diagnostic Emotional Support
Conversation task for an advanced mental health management system. We develop
the DESC dataset to assess depression symptoms while maintaining user
experience by utilizing task-specific utterance generation prompts and a strict
filtering algorithm. Evaluations by professional psychological counselors
indicate that DESC has a superior ability to diagnose depression than existing
data. Additionally, conversational quality evaluation reveals that DESC
maintains fluent, consistent, and coherent dialogues.",http://arxiv.org/abs/2408.06044v1
"The onset of old age brings physiological and mental changes, with anxiety
and depression being common mental disorders that can trigger other health
issues and reduce lifespan. However, due to a global shortage of mental health
professionals, combined with a growing population and limited awareness, these
disorders often go undiagnosed. Music therapy offers a reliable method to
address psychological, emotional, and cognitive needs. This paper presents an
approach that monitors anxiety and depression symptoms in real time using
low-complexity body sensors, followed by automated personalised music therapy,
reducing the dependence on therapists and improving mental health care
accessibility.",http://arxiv.org/abs/2410.02552v1
"Social media platforms, particularly Reddit's r/Epilepsy community, offer a
unique perspective into the experiences of individuals with epilepsy (PWE) and
their caregivers. This study analyzes 57k posts and 533k comments to explore
key themes across demographics such as age, gender, and relationships. Our
findings highlight significant discussions on epilepsy-related challenges,
including depression (with 39.75\% of posts indicating severe symptoms),
driving restrictions, workplace concerns, and pregnancy-related issues in women
with epilepsy. We introduce a novel engagement metric, F(P), which incorporates
post length, sentiment scores, and readability to quantify community
interaction. This analysis underscores the importance of integrated care
addressing both neurological and mental health challenges faced by PWE. The
insights from this study inform strategies for targeted support and awareness
interventions.",http://arxiv.org/abs/2412.01692v1
"We propose a pipeline for gaining insights into complex diseases by training
LLMs on challenging social media text data classification tasks, obtaining
explanations for the classification outputs, and performing qualitative and
quantitative analysis on the explanations. We report initial results on
predicting, explaining, and systematizing the explanations of predicted reports
on mental health concerns in people reporting Lyme disease concerns. We report
initial results on predicting future ADHD concerns for people reporting anxiety
disorder concerns, and demonstrate preliminary results on visualizing the
explanations for predicting that a person with anxiety concerns will in the
future have ADHD concerns.",http://arxiv.org/abs/2412.10414v1
"Due to the shift of civilization from the Industrial Age to the Information
Age, mathematical literacy has become a necessity in the twenty-first century.
However, in order to learn and contribute to the mathematical community, one
has to be in a state of good mental health. When I say 'good mental health,' I
mean one has to develop a set of healthy coping strategies, be in a positive
learning environment, and have a social support system. Traditionally,
universities have been the venue of such higher learning. If these institutions
want to remain as thriving grounds for higher education and engines of
research, post-secondary institutions need to be aware of these factors and
actively contribute to the well-being of its students and faulty.
Unfortunately, students do not always receive the support necessary to be
mentally healthy. The purpose of this paper is to examine how social awareness
and sensitivity of mental health in a university setting is a key component for
individuals to flourish academically and grow personally. Several voluntary
surveys completed by my first and second year math students at the University
of Waterloo will be presented. The surveys investigated the students'
experiences at the university, particularly in the Mathematics Department. In
addition, this paper explores an alternative way to structure math classes,
specifically assignment scheduling, in order to help students develop healthy
study habits. The scores for the alternative-scheduled assignments are
statistically analyzed and compared to scores of the typical-scheduled
assignments currently implemented at the University of Waterloo. Finally, this
paper briefly discusses the importance of socialization, specifically for young
mathematicians and scientists, and potential consequences of reduced social
exposure in the Digital Age.",http://arxiv.org/abs/1511.06699v1
"Mental health counseling is an enterprise with profound societal importance
where conversations play a primary role. In order to acquire the conversational
skills needed to face a challenging range of situations, mental health
counselors must rely on training and on continued experience with actual
clients. However, in the absence of large scale longitudinal studies, the
nature and significance of this developmental process remain unclear. For
example, prior literature suggests that experience might not translate into
consequential changes in counselor behavior. This has led some to even argue
that counseling is a profession without expertise.
  In this work, we develop a computational framework to quantify the extent to
which individuals change their linguistic behavior with experience and to study
the nature of this evolution. We use our framework to conduct a large
longitudinal study of mental health counseling conversations, tracking over
3,400 counselors across their tenure. We reveal that overall, counselors do
indeed change their conversational behavior to become more diverse across
interactions, developing an individual voice that distinguishes them from other
counselors. Furthermore, a finer-grained investigation shows that the rate and
nature of this diversification vary across functionally different
conversational components.",http://arxiv.org/abs/1906.07194v1
"Background: Adverse Childhood Experiences (ACEs), a set of negative events
and processes that a person might encounter during childhood and adolescence,
have been proven to be linked to increased risks of a multitude of negative
health outcomes and conditions when children reach adulthood and beyond.
  Objective: To better understand the relationship between ACEs and their
relevant risk factors with associated health outcomes and to eventually design
and implement preventive interventions, access to an integrated coherent
dataset is needed. Therefore, we implemented a formal ontology as a resource to
allow the mental health community to facilitate data integration and knowledge
modeling and to improve ACEs surveillance and research.
  Methods: We use advanced knowledge representation and Semantic Web tools and
techniques to implement the ontology. The current implementation of the
ontology is expressed in the description logic ALCRIQ(D), a sublogic of Web
Ontology Language (OWL 2).
  Results: The ACEs Ontology has been implemented and made available to the
mental health community and the public via the BioPortal repository. Moreover,
multiple use-case scenarios have been introduced to showcase and evaluate the
usability of the ontology in action. The ontology was created to be used by
major actors in the ACEs community with different applications, from the
diagnosis of individuals and predicting potential negative outcomes that they
might encounter to the prevention of ACEs in a population and designing
interventions and policies.
  Conclusions: The ACEs Ontology provides a uniform and reusable semantic
network and an integrated knowledge structure for mental health practitioners
and researchers to improve ACEs surveillance and evaluation.",http://arxiv.org/abs/1912.05530v1
"In late December 2019, the novel coronavirus (Sars-Cov-2) and the resulting
disease COVID-19 were first identified in Wuhan China. The disease slipped
through containment measures, with the first known case in the United States
being identified on January 20th, 2020. In this paper, we utilize survey data
from the Inter-university Consortium for Political and Social Research and
apply several statistical and machine learning models and techniques such as
Decision Trees, Multinomial Logistic Regression, Naive Bayes, k-Nearest
Neighbors, Support Vector Machines, Neural Networks, Random Forests, Gradient
Tree Boosting, XGBoost, CatBoost, LightGBM, Synthetic Minority Oversampling,
and Chi-Squared Test to analyze the impacts the COVID-19 pandemic has had on
the mental health of frontline workers in the United States. Through the
interpretation of the many models applied to the mental health survey data, we
have concluded that the most important factor in predicting the mental health
decline of a frontline worker is the healthcare role the individual is in
(Nurse, Emergency Room Staff, Surgeon, etc.), followed by the amount of sleep
the individual has had in the last week, the amount of COVID-19 related news an
individual has consumed on average in a day, the age of the worker, and the
usage of alcohol and cannabis.",http://arxiv.org/abs/2112.00227v2
"The issue of Internet addiction has become a serious social and health issue
in East Asian countries. There are only a few treatment programs for Internet
addiction, and their effectiveness with people from East Asian remains unclear.
As support and treatment develop, it is necessary to understand cultural
preferences for dealing with this concern. Using data from the East Asian
Social Survey (EASS), this study examined preferred sources of assistance for
help with internet use problems in four countries - China, Japan, South Korea,
and Taiwan. Preferences for kin versus non-kin support, use of alternative
medicine, and professional mental health assistance were examined, as were
between-country differences in support preferences. The results indicate a
strong preference for seeking assistance from close relatives, followed by
non-kin support (i.e., close friends and co-participants in religious
institutions), alternative medicine, and professional mental health services,
respectively. While there is a strong preference for family support, over 80%
of survey respondents were open to seeking formal or informal mental health
support outside the family. There were some significant differences between
countries, with South Koreans being more likely to seek non-kin support and
professional support for internet addiction concerns compared to Chinese. These
differences are discussed in the context of cultural and policy developments in
East Asian countries. Findings suggest the need for a more holistic approach to
treating low mental health concerns.",http://arxiv.org/abs/1902.00757v1
"Although combination antiretroviral therapy (ART) is highly effective in
suppressing viral load for people with HIV (PWH), many ART agents may
exacerbate central nervous system (CNS)-related adverse effects including
depression. Therefore, understanding the effects of ART drugs on the CNS
function, especially mental health, can help clinicians personalize medicine
with less adverse effects for PWH and prevent them from discontinuing their ART
to avoid undesirable health outcomes and increased likelihood of HIV
transmission. The emergence of electronic health records offers researchers
unprecedented access to HIV data including individuals' mental health records,
drug prescriptions, and clinical information over time. However, modeling such
data is very challenging due to high-dimensionality of the drug combination
space, the individual heterogeneity, and sparseness of the observed drug
combinations. We develop a Bayesian nonparametric approach to learn drug
combination effect on mental health in PWH adjusting for socio-demographic,
behavioral, and clinical factors. The proposed method is built upon the
subset-tree kernel method that represents drug combinations in a way that
synthesizes known regimen structure into a single mathematical representation.
It also utilizes a distance-dependent Chinese restaurant process to cluster
heterogeneous population while taking into account individuals' treatment
histories. We evaluate the proposed approach through simulation studies, and
apply the method to a dataset from the Women's Interagency HIV Study, yielding
interpretable and promising results. Our method has clinical utility in guiding
clinicians to prescribe more informed and effective personalized treatment
based on individuals' treatment histories and clinical characteristics.",http://arxiv.org/abs/2004.05487v1
"Recent years have seen a rise in social media platforms that provide
peer-to-peer support to individuals suffering from mental distress. Studies on
the impact of these platforms have focused on either short-term scales of
single-post threads, or long-term changes over arbitrary period of time (months
or years). While important, such arbitrary periods do not necessarily follow
users' progressions through acute periods of distress. Using data from
Talklife, a mental health platform, we find that user activity follows a
distinct pattern of high activity periods with interleaving periods of no
activity, and propose a method for identifying such bursts and breaks in
activity. We then show how studying activity during bursts can provide a
personalized, medium-term analysis for a key question in online mental health
communities: What characteristics of user activity lead some users to find
support and help, while others fall short? Using two independent outcome
metrics, moments of cognitive change and self-reported changes in mood during a
burst of activity, we identify two actionable features that can improve
outcomes for users: persistence within bursts, and giving complex emotional
support to others. Our results demonstrate the value of considering bursts as a
natural unit of analysis for psychosocial change in online mental health
communities.",http://arxiv.org/abs/2004.10330v1
"The COVID-19 pandemic has affected all aspects of society, not only bringing
health hazards, but also posing challenges to public order, governments and
mental health. Moreover, it is the first one in history in which people from
around the world uses social media to massively express their thoughts and
concerns. This study aims at examining the stages of crisis response and
recovery as a sociological problem by operationalizing a well-known model of
crisis stages in terms of a psycho-linguistic analysis. Based on a large
collection of Twitter data spanning from March to August 2020 in Argentina, we
present a thematic analysis on the differences in language used in social media
posts, and look at indicators that reveal the different stages of a crisis and
the country response thereof. The analysis was combined with a study of the
temporal prevalence of mental health conversations across the time span. Beyond
the Argentinian case-study, the proposed approach and analyses can be applied
to any public large-scale data. This approach can provide insights for the
design of public health politics oriented to monitor and eventually intervene
during the different stages of a crisis, and thus improve the adverse mental
health effects on the population.",http://arxiv.org/abs/2011.11024v1
"With strong marketing advocacy of the benefits of cannabis use for improved
mental health, cannabis legalization is a priority among legislators. However,
preliminary scientific research does not conclusively associate cannabis with
improved mental health. In this study, we explore the relationship between
depression and consumption of cannabis in a targeted social media corpus
involving personal use of cannabis with the intent to derive its potential
mental health benefit. We use tweets that contain an association among three
categories annotated by domain experts - Reason, Effect, and Addiction. The
state-of-the-art Natural Langauge Processing techniques fall short in
extracting these relationships between cannabis phrases and the depression
indicators. We seek to address the limitation by using domain knowledge;
specifically, the Drug Abuse Ontology for addiction augmented with Diagnostic
and Statistical Manual of Mental Disorders lexicons for mental health. Because
of the lack of annotations due to the limited availability of the domain
experts' time, we use supervised contrastive learning in conjunction with GPT-3
trained on a vast corpus to achieve improved performance even with limited
supervision. Experimental results show that our method can significantly
extract cannabis-depression relationships better than the state-of-the-art
relation extractor. High-quality annotations can be provided using a nearest
neighbor approach using the learned representations that can be used by the
scientific community to understand the association between cannabis and
depression better.",http://arxiv.org/abs/2102.01222v1
"COVID-19 poses disproportionate mental health consequences to the public
during different phases of the pandemic. We use a computational approach to
capture the specific aspects that trigger an online community's anxiety about
the pandemic and investigate how these aspects change over time. First, we
identified nine subjects of anxiety (SOAs) in a sample of Reddit posts ($N$=86)
from r/COVID19\_support using thematic analysis. Then, we quantified Reddit
users' anxiety by training algorithms on a manually annotated sample ($N$=793)
to automatically label the SOAs in a larger chronological sample ($N$=6,535).
The nine SOAs align with items in various recently developed pandemic anxiety
measurement scales. We observed that Reddit users' concerns about health risks
remained high in the first eight months of the pandemic. These concerns
diminished dramatically despite the surge of cases occurring later. In general,
users' language disclosing the SOAs became less intense as the pandemic
progressed. However, worries about mental health and the future increased
steadily throughout the period covered in this study. People also tended to use
more intense language to describe mental health concerns than health risks or
death concerns. Our results suggest that this online group's mental health
condition does not necessarily improve despite COVID-19 gradually weakening as
a health threat due to appropriate countermeasures. Our system lays the
groundwork for population health and epidemiology scholars to examine aspects
that provoke pandemic anxiety in a timely fashion.",http://arxiv.org/abs/2209.13595v1
"Developing specialized dialogue systems for mental health support requires
multi-turn conversation data, which has recently garnered increasing attention.
However, gathering and releasing large-scale, real-life multi-turn
conversations that could facilitate advancements in mental health support
presents challenges in data privacy protection and the time and cost involved
in crowdsourcing. To address these challenges, we introduce SMILE, a
single-turn to multi-turn inclusive language expansion technique that prompts
ChatGPT to rewrite public single-turn dialogues into multi-turn ones. Our work
begins by analyzing language transformation and validating the feasibility of
our proposed method. We conduct a study on dialogue diversity, including
lexical features, semantic features, and dialogue topics, demonstrating the
effectiveness of our method. Further, we employ our method to generate a
large-scale, lifelike, and diverse dialogue dataset named SMILECHAT, consisting
of 55k dialogues. Finally, we utilize the collected corpus to develop a mental
health chatbot, MeChat. To better assess the quality of SMILECHAT, we collect a
small-scale real-life counseling dataset conducted by data anonymization. Both
automatic and human evaluations demonstrate significant improvements in our
dialogue system and confirm that SMILECHAT is high-quality. Code, data, and
model are publicly available at https://github.com/qiuhuachuan/smile.",http://arxiv.org/abs/2305.00450v3
"Language models have the potential to assess mental health using social media
data. By analyzing online posts and conversations, these models can detect
patterns indicating mental health conditions like depression, anxiety, or
suicidal thoughts. They examine keywords, language markers, and sentiment to
gain insights into an individual's mental well-being. This information is
crucial for early detection, intervention, and support, improving mental health
care and prevention strategies. However, using language models for mental
health assessments from social media has two limitations: (1) They do not
compare posts against clinicians' diagnostic processes, and (2) It's
challenging to explain language model outputs using concepts that the clinician
can understand, i.e., clinician-friendly explanations. In this study, we
introduce Process Knowledge-infused Learning (PK-iL), a new learning paradigm
that layers clinical process knowledge structures on language model outputs,
enabling clinician-friendly explanations of the underlying language model
predictions. We rigorously test our methods on existing benchmark datasets,
augmented with such clinical process knowledge, and release a new dataset for
assessing suicidality. PK-iL performs competitively, achieving a 70% agreement
with users, while other XAI methods only achieve 47% agreement (average
inter-rater agreement of 0.72). Our evaluations demonstrate that PK-iL
effectively explains model predictions to clinicians.",http://arxiv.org/abs/2306.09824v1
"The demand for psychological counselling has grown significantly in recent
years, particularly with the global outbreak of COVID-19, which has heightened
the need for timely and professional mental health support. Online
psychological counselling has emerged as the predominant mode of providing
services in response to this demand. In this study, we propose the Psy-LLM
framework, an AI-based assistive tool leveraging Large Language Models (LLMs)
for question-answering in psychological consultation settings to ease the
demand for mental health professions. Our framework combines pre-trained LLMs
with real-world professional Q\&A from psychologists and extensively crawled
psychological articles. The Psy-LLM framework serves as a front-end tool for
healthcare professionals, allowing them to provide immediate responses and
mindfulness activities to alleviate patient stress. Additionally, it functions
as a screening tool to identify urgent cases requiring further assistance. We
evaluated the framework using intrinsic metrics, such as perplexity, and
extrinsic evaluation metrics, with human participant assessments of response
helpfulness, fluency, relevance, and logic. The results demonstrate the
effectiveness of the Psy-LLM framework in generating coherent and relevant
answers to psychological questions. This article discusses the potential and
limitations of using large language models to enhance mental health support
through AI technologies.",http://arxiv.org/abs/2307.11991v2
"Mental health diseases affect children's lives and well-beings which have
received increased attention since the COVID-19 pandemic. Analyzing psychiatric
clinical notes with topic models is critical to evaluating children's mental
status over time. However, few topic models are built for longitudinal
settings, and most existing approaches fail to capture temporal trajectories
for each document. To address these challenges, we develop a dynamic topic
model with consistent topics and individualized temporal dependencies on the
evolving document metadata. Our model preserves the semantic meaning of
discovered topics over time and incorporates heterogeneity among documents. In
particular, when documents can be categorized, we propose a classifier-free
approach to maximize topic heterogeneity across different document groups. We
also present an efficient variational optimization procedure adapted for the
multistage longitudinal setting. In this case study, we apply our method to the
psychiatric clinical notes from a large tertiary pediatric hospital in Southern
California and achieve a 38% increase in the overall coherence of extracted
topics. Our real data analysis reveals that children tend to express more
negative emotions during state shutdowns and more positive when schools reopen.
Furthermore, it suggests that sexual and gender minority (SGM) children display
more pronounced reactions to major COVID-19 events and a greater sensitivity to
vaccine-related news than non-SGM children. This study examines children's
mental health progression during the pandemic and offers clinicians valuable
insights to recognize disparities in children's mental health related to their
sexual and gender identities.",http://arxiv.org/abs/2312.14180v2
"Quarantine is a widely-adopted measure during health crises caused by
highly-contagious diseases like COVID-19, yet it poses critical challenges to
public mental health. Given this context, emotional disclosure on social media
in the form of keeping a diary emerges as a popular way for individuals to
express emotions and record their mental health status. However, the
exploration of emotional disclosure via diary-keeping on social media during
quarantine is underexplored, understanding which could be beneficial to
facilitate emotional connections and enlighten health intervention measures.
Focusing on this particular form of self-disclosure, this work proposes a
quantitative approach to figure out the prevalence and changing patterns of
emotional disclosure during quarantine, and the possible factors contributing
to the negative emotions. We collected 58, 796 posts with the ""Quarantine
Diary"" keyword on Weibo, a popular social media website in China. Through text
classification, we capture diverse emotion categories that characterize public
emotion disclosure during quarantine, such as annoyed, anxious, boring, happy,
hopeful and appreciative. Based on temporal analysis, we uncover the changing
patterns of emotional disclosure from long-term perspectives and period-based
perspectives (e.g., the gradual decline of all negative emotions and the
upsurge of the annoyed emotion near the end of quarantine). Leveraging topic
modeling, we also encapsulate the possible influencing factors of negative
emotions, such as freedom restriction and solitude, and uncertainty of
infection and supply. We reflect on how our findings could deepen the
understanding of mental health on social media and further provide practical
and design implications to mitigate mental health issues during quarantine.",http://arxiv.org/abs/2401.07230v1
"Among young adults, suicide is India's leading cause of death, accounting for
an alarming national suicide rate of around 16%. In recent years, machine
learning algorithms have emerged to predict suicidal behavior using various
behavioral traits. But to date, the efficacy of machine learning algorithms in
predicting suicidal behavior in the Indian context has not been explored in
literature. In this study, different machine learning algorithms and ensembles
were developed to predict suicide behavior based on childhood trauma, different
mental health parameters, and other behavioral factors. The dataset was
acquired from 391 individuals from a wellness center in India. Information
regarding their childhood trauma, psychological wellness, and other mental
health issues was acquired through standardized questionnaires. Results
revealed that cascade ensemble learning methods using a support vector machine,
decision trees, and random forest were able to classify suicidal behavior with
an accuracy of 95.04% using data from childhood trauma and mental health
questionnaires. The study highlights the potential of using these machine
learning ensembles to identify individuals with suicidal tendencies so that
targeted interinterventions could be provided efficiently.",http://arxiv.org/abs/2401.17705v1
"Addressing the critical shortage of mental health resources for effective
screening, diagnosis, and treatment remains a significant challenge. This
scarcity underscores the need for innovative solutions, particularly in
enhancing the accessibility and efficacy of therapeutic support. Embodied
agents with advanced interactive capabilities emerge as a promising and
cost-effective supplement to traditional caregiving methods. Crucial to these
agents' effectiveness is their ability to simulate non-verbal behaviors, like
backchannels, that are pivotal in establishing rapport and understanding in
therapeutic contexts but remain under-explored. To improve the rapport-building
capabilities of embodied agents we annotated backchannel smiles in videos of
intimate face-to-face conversations over topics such as mental health, illness,
and relationships. We hypothesized that both speaker and listener behaviors
affect the duration and intensity of backchannel smiles. Using cues from speech
prosody and language along with the demographics of the speaker and listener,
we found them to contain significant predictors of the intensity of backchannel
smiles. Based on our findings, we introduce backchannel smile production in
embodied agents as a generation problem. Our attention-based generative model
suggests that listener information offers performance improvements over the
baseline speaker-centric generation approach. Conditioned generation using the
significant predictors of smile intensity provides statistically significant
improvements in empirical measures of generation quality. Our user study by
transferring generated smiles to an embodied agent suggests that agent with
backchannel smiles is perceived to be more human-like and is an attractive
alternative for non-personal conversations over agent without backchannel
smiles.",http://arxiv.org/abs/2402.08837v1
"Mental health disorders significantly impact people globally, regardless of
background, education, or socioeconomic status. However, access to adequate
care remains a challenge, particularly for underserved communities with limited
resources. Text mining tools offer immense potential to support mental
healthcare by assisting professionals in diagnosing and treating patients. This
study addresses the scarcity of Arabic mental health resources for developing
such tools. We introduce MentalQA, a novel Arabic dataset featuring
conversational-style question-and-answer (QA) interactions. To ensure data
quality, we conducted a rigorous annotation process using a well-defined schema
with quality control measures. Data was collected from a question-answering
medical platform. The annotation schema for mental health questions and
corresponding answers draws upon existing classification schemes with some
modifications. Question types encompass six distinct categories: diagnosis,
treatment, anatomy \& physiology, epidemiology, healthy lifestyle, and provider
choice. Answer strategies include information provision, direct guidance, and
emotional support. Three experienced annotators collaboratively annotated the
data to ensure consistency. Our findings demonstrate high inter-annotator
agreement, with Fleiss' Kappa of $0.61$ for question types and $0.98$ for
answer strategies. In-depth analysis revealed insightful patterns, including
variations in question preferences across age groups and a strong correlation
between question types and answer strategies. MentalQA offers a valuable
foundation for developing Arabic text mining tools capable of supporting mental
health professionals and individuals seeking information.",http://arxiv.org/abs/2405.12619v1
"Mental illness remains one of the most critical public health issues. Despite
its importance, many mental health professionals highlight a disconnect between
their training and actual real-world patient practice. To help bridge this gap,
we propose PATIENT-{\Psi}, a novel patient simulation framework for cognitive
behavior therapy (CBT) training. To build PATIENT-{\Psi}, we construct diverse
patient cognitive models based on CBT principles and use large language models
(LLMs) programmed with these cognitive models to act as a simulated therapy
patient. We propose an interactive training scheme, PATIENT-{\Psi}-TRAINER, for
mental health trainees to practice a key skill in CBT -- formulating the
cognitive model of the patient -- through role-playing a therapy session with
PATIENT-{\Psi}. To evaluate PATIENT-{\Psi}, we conducted a comprehensive user
study of 13 mental health trainees and 20 experts. The results demonstrate that
practice using PATIENT-{\Psi}-TRAINER enhances the perceived skill acquisition
and confidence of the trainees beyond existing forms of training such as
textbooks, videos, and role-play with non-patients. Based on the experts'
perceptions, PATIENT-{\Psi} is perceived to be closer to real patient
interactions than GPT-4, and PATIENT-{\Psi}-TRAINER holds strong promise to
improve trainee competencies. Our code and data are released at
\url{https://github.com/ruiyiw/patient-psi}.",http://arxiv.org/abs/2405.19660v3
"Over the past decade, there has been a severe staffing shortage in mental
healthcare, exacerbated by increased demand for mental health services due to
COVID-19. This demand is projected to increase over the next decade or so,
necessitating proactive workforce planning to ensure sufficient staffing for
ongoing service delivery. Despite the subject's critical significance, the
present literature lacks thorough research dedicated to developing a model that
addresses the long-term workforce needs required for efficient mental
healthcare planning. Furthermore, our interactions with mental health
practitioners within the United Kingdom's National Health Service (NHS)
revealed the practical need for such a model. To address this gap, we aim to
develop a hybrid predictive and prescriptive modelling framework, which
combines long-term probabilistic forecasting with an analytical stock-flow
model, designed specifically for mental health workforce planning. Given the
vital role of nurses, who account for one-third of the total mental health
workforce, we focus on modelling the headcount of nurses, but the proposed
model can be generalised to other types of workforce planning in the healthcare
sector. Using statistical and machine learning approaches and real-world data
from NHS, we first identify factors contributing to variations in workforce
requirements, then develop a long-term forecasting model to estimate future
workforce needs, and finally integrate it into an analytical stock-flow method
to provide policy analysis. Our findings highlight the unsustainable nature of
present staffing plans, showing a growing nursing shortage. Furthermore, the
policy analysis demonstrates the ineffectiveness of blanket remedies,
highlighting the need for regional-level policy developments.",http://arxiv.org/abs/2406.17463v1
"Large language models (LLMs) are emerging as promising tools for mental
health care, offering scalable support through their ability to generate
human-like responses. However, the effectiveness of these models in clinical
settings remains unclear. This scoping review aimed to assess the current
generative applications of LLMs in mental health care, focusing on studies
where these models were tested with human participants in real-world scenarios.
A systematic search across APA PsycNet, Scopus, PubMed, and Web of Science
identified 726 unique articles, of which 17 met the inclusion criteria. These
studies encompassed applications such as clinical assistance, counseling,
therapy, and emotional support. However, the evaluation methods were often
non-standardized, with most studies relying on ad hoc scales that limit
comparability and robustness. Privacy, safety, and fairness were also
frequently underexplored. Moreover, reliance on proprietary models, such as
OpenAI's GPT series, raises concerns about transparency and reproducibility.
While LLMs show potential in expanding mental health care access, especially in
underserved areas, the current evidence does not fully support their use as
standalone interventions. More rigorous, standardized evaluations and ethical
oversight are needed to ensure these tools can be safely and effectively
integrated into clinical practice.",http://arxiv.org/abs/2408.11288v1
"Mental disorders, such as anxiety and depression, have become a global issue
that affects the regular lives of people across different ages. Without proper
detection and treatment, anxiety and depression can hinder the sufferer's
study, work, and daily life. Fortunately, recent advancements of digital and AI
technologies provide new opportunities for better mental health care and many
efforts have been made in developing automatic anxiety and depression
assessment techniques. However, this field still lacks a publicly available
large-scale dataset that can facilitate the development and evaluation of
AI-based techniques. To address this limitation, we have constructed a new
large-scale \textbf{M}ulti-\textbf{M}odal \textbf{Psy}chological assessment
corpus (MMPsy) on anxiety and depression assessment of Mandarin-speaking
adolescents. The MMPsy contains audios and extracted transcripts of responses
from automated anxiety or depression assessment interviews along with the
self-reported anxiety or depression evaluations of the participants using
standard mental health assessment questionnaires. Our dataset contains over
7,700 post-processed recordings of interviews for anxiety assessment and over
4,200 recordings for depression assessment. Using this dataset, we have
developed a novel deep-learning based mental disorder estimation model, named
\textbf{Mental-Perceiver}, to detect anxious/depressive mental states from
recorded audio and transcript data. Extensive experiments on our MMPsy and the
commonly-used DAIC-WOZ datasets have shown the effectiveness and superiority of
our proposed Mental-Perceiver model in anxiety and depression detection. The
MMPsy dataset will be made publicly available later to facilitate the research
and development of AI-based techniques in the mental health care field.",http://arxiv.org/abs/2408.12088v1
"Wider access to therapeutic care is one of the biggest challenges in mental
health treatment. Due to institutional barriers, some people seeking mental
health support have turned to large language models (LLMs) for personalized
therapy, even though these models are largely unsanctioned and untested. We
investigate the potential and limitations of using LLMs as providers of
evidence-based therapy by using mixed methods clinical metrics. Using HELPERT,
a prompt run on a large language model using the same process and training as a
comparative group of peer counselors, we replicated publicly accessible mental
health conversations rooted in Cognitive Behavioral Therapy (CBT) to compare
session dynamics and counselor's CBT-based behaviors between original peer
support sessions and their reconstructed HELPERT sessions. Two licensed,
CBT-trained clinical psychologists evaluated the sessions using the Cognitive
Therapy Rating Scale and provided qualitative feedback. Our findings show that
the peer sessions are characterized by empathy, small talk, therapeutic
alliance, and shared experiences but often exhibit therapist drift. Conversely,
HELPERT reconstructed sessions exhibit minimal therapist drift and higher
adherence to CBT methods but display a lack of collaboration, empathy, and
cultural understanding. Through CTRS ratings and psychologists' feedback, we
highlight the importance of human-AI collaboration for scalable mental health.
Our work outlines the ethical implication of imparting human-like subjective
qualities to LLMs in therapeutic settings, particularly the risk of deceptive
empathy, which may lead to unrealistic patient expectations and potential harm.",http://arxiv.org/abs/2409.02244v1
"This study addresses the critical issue of gender-based violence's (GBV)
impact on women's mental health. GBV, encompassing physical and sexual
aggression, often results in long-lasting adverse effects for the victims,
including anxiety, depression, post-traumatic stress disorder (PTSD), and
substance abuse. Artificial Intelligence (AI)-based speech technologies have
proven valuable for mental health assessments. However, these technologies
experience performance challenges when confronted with speakers whose data has
not been used for training.
  Our research presents a novel approach to speaker-agnostic detection of the
gender-based violence victim condition (GBVVC), focusing on the development of
robust AI models capable of generalization across diverse speakers. Leveraging
advanced deep learning models and domain-adversarial training techniques, we
minimize speaker identity's influence, achieving a 26.95% relative reduction in
speaker identification ability while enhancing the GBVVC detection by a 6.37%
relative improvement in the accuracy. This shows that models can focus on
discriminative paralinguistic biomarkers that enhance the GBVVC prediction, and
reduce the subject-specific traits' impact.
  Additionally, our model's predictions moderately correlate with pre-clinical
PTSD symptoms, emphasizing the link between GBV and mental health. This work
paves the way for AI-powered tools to aid mental health professionals in
addressing this societal issue, offering a promising baseline for further
research.",http://arxiv.org/abs/2411.18177v1
"We introduce a general-purpose, human-in-the-loop dual dialogue system to
support mental health care professionals. The system, co-designed with care
providers, is conceptualized to assist them in interacting with care seekers
rather than functioning as a fully automated dialogue system solution. The AI
assistant within the system reduces the cognitive load of mental health care
providers by proposing responses, analyzing conversations to extract pertinent
themes, summarizing dialogues, and recommending localized relevant content and
internet-based cognitive behavioral therapy exercises. These functionalities
are achieved through a multi-agent system design, where each specialized,
supportive agent is characterized by a large language model. In evaluating the
multi-agent system, we focused specifically on the proposal of responses to
emotionally distressed care seekers. We found that the proposed responses
matched a reasonable human quality in demonstrating empathy, showing its
appropriateness for augmenting the work of mental health care providers.",http://arxiv.org/abs/2411.18429v2
"For the early identification, diagnosis, and treatment of mental health
illnesses, the integration of deep learning (DL) and machine learning (ML) has
started playing a significant role. By evaluating complex data from imaging,
genetics, and behavioral assessments, these technologies have the potential to
significantly improve clinical outcomes. However, they also present unique
challenges related to data integration and ethical issues. This survey reviews
the development of ML and DL methods for the early diagnosis and treatment of
mental health issues. It examines a range of applications, with a particular
emphasis on behavioral assessments, genetic and biomarker analysis, and medical
imaging for diagnosing diseases like depression, bipolar disorder, and
schizophrenia. Predictive modeling for illness progression is further
discussed, focusing on the role of risk prediction models and longitudinal
studies. Key findings highlight how ML and DL can improve diagnostic accuracy
and treatment outcomes while addressing methodological inconsistencies, data
integration challenges, and ethical concerns. The study emphasizes the
importance of building real-time monitoring systems for individualized
treatment, enhancing data fusion techniques, and fostering interdisciplinary
collaboration. Future research should focus on overcoming these obstacles to
ensure the valuable and ethical application of ML and DL in mental health
services.",http://arxiv.org/abs/2412.06147v1
"The problem we consider considers estimating a multivariate longitudinal
panel data model whose outcomes can be a combination of discrete and continuous
variables. This problem is challenging because the likelihood is usually
analytically intractable. Our article makes both a methodological contribution
and also a substantive contribution to the application. The methodological
contribution is to introduce into the panel data literature a particle
Metropolis within Gibbs method to carry out Bayesian inference, using a
Hamiltonian Monte Carlo (Neal 2011} proposal for sampling the vector of unknown
parameters. We note that in panel data models the Our second contribution is to
apply our method to carry out a serious analysis of the impact of serious life
events on mental health and excessive alcohol consumption. The dependence
between these two outcomes may be more pronounced when consumption of alcohol
is excessive and mental health poor, which in turn has implications for how
life events impact the joint distribution of the outcomes.",http://arxiv.org/abs/1706.03953v3
"In recent years, we have seen deep learning and distributed representations
of words and sentences make impact on a number of natural language processing
tasks, such as similarity, entailment and sentiment analysis. Here we introduce
a new task: understanding of mental health concepts derived from Cognitive
Behavioural Therapy (CBT). We define a mental health ontology based on the CBT
principles, annotate a large corpus where this phenomena is exhibited and
perform understanding using deep learning and distributed representations. Our
results show that the performance of deep learning models combined with word
embeddings or sentence embeddings significantly outperform non-deep-learning
models in this difficult task. This understanding module will be an essential
component of a statistical dialogue system delivering therapy.",http://arxiv.org/abs/1809.00640v1
"With more than 300 million people depressed worldwide, depression is a global
problem. Due to access barriers such as social stigma, cost, and treatment
availability, 60% of mentally-ill adults do not receive any mental health
services. Effective and efficient diagnosis relies on detecting clinical
symptoms of depression. Automatic detection of depressive symptoms would
potentially improve diagnostic accuracy and availability, leading to faster
intervention. In this work, we present a machine learning method for measuring
the severity of depressive symptoms. Our multi-modal method uses 3D facial
expressions and spoken language, commonly available from modern cell phones. It
demonstrates an average error of 3.67 points (15.3% relative) on the
clinically-validated Patient Health Questionnaire (PHQ) scale. For detecting
major depressive disorder, our model demonstrates 83.3% sensitivity and 82.6%
specificity. Overall, this paper shows how speech recognition, computer vision,
and natural language processing can be combined to assist mental health
patients and practitioners. This technology could be deployed to cell phones
worldwide and facilitate low-cost universal access to mental health care.",http://arxiv.org/abs/1811.08592v2
"Precision medicine has received attention both in and outside the clinic. We
focus on the latter, by exploiting the relationship between individuals' social
interactions and their mental health to develop a predictive model of one's
likelihood to be depressed or anxious from rich dynamic social network data. To
our knowledge, we are the first to do this. Existing studies differ from our
work in at least one aspect: they do not model social interaction data as a
network; they do so but analyze static network data; they examine ""correlation""
between social networks and health but without developing a predictive model;
or they study other individual traits but not mental health. In a systematic
and comprehensive evaluation, we show that our predictive model that uses
dynamic social network data is superior to its static network as well as
non-network equivalents when run on the same data.",http://arxiv.org/abs/1908.02614v1
"Many statistical models have high accuracy on test benchmarks, but are not
explainable, struggle in low-resource scenarios, cannot be reused for multiple
tasks, and cannot easily integrate domain expertise. These factors limit their
use, particularly in settings such as mental health, where it is difficult to
annotate datasets and model outputs have significant impact. We introduce a
micromodel architecture to address these challenges. Our approach allows
researchers to build interpretable representations that embed domain knowledge
and provide explanations throughout the model's decision process. We
demonstrate the idea on multiple mental health tasks: depression
classification, PTSD classification, and suicidal risk assessment. Our systems
consistently produce strong results, even in low-resource scenarios, and are
more interpretable than alternative methods.",http://arxiv.org/abs/2109.13770v1
"The mental disorder of online users is determined using social media posts.
The major challenge in this domain is to avail the ethical clearance for using
the user generated text on social media platforms. Academic re searchers
identified the problem of insufficient and unlabeled data for mental health
classification. To handle this issue, we have studied the effect of data
augmentation techniques on domain specific user generated text for mental
health classification. Among the existing well established data augmentation
techniques, we have identified Easy Data Augmentation (EDA), conditional BERT,
and Back Translation (BT) as the potential techniques for generating additional
text to improve the performance of classifiers. Further, three different
classifiers Random Forest (RF), Support Vector Machine (SVM) and Logistic
Regression (LR) are employed for analyzing the impact of data augmentation on
two publicly available social media datasets. The experiments mental results
show significant improvements in classifiers performance when trained on the
augmented data.",http://arxiv.org/abs/2112.10064v1
"The present work discusses the pertinence of a 'sociotype' construct, both
theoretically and empirically oriented. The term, based on the conceptual chain
genotype-phenotype-sociotype, suggests an evolutionary preference in the human
species for some determined averages of social relationships. This core pattern
or 'sociotype' has been explored herein for the networking relationships of
young people--165 university students filling in a 20-items questionnaire on
their social interactions. In spite that this is a preliminary study,
interesting results have been obtained on gender conversation time, mental
health, sociability level, and satisfaction with personal relationships. This
sociotype hypothesis could be a timely enterprise for mental health and quality
of life policies.",http://arxiv.org/abs/1405.4136v1
"More than two thirds of mental health problems have their onset during
childhood or adolescence. Identifying children at risk for mental illness later
in life and predicting the type of illness is not easy. We set out to develop a
platform to define subtypes of childhood social-emotional development using
longitudinal, multifactorial trait-based measures. Subtypes discovered through
this study could ultimately advance psychiatric knowledge of the early
behavioural signs of mental illness. To this extent we have examined two types
of models: latent class mixture models and GP-based models. Our findings
indicate that while GP models come close in accuracy of predicting future
trajectories, LCMMs predict the trajectories as well in a fraction of the time.
Unfortunately, neither of the models are currently accurate enough to lead to
immediate clinical impact. The available data related to the development of
childhood mental health is often sparse with only a few time points measured
and require novel methods with improved efficiency and accuracy.",http://arxiv.org/abs/1612.01055v1
"With ubiquity of social media platforms, millions of people are sharing their
online persona by expressing their thoughts, moods, emotions, feelings, and
even their daily struggles with mental health issues voluntarily and publicly
on social media. Unlike the most existing efforts which study depression by
analyzing textual content, we examine and exploit multimodal big data to
discern depressive behavior using a wide variety of features including
individual-level demographics. By developing a multimodal framework and
employing statistical techniques for fusing heterogeneous sets of features
obtained by processing visual, textual and user interaction data, we
significantly enhance the current state-of-the-art approaches for identifying
depressed individuals on Twitter (improving the average F1-Score by 5 percent)
as well as facilitate demographic inference from social media for broader
applications. Besides providing insights into the relationship between
demographics and mental health, our research assists in the design of a new
breed of demographic-aware health interventions.",http://arxiv.org/abs/1902.06843v1
"The outbreak of coronavirus disease 2019 (COVID-19) recently has affected
human life to a great extent. Besides direct physical and economic threats, the
pandemic also indirectly impact people's mental health conditions, which can be
overwhelming but difficult to measure. The problem may come from various
reasons such as unemployment status, stay-at-home policy, fear for the virus,
and so forth. In this work, we focus on applying natural language processing
(NLP) techniques to analyze tweets in terms of mental health. We trained deep
models that classify each tweet into the following emotions: anger,
anticipation, disgust, fear, joy, sadness, surprise and trust. We build the
EmoCT (Emotion-Covid19-Tweet) dataset for the training purpose by manually
labeling 1,000 English tweets. Furthermore, we propose and compare two methods
to find out the reasons that are causing sadness and fear.",http://arxiv.org/abs/2004.10899v3
"Depression and post-traumatic stress disorder (PTSD) are psychiatric
conditions commonly associated with experiencing a traumatic event. Estimating
mental health status through non-invasive techniques such as activity-based
algorithms can help to identify successful early interventions. In this work,
we used locomotor activity captured from 1113 individuals who wore a research
grade smartwatch post-trauma. A convolutional variational autoencoder (VAE)
architecture was used for unsupervised feature extraction from four weeks of
actigraphy data. By using VAE latent variables and the participant's pre-trauma
physical health status as features, a logistic regression classifier achieved
an area under the receiver operating characteristic curve (AUC) of 0.64 to
estimate mental health outcomes. The results indicate that the VAE model is a
promising approach for actigraphy data analysis for mental health outcomes in
long-term studies.",http://arxiv.org/abs/2011.07406v2
"In this paper, we analyze the interplay between the use of offensive language
and mental health. We acquired publicly available datasets created for
offensive language identification and depression detection and we train
computational models to compare the use of offensive language in social media
posts written by groups of individuals with and without self-reported
depression diagnosis. We also look at samples written by groups of individuals
whose posts show signs of depression according to recent related studies. Our
analysis indicates that offensive language is more frequently used in the
samples written by individuals with self-reported depression as well as
individuals showing signs of depression. The results discussed here open new
avenues in research in politeness/offensiveness and mental health.",http://arxiv.org/abs/2105.14888v2
"Great research interests have been attracted to devise AI services that are
able to provide mental health support. However, the lack of corpora is a main
obstacle to this research, particularly in Chinese language. In this paper, we
propose PsyQA, a Chinese dataset of psychological health support in the form of
question and answer pair. PsyQA is crawled from a Chinese mental health service
platform, and contains 22K questions and 56K long and well-structured answers.
Based on the psychological counseling theories, we annotate a portion of answer
texts with typical strategies for providing support, and further present
in-depth analysis of both lexical features and strategy patterns in the
counseling answers. We also evaluate the performance of generating counseling
answers with the generative pretrained models. Results show that utilizing
strategies enhances the fluency and helpfulness of generated answers, but there
is still a large space for future research.",http://arxiv.org/abs/2106.01702v1
"It may be difficult for some individuals to open up and share their thoughts
and feelings in front of a mental health expert. For those who are more at ease
with a virtual agent, conversational agents can serve as an intermediate step
in the right direction. The conversational agent must therefore be empathetic
and able to conduct free-flowing conversations. To this effect, we present an
approach for creating a generative empathetic open-domain chatbot that can be
used for mental health applications. We leverage large scale pre-training and
empathetic conversational data to make the responses more empathetic in nature
and a multi-turn dialogue arrangement to maintain context. Our models achieve
state-of-the-art results on the Empathetic Dialogues test set.",http://arxiv.org/abs/2111.08545v1
"Research community has witnessed substantial growth in the detection of
mental health issues and their associated reasons from analysis of social
media. We introduce a new dataset for Causal Analysis of Mental health issues
in Social media posts (CAMS). Our contributions for causal analysis are
two-fold: causal interpretation and causal categorization. We introduce an
annotation schema for this task of causal analysis. We demonstrate the efficacy
of our schema on two different datasets: (i) crawling and annotating 3155
Reddit posts and (ii) re-annotating the publicly available SDCNL dataset of
1896 instances for interpretable causal analysis. We further combine these into
the CAMS dataset and make this resource publicly available along with
associated source code: https://github.com/drmuskangarg/CAMS. We present
experimental results of models learned from CAMS dataset and demonstrate that a
classic Logistic Regression model outperforms the next best (CNN-LSTM) model by
4.9\% accuracy.",http://arxiv.org/abs/2207.04674v1
"As a vital aspect of individual's quality of life, mental health has been
included as an important component of the U.N. Sustainable Development Goals.
This study focuses on a specific aspect of mental health: depression, and
examines its relationship with commute patterns. Using survey data from 1,528
residents in Beijing, China, we find that every 10 additional minutes of
commute time is associated with 1.1% higher likelihood of depression. We test
for the mechanisms of the commute-depression link and find that commute is
associated with depression as a direct stressor rather than triggering higher
work stress. When decomposing commute time into mode-specific time, we found
that time on mopeds/motorcycles has the strongest association with depression.
Moreover, the commute-depression associations are stronger for older workers
and blue-collar workers. Hence, policies that could reduce commute time,
encourage work from home, improve job-housing balance or increase
motorcyclists' safety would help promote mental health.",http://arxiv.org/abs/2207.07990v1
"Social robots have been used to assist with mental well-being in various ways
such as to help children with autism improve on their social skills and
executive functioning such as joint attention and bodily awareness. They are
also used to help older adults by reducing feelings of isolation and
loneliness, as well as supporting mental well-being of teens and children.
However, existing work in this sphere has only shown support for mental health
through social robots by responding interactively to human activity to help
them learn relevant skills. We hypothesize that humans can also get help from
social robots in mental well-being by releasing or sharing their mental health
data with the social robots. In this paper, we present a human-robot
interaction (HRI) study to evaluate this hypothesis. During the five-day study,
a total of fifty-five (n=55) participants shared their in-the-moment mood and
stress levels with a social robot. We saw a majority of positive results
indicating it is worth conducting future work in this direction, and the
potential of social robots to largely support mental well-being.",http://arxiv.org/abs/2208.04389v1
"To study the causes of the 2021 Great Resignation, we use text analysis to
investigate the changes in work- and quit-related posts between 2018 and 2021
on Reddit. We find that the Reddit discourse evolution resembles the dynamics
of the U.S. quit and layoff rates. Furthermore, when the COVID-19 pandemic
started, conversations related to working from home, switching jobs,
work-related distress, and mental health increased. We distinguish between
general work-related and specific quit-related discourse changes using a
difference-in-differences method. Our main finding is that mental health and
work-related distress topics disproportionally increased among quit-related
posts since the onset of the pandemic, likely contributing to the Great
Resignation. Along with better labor market conditions, some relief came
beginning-to-mid-2021 when these concerns decreased. Our study validates the
use of forums such as Reddit for studying emerging economic phenomena in real
time, complementing traditional labor market surveys and administrative data.",http://arxiv.org/abs/2208.07926v1
"With recent developments in digitization of clinical psychology, NLP research
community has revolutionized the field of mental health detection on social
media. Existing research in mental health analysis revolves around the
cross-sectional studies to classify users' intent on social media. For in-depth
analysis, we investigate existing classifiers to solve the problem of causal
categorization which suggests the inefficiency of learning based methods due to
limited training samples. To handle this challenge, we use transformer models
and demonstrate the efficacy of a pre-trained transfer learning on ""CAMS""
dataset. The experimental result improves the accuracy and depicts the
importance of identifying cause-and-effect relationships in the underlying
text.",http://arxiv.org/abs/2301.02589v2
"Automatically generating short summaries from users' online mental health
posts could save counselors' reading time and reduce their fatigue so that they
can provide timely responses to those seeking help for improving their mental
state. Recent Transformers-based summarization models have presented a
promising approach to abstractive summarization. They go beyond sentence
selection and extractive strategies to deal with more complicated tasks such as
novel word generation and sentence paraphrasing. Nonetheless, these models have
a prominent shortcoming; their training strategy is not quite efficient, which
restricts the model's performance. In this paper, we include a curriculum
learning approach to reweigh the training samples, bringing about an efficient
learning procedure. We apply our model on extreme summarization dataset of
MentSum posts -- a dataset of mental health related posts from Reddit social
media. Compared to the state-of-the-art model, our proposed method makes
substantial gains in terms of Rouge and Bertscore evaluation metrics, yielding
3.5% (Rouge-1), 10.4% (Rouge-2), and 4.7% (Rouge-L), 1.5% (Bertscore) relative
improvements.",http://arxiv.org/abs/2302.00954v1
"The Papageno effect concerns how media can play a positive role in preventing
and mitigating suicidal ideation and behaviors. With the increasing ubiquity
and widespread use of social media, individuals often express and share lived
experiences and struggles with mental health. However, there is a gap in our
understanding about the existence and effectiveness of the Papageno effect in
social media, which we study in this paper. In particular, we adopt a
causal-inference framework to examine the impact of exposure to mental health
coping stories on individuals on Twitter. We obtain a Twitter dataset with
$\sim$2M posts by $\sim$10K individuals. We consider engaging with coping
stories as the Treatment intervention, and adopt a stratified propensity score
approach to find matched cohorts of Treatment and Control individuals. We
measure the psychosocial shifts in affective, behavioral, and cognitive
outcomes in longitudinal Twitter data before and after engaging with the coping
stories. Our findings reveal that, engaging with coping stories leads to
decreased stress and depression, and improved expressive writing, diversity,
and interactivity. Our work discusses the practical and platform design
implications in supporting mental wellbeing.",http://arxiv.org/abs/2302.09885v1
"Virtual Mental Health Assistants (VMHAs) are seeing continual advancements to
support the overburdened global healthcare system that gets 60 million primary
care visits, and 6 million Emergency Room (ER) visits annually. These systems
are built by clinical psychologists, psychiatrists, and Artificial Intelligence
(AI) researchers for Cognitive Behavioral Therapy (CBT). At present, the role
of VMHAs is to provide emotional support through information, focusing less on
developing a reflective conversation with the patient. A more comprehensive,
safe and explainable approach is required to build responsible VMHAs to ask
follow-up questions or provide a well-informed response. This survey offers a
systematic critical review of the existing conversational agents in mental
health, followed by new insights into the improvements of VMHAs with contextual
knowledge, datasets, and their emerging role in clinical decision support. We
also provide new directions toward enriching the user experience of VMHAs with
explainability, safety, and wholesome trustworthiness. Finally, we provide
evaluation metrics and practical considerations for VMHAs beyond the current
literature to build trust between VMHAs and patients in active communications.",http://arxiv.org/abs/2304.13191v1
"The recent shift to remote learning and work has aggravated long-standing
problems, such as the problem of monitoring the mental health of individuals
and the progress of students towards learning targets. We introduce a novel
latent process model with a view to monitoring the progress of individuals
towards a hard-to-measure target of interest, measured by a set of variables.
The latent process model is based on the idea of embedding both individuals and
variables measuring progress towards the target of interest in a shared metric
space, interpreted as an interaction map that captures interactions between
individuals and variables. The fact that individuals are embedded in the same
metric space as the target helps assess the progress of individuals towards the
target. We demonstrate, with the help of simulations and applications, that the
latent process model enables a novel look at mental health and online
educational assessments in disadvantaged subpopulations.",http://arxiv.org/abs/2305.09804v2
"Wellness in trivial terms combines physical, social, and mental wellbeing.
While mental health is neglected, long-term success in a person life is mostly
determined by his psychological health and contentment. For a person in
distress, professional mental health services are quite expensive, unpopular,
and invite a lot of hesitation. Hence, it would be effective to use an Android
application that can offer day to day therapeutic assistance, meditation
sessions, and guidance since it can cater to a massive community instantly. In
this paper, we propose a mobile and web application AMITY with a chat group and
chatbot created using a machine learning approach. We have also built a dataset
to train the chatbot model that we propose in this paper. We briefly introduce
the dataset and the machine learning model in section 3. In section 4, we
include the architecture and the development details of the Hybrid application.
Next, we present our results on usability and the efficiency of the idea we
propose.",http://arxiv.org/abs/2305.11871v1
"Precision psychiatry is an ermerging field that aims to provide
individualized approaches to mental health care. Multivariate analysis and
machine learning are used to create outcome prediction models based on clinical
data such as demographics, symptom assessments, genetic information, and brain
imaging. While much emphasis has been placed on technical innovation, the
complex and varied nature of mental health presents significant challenges to
the successful implementation of these models. From this perspective, I review
ten challenges in the field of precision psychiatry, including the need for
studies on real-world populations and realistic clinical outcome definitions,
consideration of treatment-related factors such as placebo effects and
non-adherence to prescriptions. Fairness, prospective validation in comparison
to current practice and implementation studies of prediction models are other
key issues that are currently understudied. A shift is proposed from
retrospective studies based on linear and static concepts of disease towards
prospective research that considers the importance of contextual factors and
the dynamic and complex nature of mental health.",http://arxiv.org/abs/2306.12462v1
"Our paper investigates the use of discourse embedding techniques to develop a
community recommendation system that focuses on mental health support groups on
social media. Social media platforms provide a means for users to anonymously
connect with communities that cater to their specific interests. However, with
the vast number of online communities available, users may face difficulties in
identifying relevant groups to address their mental health concerns. To address
this challenge, we explore the integration of discourse information from
various subreddit communities using embedding techniques to develop an
effective recommendation system. Our approach involves the use of content-based
and collaborative filtering techniques to enhance the performance of the
recommendation system. Our findings indicate that the proposed approach
outperforms the use of each technique separately and provides interpretability
in the recommendation process.",http://arxiv.org/abs/2307.03892v1
"During the current mental health crisis, the importance of identifying
potential indicators of mental issues from social media content has surged.
Overlooking the multifaceted nature of mental and social well-being can have
detrimental effects on one's mental state. In traditional therapy sessions,
professionals manually pinpoint the origins and outcomes of underlying mental
challenges, a process both detailed and time-intensive. We introduce an
approach to this intricate mental health analysis by framing the identification
of wellness dimensions in Reddit content as a wellness concept extraction and
categorization challenge. We've curated a unique dataset named WELLXPLAIN,
comprising 3,092 entries and totaling 72,813 words. Drawing from Halbert L.
Dunn's well-regarded wellness theory, our team formulated an annotation
framework along with guidelines. This dataset also includes human-marked
textual segments, offering clear reasoning for decisions made in the wellness
concept categorization process. Our aim in publishing this dataset and
analyzing initial benchmarks is to spearhead the creation of advanced language
models tailored for healthcare-focused concept extraction and categorization.",http://arxiv.org/abs/2308.13710v1
"Large Language Models (LLMs) have demonstrated remarkable performance across
various information-seeking and reasoning tasks. These computational systems
drive state-of-the-art dialogue systems, such as ChatGPT and Bard. They also
carry substantial promise in meeting the growing demands of mental health care,
albeit relatively unexplored. As such, this study sought to examine LLMs'
capability to generate empathetic responses in conversations that emulate those
in a mental health counselling setting. We selected five LLMs: version 3.5 and
version 4 of the Generative Pre-training (GPT), Vicuna FastChat-T5, Pathways
Language Model (PaLM) version 2, and Falcon-7B-Instruct. Based on a simple
instructional prompt, these models responded to utterances derived from the
EmpatheticDialogues (ED) dataset. Using three empathy-related metrics, we
compared their responses to those from traditional response generation dialogue
systems, which were fine-tuned on the ED dataset, along with human-generated
responses. Notably, we discovered that responses from the LLMs were remarkably
more empathetic in most scenarios. We position our findings in light of
catapulting advancements in creating empathetic conversational systems.",http://arxiv.org/abs/2310.08017v1
"Artificial Intelligence (AI) has revolutionized various fields, including
medicine and mental health support. One promising application is ChatGPT, an
advanced conversational AI model that uses deep learning techniques to provide
human-like responses. This review paper explores the potential impact of
ChatGPT in psychiatry and its various applications, highlighting its role in
therapy and counseling techniques, self-help and coping strategies, mindfulness
and relaxation techniques, screening and monitoring, education and information
dissemination, specialized support, group and family support, learning and
training, expressive and artistic therapies, telepsychiatry and online support,
and crisis management and prevention. While ChatGPT offers personalized,
accessible, and scalable support, it is essential to emphasize that it should
not replace the expertise and guidance of qualified mental health
professionals. Ethical considerations, such as user privacy, data security, and
human oversight, are also discussed. By examining the potential and challenges,
this paper sheds light on the responsible integration of ChatGPT in psychiatric
research and practice, fostering improved mental health outcomes.",http://arxiv.org/abs/2311.09131v1
"The COVID-19 pandemic has intensified the urgency for effective and
accessible mental health interventions in people's daily lives. Mobile Health
(mHealth) solutions, such as AI Chatbots and Mindfulness Apps, have gained
traction as they expand beyond traditional clinical settings to support daily
life. However, the effectiveness of current mHealth solutions is impeded by the
lack of context-awareness, personalization, and modularity to foster their
reusability. This paper introduces CAREForMe, a contextual multi-armed bandit
(CMAB) recommendation framework for mental health. Designed with
context-awareness, personalization, and modularity at its core, CAREForMe
harnesses mobile sensing and integrates online learning algorithms with user
clustering capability to deliver timely, personalized recommendations. With its
modular design, CAREForMe serves as both a customizable recommendation
framework to guide future research, and a collaborative platform to facilitate
interdisciplinary contributions in mHealth research. We showcase CAREForMe's
versatility through its implementation across various platforms (e.g., Discord,
Telegram) and its customization to diverse recommendation features.",http://arxiv.org/abs/2401.15188v1
"We collected and analyzed Instagram direct messages (DMs) from 173 youth aged
13-21 (including 86 LGBTQ+ youth). We examined youth's risk-flagged social
media trace data with their self-reported mental health outcomes to examine how
the differing online experiences of LGBTQ+ youth compare with their
heterosexual counterparts. We found that LGBTQ+ youth experienced significantly
more high-risk online interactions compared to heterosexual youth. LGBTQ+ youth
reported overall poorer mental health, with online harassment specifically
amplifying Self-Harm and Injury. LGBTQ+ youth's mental well-being linked
positively to sexual messages, unlike heterosexual youth. Qualitatively, we
found that most of the risk-flagged messages of LGBTQ+ youth were sexually
motivated; however, a silver lining was that they sought support for their
sexual identity from peers on the platform. The study highlights the importance
of tailored online safety and inclusive design for LGBTQ+ youth, with
implications for CHI community advancements in fostering a supportive online
environments.",http://arxiv.org/abs/2402.08974v1
"Recent advancements in Large Language Models (LLMs) have accelerated their
usage in various domains. Given the fact that psychiatric interviews are
goal-oriented and structured dialogues between the professional interviewer and
the interviewee, it is one of the most underexplored areas where LLMs can
contribute substantial value. Here, we explore the use of LLMs for enhancing
psychiatric interviews, by analyzing counseling data from North Korean
defectors with traumatic events and mental health issues. Specifically, we
investigate whether LLMs can (1) delineate the part of the conversation that
suggests psychiatric symptoms and name the symptoms, and (2) summarize
stressors and symptoms, based on the interview dialogue transcript. Here, the
transcript data was labeled by mental health experts for training and
evaluation of LLMs. Our experimental results show that appropriately prompted
LLMs can achieve high performance on both the symptom delineation task and the
summarization task. This research contributes to the nascent field of applying
LLMs to psychiatric interview and demonstrates their potential effectiveness in
aiding mental health practitioners.",http://arxiv.org/abs/2403.17428v1
"Early detection of depressive episodes is crucial in managing mental health
disorders such as Major Depressive Disorder (MDD) and Bipolar Disorder.
However, existing methods often necessitate active participation or are
confined to clinical settings. Addressing this gap, we introduce PupilSense, a
novel, deep learning-driven mobile system designed to discreetly track
pupillary responses as users interact with their smartphones in their daily
lives. This study presents a proof-of-concept exploration of PupilSense's
capabilities, where we captured real-time pupillary data from users in
naturalistic settings. Our findings indicate that PupilSense can effectively
and passively monitor indicators of depressive episodes, offering a promising
tool for continuous mental health assessment outside laboratory environments.
This advancement heralds a significant step in leveraging ubiquitous mobile
technology for proactive mental health care, potentially transforming how
depressive episodes are detected and managed in everyday contexts.",http://arxiv.org/abs/2404.14590v1
"Current research in machine learning and artificial intelligence is largely
centered on modeling and performance evaluation, less so on data collection.
However, recent research demonstrated that limitations and biases in data may
negatively impact trustworthiness and reliability. These aspects are
particularly impactful on sensitive domains such as mental health and
neurological disorders, where speech data are used to develop AI applications
aimed at improving the health of patients and supporting healthcare providers.
In this paper, we chart the landscape of available speech datasets for this
domain, to highlight possible pitfalls and opportunities for improvement and
promote fairness and diversity. We present a comprehensive list of desiderata
for building speech datasets for mental health and neurological disorders and
distill it into a checklist focused on ethical concerns to foster more
responsible research.",http://arxiv.org/abs/2406.04116v1
"The detection of depression through non-verbal cues has gained significant
attention. Previous research predominantly centred on identifying depression
within the confines of controlled laboratory environments, often with the
supervision of psychologists or counsellors. Unfortunately, datasets generated
in such controlled settings may struggle to account for individual behaviours
in real-life situations. In response to this limitation, we present the
Extended D-vlog dataset, encompassing a collection of 1, 261 YouTube vlogs.
Additionally, the emergence of large language models (LLMs) like GPT3.5, and
GPT4 has sparked interest in their potential they can act like mental health
professionals. Yet, the readiness of these LLM models to be used in real-life
settings is still a concern as they can give wrong responses that can harm the
users. We introduce a virtual agent serving as an initial contact for mental
health patients, offering Cognitive Behavioral Therapy (CBT)-based responses.
It comprises two core functions: 1. Identifying depression in individuals, and
2. Delivering CBT-based therapeutic responses. Our Mistral model achieved
impressive scores of 70.1% and 30.9% for distortion assessment and
classification, along with a Bert score of 88.7%. Moreover, utilizing the TVLT
model on our Multimodal Extended D-vlog Dataset yielded outstanding results,
with an impressive F1-score of 67.8%",http://arxiv.org/abs/2406.10561v1
"As mental health issues for young adults present a pressing public health
concern, daily digital mood monitoring for early detection has become an
important prospect. An active research area, digital phenotyping, involves
collecting and analysing data from personal digital devices such as smartphones
(usage and sensors) and wearables to infer behaviours and mental health. Whilst
this data is standardly analysed using statistical and machine learning
approaches, the emergence of large language models (LLMs) offers a new approach
to make sense of smartphone sensing data. Despite their effectiveness across
various domains, LLMs remain relatively unexplored in digital mental health,
particularly in integrating mobile sensor data. Our study aims to bridge this
gap by employing LLMs to predict affect outcomes based on smartphone sensing
data from university students. We demonstrate the efficacy of zero-shot and
few-shot embedding LLMs in inferring general wellbeing. Our findings reveal
that LLMs can make promising predictions of affect measures using solely
smartphone sensing data. This research sheds light on the potential of LLMs for
affective state prediction, emphasizing the intricate link between smartphone
behavioral patterns and affective states. To our knowledge, this is the first
work to leverage LLMs for affective state prediction and digital phenotyping
tasks.",http://arxiv.org/abs/2407.08240v1
"Support-seekers' self-disclosure of their suffering experiences, thoughts,
and feelings in the post can help them get needed peer support in online mental
health communities (OMHCs). However, such mental health self-disclosure could
be challenging. Images can facilitate the manifestation of relevant experiences
and feelings in the text; yet, relevant images are not always available. In
this paper, we present a technical prototype named MentalImager and validate in
a human evaluation study that it can generate topical- and emotional-relevant
images based on the seekers' drafted posts or specified keywords. Two user
studies demonstrate that MentalImager not only improves seekers' satisfaction
with their self-disclosure in their posts but also invokes support-providers'
empathy for the seekers and willingness to offer help. Such improvements are
credited to the generated images, which help seekers express their emotions and
inspire them to add more details about their experiences and feelings. We
report concerns on MentalImager and discuss insights for supporting
self-disclosure in OMHCs.",http://arxiv.org/abs/2409.14859v1
"In mental health counseling, condensing dialogues into concise and relevant
summaries (aka counseling notes) holds pivotal significance. Large Language
Models (LLMs) exhibit remarkable capabilities in various generative tasks;
however, their adaptation to domain-specific intricacies remains challenging,
especially within mental health contexts. Unlike standard LLMs, mental health
experts first plan to apply domain knowledge in writing summaries. Our work
enhances LLMs' ability by introducing a novel planning engine to orchestrate
structuring knowledge alignment. To achieve high-order planning, we divide
knowledge encapsulation into two major phases: (i) holding dialogue structure
and (ii) incorporating domain-specific knowledge. We employ a planning engine
on Llama-2, resulting in a novel framework, PIECE. Our proposed system employs
knowledge filtering-cum-scaffolding to encapsulate domain knowledge.
Additionally, PIECE leverages sheaf convolution learning to enhance its
understanding of the dialogue's structural nuances. We compare PIECE with 14
baseline methods and observe a significant improvement across ROUGE and Bleurt
scores. Further, expert evaluation and analyses validate the generation quality
to be effective, sometimes even surpassing the gold standard. We further
benchmark PIECE with other LLMs and report improvement, including Llama-2
(+2.72%), Mistral (+2.04%), and Zephyr (+1.59%), to justify the
generalizability of the planning engine.",http://arxiv.org/abs/2409.14907v1
"Social interactions promote well-being, yet challenges like geographic
distance and mental health conditions can limit in-person engagement. Advances
in AI agents are transferring communication, particularly in mental health,
where AI chatbots provide accessible, non-judgmental support. However, a key
challenge is how effectively these systems can express empathy, which is
crucial in human-centered design. Current research highlights a gap in
understanding how AI can authentically convey empathy, particularly as issues
like anxiety, depression, and loneliness increase. Our research focuses on this
gap by comparing empathy expression in human-human versus human-AI
interactions. Using personal narratives and statistical analysis, we examine
empathy levels elicited by humans and AI, including GPT-4o and fine-tuned
versions of the model. This work aims to enhance the authenticity of AI-driven
empathy, contributing to the future design of more reliable and effective
mental health support systems that foster meaningful social interactions.",http://arxiv.org/abs/2409.15550v1